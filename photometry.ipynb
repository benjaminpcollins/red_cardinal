{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photometry on MIRI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import subprocess\n",
    "import miri_utils.photometry_tools as phot\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import FITSFixedWarning\n",
    "from astropy.table import Table\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=FITSFixedWarning)\n",
    "\n",
    "\n",
    "cutout_dir = \"/home/bpc/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "phot_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section to obtain modified apertures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect Amirs table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path =  '/home/bpc/University/master/Red_Cardinal/catalogues/Flux_Aperture_PSFMatched_AperCorr_old.fits'\n",
    "\n",
    "table = Table.read(table_path)\n",
    "#print(table[:5])\n",
    "table.info()\n",
    "print(table.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and call the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_dir = \"/home/bpc/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "phot_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/\"\n",
    "\n",
    "# Get all FITS file paths\n",
    "fits_files = glob.glob(os.path.join(cutout_dir, '*.fits'))\n",
    "\n",
    "# Get the basenames of the FITS files\n",
    "fits_fnames = [os.path.basename(f) for f in fits_files]\n",
    "\n",
    "adjusted_apertures = []\n",
    "\n",
    "for fname in fits_fnames:\n",
    "    id = fname.split('_')[0]\n",
    "    filter = fname.split('_')[1]\n",
    "    survey_obs = fname.split('_')[3]\n",
    "    \n",
    "    if '003' in survey_obs:\n",
    "        survey = 'primer'\n",
    "        obs = '003'\n",
    "    elif '004' in survey_obs:\n",
    "        survey = 'primer'\n",
    "        obs = '004'\n",
    "    elif 'cweb1' in survey_obs:\n",
    "        survey = 'cweb'\n",
    "        obs = '1'\n",
    "    elif 'cweb2' in survey_obs:\n",
    "        survey = 'cweb'\n",
    "        obs = '2'\n",
    "    elif 'cos3d1' in survey_obs:\n",
    "        survey = 'cos3d'\n",
    "        obs = '1'\n",
    "    elif 'cos3d2' in survey_obs:\n",
    "        survey = 'cos3d'\n",
    "        obs = '2'\n",
    "    else:\n",
    "        print(f\"Unknown survey and/or observation number for galaxy {id}:\\n\")\n",
    "        print(survey_obs)\n",
    "    \n",
    "    # Call and collect results\n",
    "    result = phot.adjust_aperture(id, filter, survey, obs, phot_dir, mask_folder='mask_v5', save_plot=True)\n",
    "    \n",
    "    if result:\n",
    "        adjusted_apertures.append(result)\n",
    "\n",
    "# After loop: create a DataFrame\n",
    "df_apertures = pd.DataFrame(adjusted_apertures)\n",
    "\n",
    "# v5 for manually modified ellipse sizes\n",
    "df_path = '/home/bpc/University/master/Red_Cardinal/photometry/aperture_table_v5.csv'\n",
    "\n",
    "# (optional) Save to CSV or integrate into photometry table\n",
    "df_apertures.to_csv(df_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily open any given FITS file with its corresponding ellipse region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Launch DS9 with the MIRI cutout and the overplotted aperture ---\n",
    "region_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/regions/\"\n",
    "cutout_dir = \"/home/bpc/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "phot_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/\"\n",
    "\n",
    "id = '10245'\n",
    "filter = 'F770W'\n",
    "survey_obs = 'primer004'\n",
    "cutout_path = os.path.join(cutout_dir, f'{id}_{filter}_cutout_{survey_obs}.fits')\n",
    "reg_path = os.path.join(region_dir, f'{id}_{survey_obs}_aperture.reg')\n",
    "subprocess.run([\"ds9\", cutout_path, \"-regions\", reg_path])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path =  '/home/bpc/University/master/Red_Cardinal/Flux_Aperture_PSFMatched_AperCorr_old.fits'\n",
    "\n",
    "table = Table.read(table_path)\n",
    "print(table[:5])\n",
    "table.info()\n",
    "print(table['Image_Err'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is where we do most of the work\n",
    "\n",
    "# Section to perform the actual photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters ---\n",
    "cutouts_folder = \"/home/bpc/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "output_folder = '/home/bpc/University/master/Red_Cardinal/photometry/'\n",
    "aperture_table_small = '/home/bpc/University/master/Red_Cardinal/photometry/aperture_table_small.csv'\n",
    "aperture_table_big = '/home/bpc/University/master/Red_Cardinal/photometry/aperture_table_big.csv'\n",
    "aperture_table = '/home/bpc/University/master/Red_Cardinal/photometry/aperture_table_v5.csv'\n",
    "fig_path = '/home/bpc/University/master/Red_Cardinal/photometry/Plots_MIRI_phot_v5/'\n",
    "#fig_path = None\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get all possible F770W files\n",
    "all_f770w_files = glob.glob(os.path.join(cutouts_folder, f'*F770W*.fits'))\n",
    "\n",
    "# Group F770W files by galaxy ID and filter\n",
    "f770w_files = []\n",
    "galaxy_ids = set([os.path.basename(f).split('_')[0] for f in all_f770w_files])\n",
    "\n",
    "#galaxy_ids = ['8465', '7922', '9871', '12202', '8843', '7904', '8338', '10021', '10245', '11136', '12340', '20397']\n",
    "\n",
    "\n",
    "for galaxy_id in galaxy_ids:\n",
    "    # Find all F770W files for this galaxy ID\n",
    "    matching_files = [f for f in all_f770w_files if os.path.basename(f).startswith(galaxy_id)]\n",
    "    \n",
    "    # Handle special case for galaxy 11853\n",
    "    if galaxy_id == '11853':\n",
    "        # Use the cweb2 file if available\n",
    "        cweb2_files = [f for f in matching_files if 'cweb2' in f.lower()]\n",
    "        if cweb2_files:\n",
    "            f770w_files.append(cweb2_files[0])\n",
    "            continue  # Skip to the next galaxy\n",
    "    \n",
    "    # Prioritise PRIMER over COSMOS-Web\n",
    "    primer_files = [f for f in matching_files if 'primer' in f.lower()]\n",
    "    cweb_files = [f for f in matching_files if 'cweb' in f.lower()]\n",
    "    \n",
    "    if primer_files:\n",
    "        f770w_files.append(primer_files[0])  # Prefer PRIMER file\n",
    "    elif cweb_files:\n",
    "        f770w_files.append(cweb_files[0])  # Use CWEB only if no PRIMER available\n",
    "\n",
    "\n",
    "# Get all F1000W files\n",
    "f1000w_files = glob.glob(os.path.join(cutouts_folder, f'*F1000W*.fits'))\n",
    "\n",
    "# Get all F1800W files\n",
    "f1800w_files = glob.glob(os.path.join(cutouts_folder, f'*F1800W*.fits'))\n",
    "\n",
    "# Get all F1800W files\n",
    "f2100w_files = glob.glob(os.path.join(cutouts_folder, f'*F2100W*.fits'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section to compare my aperture photometry to the photometry of the COSMOS-Web2025 catalogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Perform the photometry again for my data using the updated and corrected photometry\n",
    "2) Combine the tables into a single FITS output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "## STEP 1:   PERFORM PHOTOMETRY     ##\n",
    "######################################\n",
    "\n",
    "phot.perform_photometry(f770w_files, aperture_table_big, output_folder, suffix='v4')\n",
    "\n",
    "phot.perform_photometry(f1800w_files, aperture_table_big, output_folder, suffix='v4')\n",
    "\n",
    "#####################################\n",
    "## STEP 2:   COMBINE THE TABLEs    ##\n",
    "#####################################\n",
    "\n",
    "fits_table_v4 = f'Flux_Aperture_PSFMatched_AperCorr_MIRI_v4.fits'\n",
    "f770w_fname = 'phot_table_F770W_v4.csv'\n",
    "f1800w_fname = 'phot_table_F1800W_v4.csv'\n",
    "\n",
    "# Now create the combined FITS table\n",
    "#phot.combine_filter_csv_to_fits(f770w_fname, f1800w_fname, fits_table_name=fits_table_v4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from astropy.table import hstack\n",
    "\n",
    "cweb_path = '/home/bpc/University/master/Red_Cardinal/catalogues/COSMOSWeb_reduced.fits'\n",
    "my_path = '/home/bpc/University/master/Red_Cardinal/photometry/results/Flux_Aperture_PSFMatched_AperCorr_MIRI_v4.fits'\n",
    "cat_path = '/home/bpc/University/master/Red_Cardinal/catalogues/cat_targets.fits'\n",
    "\n",
    "my_table = Table.read(my_path, hdu=1)\n",
    "cosmos_table = Table.read(cweb_path, hdu=1)\n",
    "my_cat = Table.read(cat_path, hdu=1)\n",
    "fits.info(my_path)\n",
    "fits.info(cweb_path)\n",
    "#print(my_cat.columns)\n",
    "\n",
    "# Rename ID column to id to match other catalogues\n",
    "my_table.rename_column('ID', 'id')\n",
    "\n",
    "# Reduce catalogue\n",
    "my_cat_small = my_cat['id', 'ra', 'dec']\n",
    "\n",
    "# Force type setting\n",
    "my_table['id'] = my_table['id'].astype(str)\n",
    "my_cat_small['id'] = my_cat_small['id'].astype(str)\n",
    "\n",
    "# Match according to IDs\n",
    "matched = join(my_table, my_cat_small, keys=('id'), join_type='inner')\n",
    "\n",
    "print(matched.columns)\n",
    "\n",
    "matched.write('/home/bpc/University/master/Red_Cardinal/catalogues/Flux_Aperture_PSFMatched_AperCorr_MIRI_ra_dec.fits', overwrite=True)\n",
    "\n",
    "# Build coordinates\n",
    "coords_my = SkyCoord(ra=matched['ra']*u.deg, dec=matched['dec']*u.deg)\n",
    "coords_cosmos = SkyCoord(ra=cosmos_table['ra']*u.deg, dec=cosmos_table['dec']*u.deg)\n",
    "\n",
    "# Match (within 0.3 arcsec, for instance)\n",
    "idx, d2d, _ = coords_my.match_to_catalog_sky(coords_cosmos)\n",
    "match_mask = d2d < 0.3 * u.arcsec\n",
    "\n",
    "# Build matched table\n",
    "my_matched = matched[match_mask]    # important to take the matched catalogue!\n",
    "cosmos_matched = cosmos_table[idx[match_mask]]\n",
    "\n",
    "# Combine tables: rename columns to avoid name collision\n",
    "cosmos_matched.rename_columns(\n",
    "    cosmos_matched.colnames,\n",
    "    [name + \"_cosmos\" if name in my_matched.colnames else name for name in cosmos_matched.colnames]\n",
    ")\n",
    "\n",
    "# Merge horizontally\n",
    "sky_matched = hstack([my_matched, cosmos_matched])\n",
    "\n",
    "print(sky_matched.columns)\n",
    "sky_matched.info()\n",
    "\n",
    "sky_matched.write('/home/bpc/University/master/Red_Cardinal/catalogues/COSMOSWeb_sky_matched.fits', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and call huge plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_and_prepare_data(fits_file_path):\n",
    "    \"\"\"\n",
    "    Load the FITS table and prepare data for comparison\n",
    "    \"\"\"\n",
    "    # Load the FITS table\n",
    "    table = Table.read(fits_file_path)\n",
    "    \n",
    "    # Extract F770W data from multi-dimensional arrays\n",
    "    # For Flux and Flux_Err, take the first value (F770W filter)\n",
    "    flux_personal = []\n",
    "    flux_err_personal = []\n",
    "    ab_mag_personal = []\n",
    "    \n",
    "    for i in range(len(table)):\n",
    "        # Handle Flux (F770W is first element)\n",
    "        if table['Flux'].mask[i][0] == False:\n",
    "            flux_val = table['Flux'][i]*1e6 # convert to µJy\n",
    "            if hasattr(flux_val, '__len__') and len(flux_val) > 0:\n",
    "                flux_personal.append(flux_val[0])\n",
    "            else:\n",
    "                flux_personal.append(flux_val)\n",
    "        else:\n",
    "            flux_personal.append(np.nan)\n",
    "            \n",
    "        # Handle Flux_Err (F770W is first element)\n",
    "        if table['Flux_Err'].mask[i][0] == False:\n",
    "            flux_err_val = table['Flux_Err'][i]*1e6 # convert to µJy\n",
    "            if hasattr(flux_err_val, '__len__') and len(flux_err_val) > 0:\n",
    "                flux_err_personal.append(flux_err_val[0])\n",
    "            else:\n",
    "                flux_err_personal.append(flux_err_val)\n",
    "        else:\n",
    "            flux_err_personal.append(np.nan)\n",
    "            \n",
    "        # Handle AB_Mag (F770W is first element)\n",
    "        if table['AB_Mag'].mask[i][0] == False:\n",
    "            ab_mag_val = table['AB_Mag'][i]\n",
    "            if hasattr(ab_mag_val, '__len__') and len(ab_mag_val) > 0:\n",
    "                ab_mag_personal.append(ab_mag_val[0])\n",
    "            else:\n",
    "                ab_mag_personal.append(ab_mag_val)\n",
    "        else:\n",
    "            ab_mag_personal.append(np.nan)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    flux_personal = np.array(flux_personal)\n",
    "    flux_err_personal = np.array(flux_err_personal)\n",
    "    ab_mag_personal = np.array(ab_mag_personal)\n",
    "    \n",
    "    # Extract public catalogue data\n",
    "    flux_public = np.array(table['flux_auto_f770w'])\n",
    "    flux_err_public = np.array(table['flux_err_auto_f770w'])\n",
    "    mag_public = np.array(table['mag_auto_f770w'])\n",
    "    \n",
    "    # Create masks for valid data\n",
    "    valid_flux = (~np.isnan(flux_personal)) & (~np.isnan(flux_public)) & \\\n",
    "                 (flux_personal > 0) & (flux_public > 0)\n",
    "    valid_flux_err = (~np.isnan(flux_personal)) & (~np.isnan(flux_public)) & \\\n",
    "                     (flux_personal > 0) & (flux_public > 0)\n",
    "    \n",
    "    return {\n",
    "        'table': table,\n",
    "        'flux_personal': flux_personal,\n",
    "        'flux_err_personal': flux_err_personal,\n",
    "        'ab_mag_personal': ab_mag_personal,\n",
    "        'flux_public': flux_public,\n",
    "        'flux_err_public': flux_err_public,\n",
    "        'mag_public': mag_public,\n",
    "        'valid_flux': valid_flux,\n",
    "        'valid_flux_err': valid_flux_err\n",
    "    }\n",
    "\n",
    "def calculate_statistics(x, y, valid_mask):\n",
    "    \"\"\"\n",
    "    Calculate comparison statistics\n",
    "    \"\"\"\n",
    "    if np.sum(valid_mask) < 3:\n",
    "        return {}\n",
    "    \n",
    "    x_valid = x[valid_mask]\n",
    "    y_valid = y[valid_mask]\n",
    "    \n",
    "    # Linear correlation\n",
    "    corr_coef, p_value = stats.pearsonr(x_valid, y_valid)\n",
    "    \n",
    "    # Calculate residuals and statistics\n",
    "    residuals = y_valid - x_valid\n",
    "    mean_residual = np.mean(residuals)\n",
    "    median_residual = np.median(residuals)\n",
    "    std_residual = np.std(residuals)\n",
    "    rms_residual = np.sqrt(np.mean(residuals**2))\n",
    "    \n",
    "    # Fractional differences for positive values\n",
    "    frac_diff = (y_valid - x_valid) / x_valid\n",
    "    median_frac_diff = np.median(frac_diff)\n",
    "    mean_frac_diff = np.mean(frac_diff)\n",
    "    std_frac_diff = np.std(frac_diff)\n",
    "    \n",
    "    return {\n",
    "        'correlation': corr_coef,\n",
    "        'p_value': p_value,\n",
    "        'median_residual': median_residual,\n",
    "        'mean_residual': mean_residual,\n",
    "        'std_residual': std_residual,\n",
    "        'rms_residual': rms_residual,\n",
    "        'median_frac_diff': median_frac_diff,\n",
    "        'mean_frac_diff': mean_frac_diff,\n",
    "        'std_frac_diff': std_frac_diff,\n",
    "        'n_objects': len(x_valid)\n",
    "    }\n",
    "\n",
    "def create_comparison_plot(data):\n",
    "    \"\"\"\n",
    "    Create comprehensive comparison plots\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    # Define color scheme\n",
    "    colors = {'scatter': '#1f77b4', 'line': '#ff7f0e', 'hist': '#2ca02c'}\n",
    "    \n",
    "    # 1. Flux comparison (log-log scale)\n",
    "    ax1 = plt.subplot(3, 3, 1)\n",
    "    valid_flux = data['valid_flux']\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        \n",
    "        ax1.scatter(x_flux, y_flux, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(x_flux), np.min(y_flux))\n",
    "        max_val = max(np.max(x_flux), np.max(y_flux))\n",
    "        ax1.plot([min_val, max_val], [min_val, max_val], '--', color=colors['line'], lw=2)\n",
    "        \n",
    "        ax1.set_xscale('log')\n",
    "        ax1.set_yscale('log')\n",
    "        ax1.set_xlabel('Personal Catalogue Flux (µJy)')\n",
    "        ax1.set_ylabel('COSMOS-Web DR1 Catalogue Flux (µJy)')\n",
    "        ax1.set_title('Flux Comparison (F770W)')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        stats_flux = calculate_statistics(x_flux, y_flux, np.ones(len(x_flux), dtype=bool))\n",
    "        if stats_flux:\n",
    "            ax1.text(0.05, 0.95, f'r = {stats_flux[\"correlation\"]:.3f}\\nN = {stats_flux[\"n_objects\"]}', \n",
    "                    transform=ax1.transAxes, verticalalignment='top', \n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 2. Flux error comparison (log-log scale)\n",
    "    ax2 = plt.subplot(3, 3, 2)\n",
    "    valid_flux_err = data['valid_flux_err']\n",
    "    if np.sum(valid_flux_err) > 0:\n",
    "        x_err = data['flux_err_personal'][valid_flux_err]\n",
    "        y_err = data['flux_err_public'][valid_flux_err]\n",
    "        \n",
    "        ax2.scatter(x_err, y_err, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(x_err), np.min(y_err))\n",
    "        max_val = max(np.max(x_err), np.max(y_err))\n",
    "        ax2.plot([min_val, max_val], [min_val, max_val], '--', color=colors['line'], lw=2)\n",
    "        \n",
    "        ax2.set_xscale('log')\n",
    "        ax2.set_yscale('log')\n",
    "        ax2.set_xlabel('Personal Catalogue Flux Error (µJy)')\n",
    "        ax2.set_ylabel('COSMOS-Web DR1 Catalogue Flux Error (µJy)')\n",
    "        ax2.set_title('Flux Error Comparison (F770W)')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        stats_err = calculate_statistics(x_err, y_err, np.ones(len(x_err), dtype=bool))\n",
    "        if stats_err:\n",
    "            ax2.text(0.05, 0.95, f'r = {stats_err[\"correlation\"]:.3f}\\nN = {stats_err[\"n_objects\"]}', \n",
    "                    transform=ax2.transAxes, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    \n",
    "    # 3. Signal-to-noise ratio comparison\n",
    "    ax3 = plt.subplot(3, 3, 3)\n",
    "    valid_snr = data['valid_flux'] & data['valid_flux_err']\n",
    "    if np.sum(valid_snr) > 0:\n",
    "        snr_personal = data['flux_personal'][valid_snr] / data['flux_err_personal'][valid_snr]\n",
    "        snr_public = data['flux_public'][valid_snr] / data['flux_err_public'][valid_snr]\n",
    "        \n",
    "        max_idx = np.argmax(snr_public)\n",
    "        \n",
    "        snr_personal = np.delete(snr_personal, max_idx)\n",
    "        snr_public = np.delete(snr_public, max_idx)\n",
    "        \n",
    "        ax3.scatter(snr_personal, snr_public, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(snr_personal), np.min(snr_public))\n",
    "        max_val = max(np.max(snr_personal), np.max(snr_public))\n",
    "        ax3.plot([min_val, max_val], [min_val, max_val], '--', color=colors['line'], lw=2)\n",
    "        \n",
    "        ax3.set_xlabel('Personal Catalogue S/N')\n",
    "        ax3.set_ylabel('COSMOS-Web DR1 Catalogue S/N')\n",
    "        ax3.set_title('Signal-to-Noise Ratio Comparison')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        stats_snr = calculate_statistics(snr_personal, snr_public, np.ones(len(snr_personal), dtype=bool))\n",
    "        if stats_snr:\n",
    "            ax3.text(0.05, 0.95, f'r = {stats_snr[\"correlation\"]:.3f}\\nN = {stats_snr[\"n_objects\"]}', \n",
    "                    transform=ax3.transAxes, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 4. Flux residuals vs flux\n",
    "    ax4 = plt.subplot(3, 3, 4)\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        residuals = y_flux - x_flux\n",
    "        \n",
    "        ax4.scatter(x_flux, residuals, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        ax4.axhline(y=0, color=colors['line'], linestyle='--', lw=2)\n",
    "        ax4.set_xscale('log')\n",
    "        ax4.set_xlabel('Personal Catalogue Flux (µJy)')\n",
    "        ax4.set_ylabel('Flux Residuals (Public - Personal)')\n",
    "        ax4.set_title('Flux Residuals vs Flux')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Fractional flux differences\n",
    "    ax5 = plt.subplot(3, 3, 5)\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        frac_diff = (y_flux - x_flux) / x_flux\n",
    "        \n",
    "        ax5.scatter(x_flux, frac_diff, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        ax5.axhline(y=0, color=colors['line'], linestyle='--', lw=2)\n",
    "        ax5.set_xscale('log')\n",
    "        ax5.set_xlabel('Personal Catalogue Flux (µJy)')\n",
    "        ax5.set_ylabel('Fractional Flux Difference')\n",
    "        ax5.set_title('Fractional Flux Differences')\n",
    "        ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Error bar comparison\n",
    "    ax6 = plt.subplot(3, 3, 6)\n",
    "    if np.sum(valid_flux) & np.sum(valid_flux_err) > 0:\n",
    "        valid_both = valid_flux & valid_flux_err\n",
    "        x_flux = data['flux_personal'][valid_both]\n",
    "        y_flux = data['flux_public'][valid_both]\n",
    "        x_err = data['flux_err_personal'][valid_both]\n",
    "        y_err = data['flux_err_public'][valid_both]\n",
    "        \n",
    "        # Plot a subset of points with error bars to avoid cluttering\n",
    "        #n_plot = min(50, len(x_flux))\n",
    "        #indices = np.random.choice(len(x_flux), n_plot, replace=False)\n",
    "        \n",
    "        ax6.errorbar(x_flux, y_flux, \n",
    "                    xerr=x_err, yerr=y_err,\n",
    "                    fmt='o', alpha=0.6, capsize=3, color=colors['scatter'])\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(x_flux), np.min(y_flux))\n",
    "        max_val = max(np.max(x_flux), np.max(y_flux))\n",
    "        ax6.plot([min_val, max_val], [min_val, max_val], '--', color=colors['line'], lw=2)\n",
    "        \n",
    "        ax6.loglog()\n",
    "        ax6.set_xlabel('Personal Catalogue Flux (µJy)')\n",
    "        ax6.set_ylabel('COSMOS-Web DR1 Catalogue Flux (µJy)')\n",
    "        ax6.set_title(f'Flux with Error Bars')\n",
    "        ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 7. Flux histogram comparison\n",
    "    ax7 = plt.subplot(3, 3, 7)\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        \n",
    "        bins = np.logspace(np.log10(min(np.min(x_flux), np.min(y_flux))), \n",
    "                          np.log10(max(np.max(x_flux), np.max(y_flux))), 20)\n",
    "        \n",
    "        ax7.hist(x_flux, bins=bins, alpha=0.6, label='Personal', color=colors['scatter'])\n",
    "        ax7.hist(y_flux, bins=bins, alpha=0.6, label='COSMOS-Web DR1', color=colors['line'])\n",
    "        ax7.set_xscale('log')\n",
    "        ax7.set_xlabel('Flux (µJy)')\n",
    "        ax7.set_ylabel('Number of Objects')\n",
    "        ax7.set_title('Flux Distribution Comparison')\n",
    "        ax7.legend()\n",
    "        ax7.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 8. Residuals histogram\n",
    "    ax8 = plt.subplot(3, 3, 8)\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        frac_diff = (y_flux - x_flux) / x_flux\n",
    "        \n",
    "        ax8.hist(frac_diff, bins=30, alpha=0.7, color=colors['hist'])\n",
    "        ax8.axvline(x=0, color=colors['line'], linestyle='--', lw=2)\n",
    "        ax8.axvline(x=np.median(frac_diff), color='red', linestyle='-', lw=2, label=f'Median: {np.median(frac_diff):.3f}')\n",
    "        ax8.axvline(x=np.mean(frac_diff), color='blue', linestyle='-', lw=2, label=f'Mean: {np.mean(frac_diff):.3f}')\n",
    "        ax8.set_xlabel('Fractional Flux Difference')\n",
    "        ax8.set_ylabel('Number of Objects')\n",
    "        ax8.set_title('Fractional Difference Distribution')\n",
    "        ax8.legend()\n",
    "        ax8.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 9. Summary statistics text\n",
    "    ax12 = plt.subplot(3, 3, 9)\n",
    "    ax12.axis('off')\n",
    "    \n",
    "    summary_text = \"\\n  PHOTOMETRY COMPARISON SUMMARY  \\n\\n\"\n",
    "    \n",
    "    if np.sum(valid_flux) > 0:\n",
    "        stats_flux = calculate_statistics(data['flux_personal'][valid_flux], \n",
    "                                        data['flux_public'][valid_flux], \n",
    "                                        np.ones(np.sum(valid_flux), dtype=bool))\n",
    "        if stats_flux:\n",
    "            summary_text += f\"  FLUX COMPARISON (N={stats_flux['n_objects']}):  \\n\"\n",
    "            summary_text += f\"    Correlation: {stats_flux['correlation']:.3f}  \\n\"\n",
    "            summary_text += f\"    Median fractional diff: {stats_flux['median_frac_diff']:.3f}  \\n\"\n",
    "            summary_text += f\"    Mean fractional diff: {stats_flux['mean_frac_diff']:.3f}  \\n\"\n",
    "            summary_text += f\"    Std fractional diff: {stats_flux['std_frac_diff']:.3f}  \\n\\n\"\n",
    "    \n",
    "    summary_text += f\"  DATA COVERAGE:\\n\"\n",
    "    summary_text += f\"    Total objects: {len(data['table'])}  \\n\"\n",
    "    summary_text += f\"    Valid flux measurements: {np.sum(valid_flux)}  \\n\"\n",
    "    \n",
    "    ax12.text(0.05, 0.95, summary_text, transform=ax12.transAxes, \n",
    "             verticalalignment='top', fontfamily='monospace', fontsize=14,\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Main execution function\n",
    "def analyse_photometry_comparison(fits_file_path, output_plot_path=None):\n",
    "    \"\"\"\n",
    "    Main function to perform photometry comparison analysis\n",
    "    \"\"\"\n",
    "    print(\"Loading and preparing data...\")\n",
    "    data = load_and_prepare_data(fits_file_path)\n",
    "    \n",
    "    print(\"Creating comparison plots...\")\n",
    "    fig = create_comparison_plot(data)\n",
    "    \n",
    "    if output_plot_path:\n",
    "        print(f\"Saving plot to {output_plot_path}\")\n",
    "        plt.savefig(output_plot_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PHOTOMETRY COMPARISON ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    valid_flux = data['valid_flux']\n",
    "    \n",
    "    if np.sum(valid_flux) > 0:\n",
    "        stats_flux = calculate_statistics(data['flux_personal'][valid_flux], \n",
    "                                        data['flux_public'][valid_flux], \n",
    "                                        np.ones(np.sum(valid_flux), dtype=bool))\n",
    "        if stats_flux:\n",
    "            print(f\"\\nFLUX COMPARISON ({stats_flux['n_objects']} objects):\")\n",
    "            print(f\"  Pearson correlation coefficient: {stats_flux['correlation']:.4f}\")\n",
    "            print(f\"  Mean fractional difference: {stats_flux['mean_frac_diff']:.4f}\")\n",
    "            print(f\"  Standard deviation of fractional differences: {stats_flux['std_frac_diff']:.4f}\")\n",
    "            print(f\"  RMS of absolute residuals: {stats_flux['rms_residual']:.4f} µJy\")\n",
    "    \n",
    "    print(f\"\\nDATA COVERAGE:\")\n",
    "    print(f\"  Total objects in table: {len(data['table'])}\")\n",
    "    print(f\"  Objects with valid flux measurements: {np.sum(valid_flux)}\")\n",
    "    \n",
    "    return data, fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Replace with your FITS file path\n",
    "fits_file_path = '/home/bpc/University/master/Red_Cardinal/catalogues/COSMOSWeb_sky_matched.fits'\n",
    "\n",
    "\n",
    "# Optional: specify output path for the plot\n",
    "output_plot_path = '/home/bpc/University/master/Red_Cardinal/photometry/photometry_comparisons/phot_comp_sky_matched_new.png'\n",
    "\n",
    "# Run the analysis\n",
    "data, fig = analyse_photometry_comparison(fits_file_path, output_plot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section to perform photometry with all 4 filters (F770W, F1000W, F1800W, F2100W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing the photometry became much easier now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "phot.perform_photometry(f770w_files, aperture_table, output_folder, suffix='v5')\n",
    "\n",
    "phot.perform_photometry(f1000w_files, aperture_table, output_folder, suffix='v5')\n",
    "\n",
    "phot.perform_photometry(f1800w_files, aperture_table, output_folder, suffix='v5')\n",
    "\n",
    "phot.perform_photometry(f2100w_files, aperture_table, output_folder, suffix='v5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now combine the csv files into one big table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_table_v5 = 'Flux_Aperture_PSFMatched_AperCorr_MIRI_v5.fits'\n",
    "\n",
    "results_dir = '/home/bpc/University/master/Red_Cardinal/photometry/results/'\n",
    "\n",
    "f770w_fname  = os.path.join(results_dir, 'phot_table_F770W_v5.csv')\n",
    "f1000w_fname = os.path.join(results_dir, 'phot_table_F1000W_v5.csv')\n",
    "f1800w_fname = os.path.join(results_dir, 'phot_table_F1800W_v5.csv')\n",
    "f2100w_fname = os.path.join(results_dir, 'phot_table_F2100W_v5.csv')\n",
    "\n",
    "csv_paths = [f770w_fname, f1000w_fname, f1800w_fname, f2100w_fname]\n",
    "\n",
    "# Now create the combined FITS table\n",
    "phot.create_fits_table_from_csv(csv_paths, output_file=fits_table_v5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to read and interpret the flags:\n",
    "fits_table_v5 = '/home/bpc/University/master/Red_Cardinal/photometry/phot_tables/Flux_Aperture_PSFMatched_AperCorr_MIRI_v5.fits'\n",
    "table = Table.read(fits_table_v5)\n",
    "\n",
    "for i, gid in enumerate(table['ID']):\n",
    "    filters_available = table['Filters'][i].split(',')\n",
    "    has_companion = table['Flag_Com'][i]\n",
    "    artifact_flags = table['Flag_Art'][i]\n",
    "    \n",
    "    print(f\"Galaxy {gid}: Companion = {has_companion}\")\n",
    "    for j, filt in enumerate(filters_available):\n",
    "        has_artifact = artifact_flags[j]\n",
    "        print(f\"  {filt}: Artifact = {has_artifact}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_table_v5 = '/home/bpc/University/master/Red_Cardinal/photometry/phot_tables/Flux_Aperture_PSFMatched_AperCorr_MIRI_v5.fits'\n",
    "fig_path = '/home/bpc/University/master/Red_Cardinal/photometry/miri_coverage_v5.png'\n",
    "stats_path = '/home/bpc/University/master/Red_Cardinal/photometry/galaxy_stats_v5.txt'\n",
    "filter_to_ids = phot.galaxy_statistics(fits_table_v5, fig_path, stats_path)\n",
    "\n",
    "ids_in_f770w = filter_to_ids.get('F70W', set())\n",
    "ids_in_f1000w = filter_to_ids.get('F1000W', set())\n",
    "ids_in_f1800w = filter_to_ids.get('F1800W', set())\n",
    "ids_in_f2100w = filter_to_ids.get('F2100W', set())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for my newest function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_dir = '/home/bpc/University/master/Red_Cardinal/photometry/vis_data'\n",
    "mosaic_dir = '/home/bpc/University/master/Red_Cardinal/photometry/mosaic_plots/'\n",
    "plane_sub_dir = '/home/bpc/University/master/Red_Cardinal/photometry/plane_sub/'\n",
    "\n",
    "#phot.create_mosaics(vis_dir, mosaic_dir, plane_sub_dir)\n",
    "phot.create_mosaics(vis_dir, plane_sub_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
