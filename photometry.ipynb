{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photometry on MIRI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import subprocess\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS, FITSFixedWarning\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "from astropy.stats import SigmaClip\n",
    "from astropy.visualization import ZScaleInterval\n",
    "\n",
    "from photutils.aperture import EllipticalAperture, EllipticalAnnulus, RectangularAperture, aperture_photometry\n",
    "from photutils.background import Background2D, MedianBackground\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=FITSFixedWarning)\n",
    "\n",
    "\n",
    "cutout_dir = \"/home/bpc/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "phot_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section to obtain modified apertures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect Amirs table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path =  '/home/bpc/University/master/Red_Cardinal/Flux_Aperture_PSFMatched_AperCorr_old.fits'\n",
    "\n",
    "table = Table.read(table_path)\n",
    "#print(table[:5])\n",
    "table.info()\n",
    "print(table.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's choose a galaxy, read its aperture data and overplot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cutout(file_path, index=1):\n",
    "    \"\"\"Loads a FITS cutout file and extracts the data, header, and WCS.\"\"\"\n",
    "    try:\n",
    "        with fits.open(file_path) as hdu:\n",
    "            data = hdu[index].data\n",
    "            header = hdu[index].header\n",
    "            wcs = WCS(header)\n",
    "        return data, wcs\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None, None\n",
    "\n",
    "def adjust_aperture(galaxy_id, filter, survey, obs, output_folder, save_plot=False):\n",
    "    \n",
    "    # --- Load the FITS table ---\n",
    "    #table_path =  '/home/bpc/University/master/Red_Cardinal/Flux_Aperture_PSFMatched_AperCorr_old.fits'\n",
    "    #aperture_table = Table.read(table_path)\n",
    "    table_path =  '/home/bpc/University/master/Red_Cardinal/aperture_table.csv'\n",
    "    df = pd.read_csv(table_path)\n",
    "    \n",
    "    # --- Select the galaxy by ID ---\n",
    "    #row = aperture_table[aperture_table['ID'] == galaxy_id][0]\n",
    "    galaxy_id = int(galaxy_id)\n",
    "    row = df[df['ID'] == galaxy_id].iloc[0]\n",
    "\n",
    "    # --- Read in rotation angle of MIRI FITS file ---\n",
    "    angle_file = '/home/bpc/University/master/Red_Cardinal/rotation_angles.json'\n",
    "    with open(angle_file, \"r\") as f:\n",
    "        angles = json.load(f)\n",
    "    angle = angles[f\"angle_{survey}{obs}\"]\n",
    "    \n",
    "    # --- Read WCS from NIRCam image ---\n",
    "    nircam_path = f\"/home/bpc/University/master/Red_Cardinal/NIRCam/F444W_cutouts/{galaxy_id}_F444W_cutout.fits\"\n",
    "    nircam_data, nircam_wcs = load_cutout(nircam_path)\n",
    "\n",
    "    # --- Convert NIRCam pixel coordinates to sky ---\n",
    "    sky_coord = nircam_wcs.pixel_to_world(row['Apr_Xcenter'], row['Apr_Ycenter'])\n",
    "    \n",
    "    # --- Open MIRI cutout image ---\n",
    "    miri_path = f\"/home/bpc/University/master/Red_Cardinal/cutouts_phot/{galaxy_id}_{filter}_cutout_{survey}{obs}.fits\"\n",
    "    miri_data, miri_wcs = load_cutout(miri_path)\n",
    "\n",
    "    # --- Convert sky coords to MIRI pixel coordinates ---\n",
    "    miri_x, miri_y = miri_wcs.world_to_pixel(sky_coord)\n",
    "\n",
    "    # --- Create elliptical region in MIRI pixel space ---\n",
    "    nircam_scale = 0.03    # arcsec/pixel\n",
    "    miri_scale = 0.11092  # arcsec per pixel\n",
    "    \n",
    "    # arcsec/pixel\n",
    "    scale_factor = nircam_scale / miri_scale\n",
    "    \n",
    "    # --- Specify parameters for the ellips ---\n",
    "    width = row['Apr_A'] * scale_factor\n",
    "    height = row['Apr_B'] * scale_factor\n",
    "    theta = -row['Apr_Theta']\n",
    "    theta_new = ((theta - angle) % 180) * u.deg\n",
    "    \n",
    "    # --- Create region file and check if folder exists ---\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    reg_file = os.path.join(output_folder, f'regions/{galaxy_id}_{survey}{obs}_aperture.reg') \n",
    "    \n",
    "    # --- Write to DS9-compatible region file ---\n",
    "    with open(reg_file, \"w\") as fh:\n",
    "        fh.write(\"# Region file format: DS9 version 4.1\\n\")\n",
    "        fh.write(\"global color=red dashlist=8 3 width=2 font=\\\"helvetica 10 normal\\\" \"\n",
    "                \"select=1 highlite=1 dash=0 fixed=0 edit=1 move=1 delete=1 include=1 source=1\\n\")\n",
    "        fh.write(\"image\\n\")\n",
    "        fh.write(f\"ellipse({miri_x:.2f},{miri_y:.2f},{width:.2f},{height:.2f},{theta_new:.2f})\\n\")\n",
    "    \n",
    "    if save_plot:\n",
    "        \n",
    "        # --- Clean and prepare the MIRI data for plotting ---\n",
    "        miri_clean = np.copy(miri_data)\n",
    "        finite_vals = miri_clean[np.isfinite(miri_clean)].flatten()\n",
    "        \n",
    "        # Sort and get lowest 80% values\n",
    "        sorted_vals = np.sort(finite_vals)\n",
    "        cutoff_index = int(0.8 * len(sorted_vals))\n",
    "        background_vals = sorted_vals[:cutoff_index]\n",
    "        background_mean = np.mean(background_vals)\n",
    "\n",
    "        # Replace NaNs or infs with background mean\n",
    "        miri_clean[~np.isfinite(miri_clean)] = background_mean\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6,6))\n",
    "        ax.imshow(miri_clean, origin='lower', cmap='gray', vmin=np.percentile(miri_clean, 5), vmax=np.percentile(miri_clean, 99))\n",
    "\n",
    "        # Original ellipse (without rotation correction)\n",
    "        ellipse_original = Ellipse(\n",
    "            xy=(miri_x, miri_y),\n",
    "            width=width,\n",
    "            height=height,\n",
    "            angle=theta,  # Just the original Î¸!\n",
    "            edgecolor='red',\n",
    "            facecolor='none',\n",
    "            lw=2,\n",
    "            label='Original Ellipse'\n",
    "        )\n",
    "        ax.add_patch(ellipse_original)\n",
    "\n",
    "        ellipse = Ellipse(\n",
    "            xy=(miri_x, miri_y),\n",
    "            width=width,\n",
    "            height=height,\n",
    "            angle=theta_new.to_value(u.deg),\n",
    "            edgecolor='blue',\n",
    "            linestyle='--',  # maybe dashed to differentiate\n",
    "            facecolor='none',\n",
    "            lw=2,\n",
    "            label='Rotated Ellipse'\n",
    "        )\n",
    "        ax.add_patch(ellipse)\n",
    "        \n",
    "        ax.set_title(f\"Galaxy {galaxy_id} - {filter} ({survey}{obs})\")\n",
    "        ax.set_xlim(miri_x - 30, miri_x + 30)\n",
    "        ax.set_ylim(miri_y - 30, miri_y + 30)\n",
    "        ax.legend(loc='upper right')\n",
    "        \n",
    "        # Save figure\n",
    "        png_path = os.path.join(output_folder, f'masks/{galaxy_id}_{survey}{obs}_aperture_overlay.png')\n",
    "        plt.savefig(png_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        \n",
    "    # Collect modified aperture data\n",
    "    aperture_info = {          \n",
    "    'Apr_A': width,            # Rescaled aperture\n",
    "    'Apr_B': height,\n",
    "    'Apr_Xcenter': miri_x,\n",
    "    'Apr_Ycenter': miri_y,\n",
    "    'Apr_Theta': theta_new.to_value(u.deg),\n",
    "    'ID': galaxy_id\n",
    "    }\n",
    "    \n",
    "    return aperture_info\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and call the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_dir = \"/home/bpc/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "phot_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/\"\n",
    "\n",
    "# Get all FITS file paths\n",
    "fits_files = glob.glob(os.path.join(cutout_dir, '*.fits'))\n",
    "\n",
    "# Get the basenames of the FITS files\n",
    "fits_fnames = [os.path.basename(f) for f in fits_files]\n",
    "\n",
    "adjusted_apertures = []\n",
    "\n",
    "for fname in fits_fnames:\n",
    "    id = fname.split('_')[0]\n",
    "    filter = fname.split('_')[1]\n",
    "    if filter == 'F1800W': continue\n",
    "    survey_obs = fname.split('_')[3]\n",
    "    if '003' in survey_obs:\n",
    "        survey = 'primer'\n",
    "        obs = '003'\n",
    "    elif '004' in survey_obs:\n",
    "        survey = 'primer'\n",
    "        obs = '004'\n",
    "    elif '1' in survey_obs:\n",
    "        survey = 'cweb'\n",
    "        obs = '1'\n",
    "    elif '2' in survey_obs:\n",
    "        survey = 'cweb'\n",
    "        obs = '2'\n",
    "    else:\n",
    "        print(f\"Unknown survey and/or observation number for galaxy {id}:\\n\")\n",
    "        print(survey_obs)\n",
    "    \n",
    "    # Call and collect results\n",
    "    result = adjust_aperture(id, filter, survey, obs, phot_dir, save_plot=False)\n",
    "    if result:\n",
    "        adjusted_apertures.append(result)\n",
    "\n",
    "# After loop: create a DataFrame\n",
    "df_apertures = pd.DataFrame(adjusted_apertures)\n",
    "\n",
    "df_path = '/home/bpc/University/master/Red_Cardinal/photometry/aperture_table_rot.csv'\n",
    "\n",
    "# (optional) Save to CSV or integrate into photometry table\n",
    "df_apertures.to_csv(df_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily open any given FITS file with its corresponding ellipse region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Launch DS9 with the MIRI cutout and the overplotted aperture ---\n",
    "region_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/regions/\"\n",
    "cutout_dir = \"/home/bpc/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "phot_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/\"\n",
    "\n",
    "id = '10245'\n",
    "filter = 'F770W'\n",
    "survey_obs = 'primer004'\n",
    "cutout_path = os.path.join(cutout_dir, f'{id}_{filter}_cutout_{survey_obs}.fits')\n",
    "reg_path = os.path.join(region_dir, f'{id}_{survey_obs}_aperture.reg')\n",
    "subprocess.run([\"ds9\", cutout_path, \"-regions\", reg_path])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path =  '/home/bpc/University/master/Red_Cardinal/Flux_Aperture_PSFMatched_AperCorr_old.fits'\n",
    "\n",
    "table = Table.read(table_path)\n",
    "print(table[:5])\n",
    "table.info()\n",
    "print(table['Image_Err'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is where we do most of the work\n",
    "\n",
    "# Section to perform the actual photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's set some parameters straight:\n",
    "\n",
    "pixscale_arcsec = 0.11092  # arcsec per pixel\n",
    "\n",
    "pix_area_sr = 2.89208962133982e-13  # from MIRI header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_background(galaxy_id, filter_name, image_data, aperture_params, sigma=3.0, \n",
    "                        annulus_factor=3.0, fig_path=None):\n",
    "    \"\"\"\n",
    "    Estimate background using a global 2D plane fit, then extract statistics from \n",
    "    an elliptical annulus.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    galaxy_id : str\n",
    "        The ID of the galaxy\n",
    "    filter_name : str\n",
    "        The band which is being observed\n",
    "    image_data : ndarray\n",
    "        The 2D image data\n",
    "    aperture_params : dict\n",
    "        Dictionary containing aperture parameters (x_center, y_center, a, b, theta)\n",
    "    sigma : float\n",
    "        Sigma clipping threshold\n",
    "    annulus_factor : float\n",
    "        Factor by which to scale the inner ellipse to create the outer ellipse\n",
    "    visualise : bool, optional\n",
    "        If True, display visualisation plots\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    - background_plane : ndarray\n",
    "        2D background model\n",
    "    - background_median : float\n",
    "        median background value within the annulus\n",
    "    - background_std : float\n",
    "        standard deviation of background model within the annulus (excluding clipped data)\n",
    "    - background_region_mask : ndarray\n",
    "        boolean mask showing the region used for background stats\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    x_center = aperture_params['x_center']\n",
    "    y_center = aperture_params['y_center']\n",
    "    a = aperture_params['a']\n",
    "    b = aperture_params['b']\n",
    "    theta = aperture_params['theta']    # in radians\n",
    "    \n",
    "    # Create source aperture\n",
    "    source_aperture = EllipticalAperture(\n",
    "        positions=(x_center, y_center),\n",
    "        a=a,\n",
    "        b=b,\n",
    "        theta=theta\n",
    "    )\n",
    "    \n",
    "    # Create mask for the source\n",
    "    source_mask = source_aperture.to_mask(method='center').to_image(image_data.shape)\n",
    "    source_mask_bool = source_mask.astype(bool)\n",
    "    \n",
    "    # Apply initial source mask to the data\n",
    "    masked_data = np.copy(image_data)\n",
    "    masked_data[source_mask_bool] = np.nan\n",
    "    \n",
    "    # Apply sigma clipping to the remaining background\n",
    "    sigma_clip = SigmaClip(sigma=sigma)\n",
    "    clipped_data = sigma_clip(masked_data)\n",
    "    \n",
    "    # Create a mask for sigma-clipped pixels (clipped_data.mask is True for clipped values)\n",
    "    sigma_clipped_mask = clipped_data.mask if hasattr(clipped_data, 'mask') else np.isnan(clipped_data)\n",
    "    \n",
    "    # Create a global mask for all valid background pixels (not in source, not sigma-clipped)\n",
    "    global_mask = ~source_mask_bool & ~np.isnan(image_data) & ~sigma_clipped_mask\n",
    "    \n",
    "    # Define indices for the full image\n",
    "    y, x = np.indices(image_data.shape)\n",
    "    \n",
    "    # Extract coordinates and values of all valid background pixels for global fitting\n",
    "    x_vals = x[global_mask].flatten()\n",
    "    y_vals = y[global_mask].flatten()\n",
    "    z_vals = image_data[global_mask].flatten()\n",
    "    \n",
    "    # Check if we have enough pixels for fitting\n",
    "    if len(z_vals) < 3:\n",
    "        raise ValueError(\"Not enough background pixels for fitting. Try adjusting parameters.\")\n",
    "    \n",
    "    # Fit a 2D plane (ax + by + c) to all valid background pixels\n",
    "    A = np.vstack([x_vals, y_vals, np.ones_like(x_vals)]).T\n",
    "    coeffs, residuals, rank, s = np.linalg.lstsq(A, z_vals, rcond=None)\n",
    "    alpha, beta, gamma = coeffs\n",
    "    \n",
    "    # Create the 2D background plane for the entire image\n",
    "    background_plane = alpha * x + beta * y + gamma\n",
    "    \n",
    "    # Define the background region\n",
    "    region_name = \"Annulus\"\n",
    "    \n",
    "    # Set minimum and maximum sizes for the annulus\n",
    "    min_pixels = 300  # Minimum number of pixels in the annulus for reliable background estimation\n",
    "    max_annulus_size = 35  # Roughly half of the 75x75 image size for large apertures\n",
    "    step_factor = 0.15  # Step size for expanding the annulus\n",
    "    max_attempts = 10\n",
    "    attempt = 0\n",
    "    \n",
    "    # Start with a slightly larger annulus than the source aperture\n",
    "    a_in = a * 2\n",
    "    b_in = b * 2\n",
    "    a_out = a_in * annulus_factor\n",
    "    b_out = b_in * annulus_factor\n",
    "    \n",
    "    if galaxy_id in ['12020', '17669', '7136']:\n",
    "        a_in *= 1.2\n",
    "        b_in *= 1.2\n",
    "        a_out *= 1.3\n",
    "        b_out *= 1.3\n",
    "    if galaxy_id in ['9871', '11136', '11137', '11494', '12340', '12717', '17793', '16874', '17517', '20397']:\n",
    "        a_out *= 0.7\n",
    "        b_out *= 0.7\n",
    "    \n",
    "    # Adjust the outer size until the annulus contains enough pixels\n",
    "    while attempt < max_attempts:\n",
    "        # Create the annulus\n",
    "        annulus = EllipticalAnnulus(\n",
    "            positions=(x_center, y_center),\n",
    "            a_in=a_in,\n",
    "            b_in=b_in,\n",
    "            a_out=min(a_out, max_annulus_size),\n",
    "            b_out=min(b_out, max_annulus_size),\n",
    "            theta=theta\n",
    "        )\n",
    "        \n",
    "        # Create mask for the annulus region\n",
    "        annulus_mask = annulus.to_mask(method='center').to_image(image_data.shape)\n",
    "        background_region_mask = annulus_mask.astype(bool) & ~np.isnan(image_data)\n",
    "        pixel_count = np.sum(background_region_mask)\n",
    "\n",
    "        # If the annulus has enough pixels, break the loop\n",
    "        if pixel_count >= min_pixels:\n",
    "            break\n",
    "        \n",
    "        # Expand the annulus for the next attempt\n",
    "        a_out += a_in * step_factor\n",
    "        b_out += b_in * step_factor\n",
    "        attempt += 1\n",
    "        \n",
    "    \n",
    "    # Gather all the pixels within the background region that were NOT sigma-clipped\n",
    "    bkg_region_valid_pixels = ~sigma_clipped_mask & background_region_mask\n",
    "    residual_data = image_data - background_plane\n",
    "    num_valid_pixels = np.sum(bkg_region_valid_pixels)\n",
    "    \n",
    "    # Calculate background statistics\n",
    "    background_residuals = residual_data[bkg_region_valid_pixels]\n",
    "    background_std = np.std(background_residuals) * np.sqrt(num_valid_pixels)\n",
    "    \n",
    "    # Extract background plane values for the background region and calculate the median\n",
    "    bkg_plane_values = background_plane[background_region_mask]\n",
    "    background_median = np.median(bkg_plane_values)\n",
    "    \n",
    "    # Print background statistics\n",
    "    print(f\"Background Statistics:\")\n",
    "    print(f\"  Global 2D Plane coefficients: a={alpha:.6e}, b={beta:.6e}, c={gamma:.6f}\")\n",
    "    print(f\"  {region_name} region background median: {background_median:.6f}\")\n",
    "    print(f\"  {region_name} region background std dev: {background_std:.6f}\")\n",
    "    \n",
    "    # Create a mask visualisation\n",
    "    mask_vis = np.zeros_like(image_data, dtype=int)\n",
    "    mask_vis[~sigma_clipped_mask] = 1  # Pixels excluded by sigma clipping\n",
    "    mask_vis[background_region_mask] = 2  # Pixels in the annulus/rectangle\n",
    "    mask_vis[source_mask_bool] = 3  # Source pixels\n",
    "    \n",
    "    # Store visualization data\n",
    "    vis_data = {\n",
    "        'galaxy_id': galaxy_id,\n",
    "        'filter': filter_name,\n",
    "        'original_data': image_data,\n",
    "        'background_plane': background_plane,\n",
    "        'background_subtracted': residual_data,\n",
    "        'mask_vis': mask_vis,\n",
    "        'sigma_clipped_mask': sigma_clipped_mask,\n",
    "        'background_region_mask': background_region_mask,\n",
    "        'source_mask': source_mask_bool,\n",
    "        'aperture_params': aperture_params,\n",
    "        'a_in': a_in,\n",
    "        'b_in': b_in,\n",
    "        'a_out': a_out,\n",
    "        'b_out': b_out,\n",
    "        'sigma': sigma,\n",
    "        'region_name': region_name,\n",
    "        'coeffs': (alpha, beta, gamma)\n",
    "    }\n",
    "    \n",
    "    # If requested, visualize the results\n",
    "    if fig_path:\n",
    "        visualise_background(vis_data, fig_path=fig_path)\n",
    "    \n",
    "    return background_median, background_std\n",
    "\n",
    "\n",
    "\n",
    "def visualise_background(vis_data, fig_path=None):\n",
    "    \"\"\"\n",
    "    Create visualisations from the background estimation data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    vis_data : dict\n",
    "        Dictionary containing all data needed for visualisation\n",
    "    fig_path : str, optional\n",
    "        Path to save the visualisation figure\n",
    "    \"\"\"\n",
    "    # Extract data from the dictionary\n",
    "    image_data = vis_data['original_data']\n",
    "    background_plane = vis_data['background_plane']\n",
    "    background_subtracted = vis_data['background_subtracted']\n",
    "    mask_vis = vis_data['mask_vis']\n",
    "    aperture_params = vis_data['aperture_params']\n",
    "    sigma = vis_data['sigma']\n",
    "    region_name = vis_data['region_name']\n",
    "    galaxy_id = vis_data['galaxy_id']\n",
    "    filter = vis_data['filter']\n",
    "    \n",
    "    # Create aperture objects for plotting\n",
    "    x_center = aperture_params['x_center']\n",
    "    y_center = aperture_params['y_center']\n",
    "    a = aperture_params['a']\n",
    "    b = aperture_params['b']\n",
    "    theta = aperture_params['theta']\n",
    "    \n",
    "    source_aperture = EllipticalAperture(\n",
    "        positions=(x_center, y_center),\n",
    "        a=a,\n",
    "        b=b,\n",
    "        theta=theta\n",
    "    )\n",
    "    \n",
    "    # Create visualisations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    \n",
    "    # Original data with aperture\n",
    "    vmin = np.nanpercentile(image_data, 5)\n",
    "    vmax = np.nanpercentile(image_data, 95)\n",
    "    \n",
    "    im0 = axes[0, 0].imshow(image_data, origin='lower', cmap='magma', vmin=vmin, vmax=vmax)\n",
    "    plt.colorbar(im0, ax=axes[0, 0], label='Flux [MJy/(sr pixel)]')\n",
    "    \n",
    "    # Plot the source aperture\n",
    "    source_aperture.plot(ax=axes[0, 0], color='red', lw=1.5)\n",
    "    \n",
    "    # Plot the background region\n",
    "    annulus = EllipticalAnnulus(\n",
    "        positions=(x_center, y_center),\n",
    "        a_in  = vis_data['a_in'],\n",
    "        b_in  = vis_data['b_in'],\n",
    "        a_out = vis_data['a_out'],\n",
    "        b_out = vis_data['b_out'],\n",
    "        theta = theta\n",
    "    )\n",
    "    annulus.plot(ax=axes[0, 0], color='white', lw=1.5)\n",
    "        \n",
    "    axes[0, 0].set_title(\"Original Data with Aperture and Annulus\")\n",
    "    \n",
    "    # Background-subtracted data\n",
    "    vmin2 = np.nanpercentile(background_subtracted, 5)\n",
    "    vmax2 = np.nanpercentile(background_subtracted, 95)\n",
    "    \n",
    "    im1 = axes[0, 1].imshow(background_subtracted, origin='lower', cmap='magma', vmin=vmin2, vmax=vmax2)\n",
    "    plt.colorbar(im1, ax=axes[0, 1], label='Background-subtracted Flux [MJy/(sr pixel)]')\n",
    "    source_aperture.plot(ax=axes[0, 1], color='red', lw=1.5)\n",
    "    axes[0, 1].set_title(\"Background-subtracted Data with Aperture\")\n",
    "    \n",
    "    # Global 2D background plane\n",
    "    im2 = axes[1, 0].imshow(background_plane, origin='lower', cmap='viridis')\n",
    "    plt.colorbar(im2, ax=axes[1, 0], label='Background Flux [MJy/(sr pixel)')\n",
    "    axes[1, 0].set_title(\"Global 2D Background Plane\")\n",
    "        \n",
    "    # Mask visualisation\n",
    "    cmap = plt.cm.get_cmap('viridis', 4)\n",
    "    im3 = axes[1, 1].imshow(mask_vis, origin='lower', cmap=cmap, vmin=-0.5, vmax=3.5)\n",
    "    cbar = plt.colorbar(im3, ax=axes[1, 1], ticks=[0, 1, 2, 3])\n",
    "    cbar.set_ticklabels([f'Excluded\\n(Ï={sigma})', 'Used for fitting', \n",
    "                         f'{region_name} region', 'Source'])\n",
    "    axes[1, 1].set_title(\"Pixel Masks\")\n",
    "    \n",
    "    fig.suptitle(f'{filter}', fontsize=18)#, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if fig_path:\n",
    "        os.makedirs(fig_path, exist_ok=True)\n",
    "        if filter == 'F1800W':\n",
    "            filepath = os.path.join(fig_path, f'{galaxy_id}_{filter}.png')\n",
    "        else: \n",
    "            filepath = os.path.join(fig_path, f'{galaxy_id}.png')\n",
    "        plt.savefig(filepath, dpi=150)\n",
    "        plt.close(fig)\n",
    "\n",
    "def get_psf(filter_name, psf_dir='/home/bpc/University/master/Red_Cardinal/WebbPSF/'):\n",
    "    \"\"\"\n",
    "    Read MIRI PSF file for the specified filter.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filter_name : str\n",
    "        Name of the filter\n",
    "    psf_dir : str\n",
    "        Directory containing PSF files\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    psf_data : ndarray\n",
    "        PSF data\n",
    "    \"\"\"\n",
    "    psf_file = os.path.join(psf_dir, f'PSF_MIRI_{filter_name}.fits')    \n",
    "    with fits.open(psf_file) as psf:\n",
    "        return psf[0].data\n",
    "\n",
    "def get_aperture_params(galaxy_id, aperture_table):\n",
    "    \"\"\"\n",
    "    Retrieve aperture parameters from the CSV table.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    galaxy_id : str\n",
    "        ID of the galaxy\n",
    "    aperture_table : str\n",
    "        Path to CSV table with aperture parameters\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with aperture parameters\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(aperture_table)\n",
    "    row = df[df['ID'] == int(galaxy_id)].iloc[0]\n",
    "    \n",
    "    return {\n",
    "        'x_center': row['Apr_Xcenter'],\n",
    "        'y_center': row['Apr_Ycenter'], \n",
    "        'a': row['Apr_A'] / 2,  # Converting diameter to radius\n",
    "        'b': row['Apr_B'] / 2,  # Converting diameter to radius\n",
    "        'theta': (row['Apr_Theta'] * u.deg).to_value(u.rad)  # Convert to radians\n",
    "    }\n",
    "\n",
    "def calculate_aperture_correction(psf_data, aperture_params):\n",
    "    \"\"\"\n",
    "    Calculate aperture correction factor for given PSF and aperture.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    psf_data : ndarray\n",
    "        PSF data\n",
    "    aperture_params : dict\n",
    "        Aperture parameters\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    correction_factor : float\n",
    "        Aperture correction factor\n",
    "    \"\"\"\n",
    "    aperture = EllipticalAperture(\n",
    "        positions=(psf_data.shape[1] / 2, psf_data.shape[0] / 2),\n",
    "        a=aperture_params['a'],\n",
    "        b=aperture_params['b'],\n",
    "        theta=aperture_params['theta']\n",
    "    )\n",
    "    total_flux = np.sum(psf_data)\n",
    "    phot_table = aperture_photometry(psf_data, aperture)\n",
    "    flux_in_aperture = phot_table['aperture_sum'][0]\n",
    "    return total_flux / flux_in_aperture\n",
    "\n",
    "def measure_flux(image_data, error_map, background_median, background_std, aperture_params):\n",
    "    \"\"\"\n",
    "    Calculate flux and uncertainty from aperture photometry.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_data : ndarray\n",
    "        Image data\n",
    "    background_median : float\n",
    "        Median background level\n",
    "    error_map : ndarray\n",
    "        Error map data\n",
    "    background_std : float\n",
    "        Standard deviation of background\n",
    "    aperture_params : dict\n",
    "        Aperture parameters\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with flux measurements and uncertainties\n",
    "    \"\"\"\n",
    "    # Subtract the median background value within the annulus from the data\n",
    "    data_bkgsub = image_data - background_median\n",
    "    \n",
    "    # Create aperture\n",
    "    aperture = EllipticalAperture(\n",
    "        positions=(aperture_params['x_center'], aperture_params['y_center']),\n",
    "        a=aperture_params['a'],\n",
    "        b=aperture_params['b'],\n",
    "        theta=aperture_params['theta']\n",
    "    )\n",
    "    \n",
    "    # Sum flux within the aperture - baclground subtracted data\n",
    "    phot_table = aperture_photometry(data_bkgsub, aperture, method='exact')\n",
    "    flux = phot_table['aperture_sum'][0]    # in MJy/sr\n",
    "    \n",
    "    # Mask for aperture\n",
    "    aperture_mask = aperture.to_mask(method='exact')\n",
    "    mask = aperture_mask.to_image(data_bkgsub.shape)\n",
    "    \n",
    "    # Flux uncertainty from ERR extension\n",
    "    image_errors = error_map * mask\n",
    "    sum_image_errors = np.sqrt(np.sum(image_errors**2))\n",
    "    \n",
    "    # Number of pixels within the aperture\n",
    "    n_pix = aperture.area\n",
    "    \n",
    "    # To obtain the background flux within the aperture we multiply the median background within the annulus\n",
    "    # by the number of pixels within the aperture    \n",
    "    background_flux = n_pix * background_median\n",
    "    \n",
    "    # Total flux uncertainty\n",
    "    total_flux_error = np.sqrt(sum_image_errors**2 + background_std**2)\n",
    "    \n",
    "    # Median error of the error map within the aperture\n",
    "    median_error = np.median(error_map[mask>0])    \n",
    "    \n",
    "    # Convert everything to from MJy/sr to Jy\n",
    "    miri_scale = 0.11092  # arcsec per pixel\n",
    "    miri_scale_rad = miri_scale / 206265\n",
    "    omega_pix = miri_scale_rad**2\n",
    "    conversion_factor = 1e6 * omega_pix\n",
    "    \n",
    "    # Now everything is in Jy!!\n",
    "    return {\n",
    "        'flux': flux * conversion_factor,\n",
    "        'flux_error': total_flux_error * conversion_factor,\n",
    "        'background_flux': background_flux * conversion_factor,\n",
    "        'median_error': median_error * conversion_factor,\n",
    "        'pixel_count': n_pix\n",
    "    }\n",
    "\n",
    "# --- Main Loop ---\n",
    "\n",
    "def perform_photometry(cutout_files, aperture_table, output_folder, psf_data=None):\n",
    "    \"\"\"\n",
    "    Main function to perform photometry on a list of cutout files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cutout_files : list\n",
    "        List of paths to cutout FITS files\n",
    "    aperture_table : str\n",
    "        Path to CSV table with aperture parameters\n",
    "    output_folder : str\n",
    "        Path to output folder\n",
    "    psf_dir : str, optional\n",
    "        Directory containing PSF files\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for fits_path in cutout_files:\n",
    "        # Extract ID and filter from filename\n",
    "        fits_name = os.path.basename(fits_path)\n",
    "        galaxy_id = fits_name.split('_')[0]\n",
    "        filter_name = fits_name.split('_')[1]\n",
    "        \n",
    "        print(f'Processing galaxy {galaxy_id} with filter {filter_name}...')\n",
    "        \n",
    "        # Load image data\n",
    "        with fits.open(fits_path) as hdul:\n",
    "            image_data = hdul['SCI'].data if 'SCI' in hdul else hdul[1].data\n",
    "            image_error = hdul['ERR'].data if 'ERR' in hdul else hdul[2].data\n",
    "            \n",
    "        # Get aperture parameters\n",
    "        aperture_params = get_aperture_params(galaxy_id, aperture_table)\n",
    "        \n",
    "        # Set sigma-clipping threshold based on galaxy ID and filter\n",
    "        sigma = 2.8  # Default value\n",
    "        \n",
    "        # Special cases for certain galaxies\n",
    "        if galaxy_id in ['12332', '12282', '10314', '12164', '18332', '21452', '21477', \n",
    "                        '21541', '22606', '10592', '11136', '11142', '11420', '11451', \n",
    "                        '11494', '11716', '13103', '16419', '19042']:\n",
    "            sigma = 2.0\n",
    "            \n",
    "        # Additional adjustments for F770W filter\n",
    "        if filter_name == 'F770W' and galaxy_id in ['7136', '7904', '7922', '8469', '11716', \n",
    "                                                   '16424', '17000', '17669', '11137']:\n",
    "            sigma = 2.0\n",
    "        \n",
    "        # Setup paths for visualisation\n",
    "        #vis_path = os.path.join(output_folder, 'mosaic_fits')\n",
    "        #os.makedirs(vis_path, exist_ok=True)\n",
    "        \n",
    "        fig_path = os.path.join(output_folder, 'mosaic_plots')\n",
    "        os.makedirs(fig_path, exist_ok=True)\n",
    "        \n",
    "        # Estimate background with 2D-plane fit\n",
    "        background_median, background_std = estimate_background(\n",
    "            galaxy_id, \n",
    "            filter_name, \n",
    "            image_data, \n",
    "            aperture_params,\n",
    "            sigma=sigma, \n",
    "            annulus_factor=3.0, \n",
    "            fig_path=fig_path\n",
    "        )                                                                   \n",
    "        \n",
    "        # Measure flux\n",
    "        flux_measurements = measure_flux(\n",
    "            image_data, \n",
    "            image_error,\n",
    "            background_median,  \n",
    "            background_std, \n",
    "            aperture_params\n",
    "        )\n",
    "\n",
    "        # Get PSF and calculate aperture correction\n",
    "        correction_factor = calculate_aperture_correction(psf_data, aperture_params)\n",
    "\n",
    "        # Apply aperture correction\n",
    "        corrected_flux = flux_measurements['flux'] * correction_factor\n",
    "        corrected_flux_error = flux_measurements['flux_error'] * correction_factor\n",
    "        corrected_background_flux = flux_measurements['background_flux'] * correction_factor\n",
    "        corrected_background_error = background_std * correction_factor\n",
    "        \n",
    "        # --- Convert fluxes into AB magnitudes ---\n",
    "        if corrected_flux > 0:\n",
    "            ab_mag = -2.5 * np.log10(corrected_flux) + 8.90\n",
    "        else: ab_mag = np.nan\n",
    "        \n",
    "        # Append results\n",
    "        results.append({\n",
    "            'ID': int(galaxy_id),\n",
    "            'Flux': corrected_flux,\n",
    "            'Flux_Err': corrected_flux_error,\n",
    "            'Image_Err': flux_measurements['median_error'] * correction_factor,\n",
    "            'Flux_BKG': corrected_background_flux,\n",
    "            'Flux_BKG_Err': corrected_background_error,\n",
    "            'AB_Mag': ab_mag,\n",
    "            'N_PIX': flux_measurements['pixel_count'],\n",
    "            'Apr_A': aperture_params['a'] * 2,  # Convert back to diameter for output\n",
    "            'Apr_B': aperture_params['b'] * 2,  # Convert back to diameter for output\n",
    "            'Apr_Xcenter': aperture_params['x_center'],\n",
    "            'Apr_Ycenter': aperture_params['y_center'],\n",
    "            'Apr_Theta': (aperture_params['theta'] * u.rad).to_value(u.deg)  # Convert to degrees for output\n",
    "        })\n",
    "    \n",
    "    # Save to output table (assuming it's a pandas DataFrame)\n",
    "    os.makedirs(os.path.join(output_folder, 'results'), exist_ok=True)\n",
    "    output_path = os.path.join(output_folder, f'results/photometry_table_{filter_name}.csv')\n",
    "    output_df = pd.DataFrame(results)\n",
    "    output_df.to_csv(output_path, index=False)\n",
    "    \n",
    "def combine_figures(fig_path='/home/bpc/University/master/Red_Cardinal/photometry/mosaic_plots/'):\n",
    "    \"\"\"Function that scans a directory for plots in different filters and\n",
    "       combines them if available.   \n",
    "    \"\"\"\n",
    "    print(f\"Scanning {fig_path} for galaxy images to combine...\")\n",
    "\n",
    "    # Get all F1800W images\n",
    "    f1800w_pngs = glob.glob(os.path.join(fig_path, '*_F1800W.png'))\n",
    "\n",
    "    # Track how many images we've combined\n",
    "    combined_count = 0\n",
    "\n",
    "    for f1800w_png in f1800w_pngs:\n",
    "        # Extract galaxy ID from filename\n",
    "        galaxy_id = os.path.basename(f1800w_png).replace('_F1800W.png', '')\n",
    "        f770w_png = os.path.join(fig_path, f'{galaxy_id}.png')\n",
    "        \n",
    "        # Check if the standard file exists\n",
    "        if os.path.exists(f770w_png):\n",
    "            try:\n",
    "                # Open both images\n",
    "                img_f770w = Image.open(f770w_png)\n",
    "                img_f1800w = Image.open(f1800w_png)\n",
    "                \n",
    "                # Get dimensions\n",
    "                width1, height1 = img_f770w.size\n",
    "                width2, height2 = img_f1800w.size\n",
    "                \n",
    "                # Create a new image with enough width for both images\n",
    "                combined_width = width1 + width2\n",
    "                combined_height = max(height1, height2)\n",
    "                combined_img = Image.new('RGB', (combined_width, combined_height), (255, 255, 255))\n",
    "                \n",
    "                # Paste both images\n",
    "                combined_img.paste(img_f770w, (0, 0))\n",
    "                combined_img.paste(img_f1800w, (width1, 0))\n",
    "                \n",
    "                # Save combined image\n",
    "                save_png = os.path.join(fig_path, f'{galaxy_id}.png')\n",
    "                combined_img.save(save_png)\n",
    "                \n",
    "                # Delete the F1800W file\n",
    "                os.remove(f1800w_png)\n",
    "                \n",
    "                combined_count += 1\n",
    "                print(f\"Combined images for galaxy {galaxy_id}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error combining images for galaxy {galaxy_id}: {e}\")\n",
    "\n",
    "    print(f\"Combined {combined_count} galaxy image pairs.\")\n",
    "\n",
    "    # Check if any F1800W images remain (no matching F770W image)\n",
    "    remaining_f1800w = glob.glob(os.path.join(fig_path, '*_F1800W.png'))\n",
    "    if remaining_f1800w:\n",
    "        print(f\"Note: {len(remaining_f1800w)} F1800W images have no matching standard image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the code should be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = ['8465', '7922', '9871', '12202', '8843', '7904', '8338', '10021', '10245', '11136', '12340', '20397']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters ---\n",
    "cutouts_folder = \"/home/bpc/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "output_folder = '/home/bpc/University/master/Red_Cardinal/photometry/'\n",
    "aperture_table = '/home/bpc/University/master/Red_Cardinal/photometry/aperture_table_rot.csv'\n",
    "fig_path = '/home/bpc/University/master/Red_Cardinal/photometry/Plots_MIRI_phot/'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get all possible F770W files\n",
    "all_f770w_files = glob.glob(os.path.join(cutouts_folder, f'*F770W*.fits'))\n",
    "\n",
    "# Group F770W files by galaxy ID and filter\n",
    "f770w_files = []\n",
    "galaxy_ids = set([os.path.basename(f).split('_')[0] for f in all_f770w_files])\n",
    "\n",
    "for galaxy_id in galaxy_ids:\n",
    "    # Find all F770W files for this galaxy ID\n",
    "    matching_files = [f for f in all_f770w_files if os.path.basename(f).startswith(galaxy_id)]\n",
    "    \n",
    "    # Handle special case for galaxy 11853\n",
    "    if galaxy_id == '11853':\n",
    "        # Use the cweb2 file if available\n",
    "        cweb2_files = [f for f in matching_files if 'cweb2' in f.lower()]\n",
    "        if cweb2_files:\n",
    "            f770w_files.append(cweb2_files[0])\n",
    "            continue  # Skip to the next galaxy\n",
    "    \n",
    "    # Prioritise PRIMER over COSMOS-Web\n",
    "    primer_files = [f for f in matching_files if 'primer' in f.lower()]\n",
    "    cweb_files = [f for f in matching_files if 'cweb' in f.lower()]\n",
    "    \n",
    "    if primer_files:\n",
    "        f770w_files.append(primer_files[0])  # Prefer PRIMER file\n",
    "    elif cweb_files:\n",
    "        f770w_files.append(cweb_files[0])  # Use CWEB only if no PRIMER available\n",
    "\n",
    "# Get all F1800W files\n",
    "f1800w_files = glob.glob(os.path.join(cutouts_folder, f'*F1800W*.fits'))\n",
    "\n",
    "psf_f770w = get_psf('F770W')\n",
    "psf_f1800w = get_psf('F1800W')\n",
    "\n",
    "perform_photometry(f770w_files, aperture_table, output_folder, psf_f770w)\n",
    "perform_photometry(f1800w_files, aperture_table, output_folder, psf_f1800w)\n",
    "\n",
    "combine_figures(fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce the table with the photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the contents of the original FITS files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = './../cutouts/7102_F770W_cutout_cweb1.fits'\n",
    "#with fits.open(fname) as hdul:\n",
    "    #hdul.info()\n",
    "\n",
    "\n",
    "fname = './../MIRI/PRIMER_003/jw01837-o003_t003_miri_f770w_i2d.fits'\n",
    "with fits.open(fname) as hdul:\n",
    "    hdul.info()\n",
    "\n",
    "fname = './../MIRI_shifted/PRIMER_003_shifted/jw01837-o003_t003_miri_f770w_i2d_shifted.fits'\n",
    "with fits.open(fname) as hdul:\n",
    "    hdul.info()\n",
    "              \n",
    "    \n",
    "fname = './../photometry/mosaic_fits/11136_F770W.fits'\n",
    "with fits.open(fname) as hdul:\n",
    "    hdul.info()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
