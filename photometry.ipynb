{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photometry on MIRI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import subprocess\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS, FITSFixedWarning\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "from astropy.stats import SigmaClip\n",
    "from astropy.visualization import ZScaleInterval\n",
    "\n",
    "from photutils.aperture import EllipticalAperture, EllipticalAnnulus, RectangularAperture, aperture_photometry\n",
    "from photutils.background import Background2D, MedianBackground\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=FITSFixedWarning)\n",
    "\n",
    "\n",
    "cutout_dir = \"/home/bpc/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "phot_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section to obtain modified apertures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect Amirs table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path =  '/home/bpc/University/master/Red_Cardinal/Flux_Aperture_PSFMatched_AperCorr_old.fits'\n",
    "\n",
    "table = Table.read(table_path)\n",
    "#print(table[:5])\n",
    "table.info()\n",
    "print(table.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's choose a galaxy, read its aperture data and overplot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cutout(file_path, index=1):\n",
    "    \"\"\"Loads a FITS cutout file and extracts the data, header, and WCS.\"\"\"\n",
    "    try:\n",
    "        with fits.open(file_path) as hdu:\n",
    "            data = hdu[index].data\n",
    "            header = hdu[index].header\n",
    "            wcs = WCS(header)\n",
    "        return data, wcs\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None, None\n",
    "\n",
    "def adjust_aperture(galaxy_id, filter, survey, obs, output_folder, save_plot=False):\n",
    "    \n",
    "    # --- Load the FITS table ---\n",
    "    #table_path =  '/home/bpc/University/master/Red_Cardinal/Flux_Aperture_PSFMatched_AperCorr_old.fits'\n",
    "    #aperture_table = Table.read(table_path)\n",
    "    table_path =  '/home/bpc/University/master/Red_Cardinal/aperture_table.csv'\n",
    "    df = pd.read_csv(table_path)\n",
    "    \n",
    "    # --- Select the galaxy by ID ---\n",
    "    #row = aperture_table[aperture_table['ID'] == galaxy_id][0]\n",
    "    galaxy_id = int(galaxy_id)\n",
    "    row = df[df['ID'] == galaxy_id].iloc[0]\n",
    "\n",
    "    # --- Read in rotation angle of MIRI FITS file ---\n",
    "    angle_file = '/home/bpc/University/master/Red_Cardinal/rotation_angles.json'\n",
    "    with open(angle_file, \"r\") as f:\n",
    "        angles = json.load(f)\n",
    "    angle = angles[f\"angle_{survey}{obs}\"]\n",
    "    \n",
    "    # --- Read WCS from NIRCam image ---\n",
    "    nircam_path = f\"/home/bpc/University/master/Red_Cardinal/NIRCam/F444W_cutouts/{galaxy_id}_F444W_cutout.fits\"\n",
    "    nircam_data, nircam_wcs = load_cutout(nircam_path)\n",
    "\n",
    "    # --- Convert NIRCam pixel coordinates to sky ---\n",
    "    sky_coord = nircam_wcs.pixel_to_world(row['Apr_Xcenter'], row['Apr_Ycenter'])\n",
    "    \n",
    "    # --- Open MIRI cutout image ---\n",
    "    miri_path = f\"/home/bpc/University/master/Red_Cardinal/cutouts_phot/{galaxy_id}_{filter}_cutout_{survey}{obs}.fits\"\n",
    "    miri_data, miri_wcs = load_cutout(miri_path)\n",
    "\n",
    "    # --- Convert sky coords to MIRI pixel coordinates ---\n",
    "    miri_x, miri_y = miri_wcs.world_to_pixel(sky_coord)\n",
    "\n",
    "    # --- Create elliptical region in MIRI pixel space ---\n",
    "    nircam_scale = 0.03    # arcsec/pixel\n",
    "    miri_scale = 0.11092  # arcsec per pixel\n",
    "    \n",
    "    # arcsec/pixel\n",
    "    scale_factor = nircam_scale / miri_scale\n",
    "    \n",
    "    # --- Specify parameters for the ellips ---\n",
    "    width = row['Apr_A'] * scale_factor\n",
    "    height = row['Apr_B'] * scale_factor\n",
    "    theta = -row['Apr_Theta']\n",
    "    theta_new = ((theta - angle) % 180) * u.deg\n",
    "    \n",
    "    # --- Create region file and check if folder exists ---\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    reg_file = os.path.join(output_folder, f'regions/{galaxy_id}_{survey}{obs}_aperture.reg') \n",
    "    \n",
    "    # --- Write to DS9-compatible region file ---\n",
    "    with open(reg_file, \"w\") as fh:\n",
    "        fh.write(\"# Region file format: DS9 version 4.1\\n\")\n",
    "        fh.write(\"global color=red dashlist=8 3 width=2 font=\\\"helvetica 10 normal\\\" \"\n",
    "                \"select=1 highlite=1 dash=0 fixed=0 edit=1 move=1 delete=1 include=1 source=1\\n\")\n",
    "        fh.write(\"image\\n\")\n",
    "        fh.write(f\"ellipse({miri_x:.2f},{miri_y:.2f},{width:.2f},{height:.2f},{theta_new:.2f})\\n\")\n",
    "    \n",
    "    if save_plot:\n",
    "        \n",
    "        # --- Clean and prepare the MIRI data for plotting ---\n",
    "        miri_clean = np.copy(miri_data)\n",
    "        finite_vals = miri_clean[np.isfinite(miri_clean)].flatten()\n",
    "        \n",
    "        # Sort and get lowest 80% values\n",
    "        sorted_vals = np.sort(finite_vals)\n",
    "        cutoff_index = int(0.8 * len(sorted_vals))\n",
    "        background_vals = sorted_vals[:cutoff_index]\n",
    "        background_mean = np.mean(background_vals)\n",
    "\n",
    "        # Replace NaNs or infs with background mean\n",
    "        miri_clean[~np.isfinite(miri_clean)] = background_mean\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6,6))\n",
    "        ax.imshow(miri_clean, origin='lower', cmap='gray', vmin=np.percentile(miri_clean, 5), vmax=np.percentile(miri_clean, 99))\n",
    "\n",
    "        # Original ellipse (without rotation correction)\n",
    "        ellipse_original = Ellipse(\n",
    "            xy=(miri_x, miri_y),\n",
    "            width=width,\n",
    "            height=height,\n",
    "            angle=theta,  # Just the original Î¸!\n",
    "            edgecolor='red',\n",
    "            facecolor='none',\n",
    "            lw=2,\n",
    "            label='Original Ellipse'\n",
    "        )\n",
    "        ax.add_patch(ellipse_original)\n",
    "\n",
    "        ellipse = Ellipse(\n",
    "            xy=(miri_x, miri_y),\n",
    "            width=width,\n",
    "            height=height,\n",
    "            angle=theta_new.to_value(u.deg),\n",
    "            edgecolor='blue',\n",
    "            linestyle='--',  # maybe dashed to differentiate\n",
    "            facecolor='none',\n",
    "            lw=2,\n",
    "            label='Rotated Ellipse'\n",
    "        )\n",
    "        ax.add_patch(ellipse)\n",
    "        \n",
    "        ax.set_title(f\"Galaxy {galaxy_id} - {filter} ({survey}{obs})\")\n",
    "        ax.set_xlim(miri_x - 30, miri_x + 30)\n",
    "        ax.set_ylim(miri_y - 30, miri_y + 30)\n",
    "        ax.legend(loc='upper right')\n",
    "        \n",
    "        # Save figure\n",
    "        png_path = os.path.join(output_folder, f'masks/{galaxy_id}_{survey}{obs}_aperture_overlay.png')\n",
    "        plt.savefig(png_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        \n",
    "    # Collect modified aperture data\n",
    "    aperture_info = {          \n",
    "    'Apr_A': width,            # Rescaled aperture\n",
    "    'Apr_B': height,\n",
    "    'Apr_Xcenter': miri_x,\n",
    "    'Apr_Ycenter': miri_y,\n",
    "    'Apr_Theta': theta_new.to_value(u.deg),\n",
    "    'ID': galaxy_id\n",
    "    }\n",
    "    \n",
    "    return aperture_info\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and call the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_dir = \"/home/bpc/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "phot_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/\"\n",
    "\n",
    "# Get all FITS file paths\n",
    "fits_files = glob.glob(os.path.join(cutout_dir, '*.fits'))\n",
    "\n",
    "# Get the basenames of the FITS files\n",
    "fits_fnames = [os.path.basename(f) for f in fits_files]\n",
    "\n",
    "adjusted_apertures = []\n",
    "\n",
    "for fname in fits_fnames:\n",
    "    id = fname.split('_')[0]\n",
    "    filter = fname.split('_')[1]\n",
    "    if filter == 'F1800W': continue\n",
    "    survey_obs = fname.split('_')[3]\n",
    "    if '003' in survey_obs:\n",
    "        survey = 'primer'\n",
    "        obs = '003'\n",
    "    elif '004' in survey_obs:\n",
    "        survey = 'primer'\n",
    "        obs = '004'\n",
    "    elif '1' in survey_obs:\n",
    "        survey = 'cweb'\n",
    "        obs = '1'\n",
    "    elif '2' in survey_obs:\n",
    "        survey = 'cweb'\n",
    "        obs = '2'\n",
    "    else:\n",
    "        print(f\"Unknown survey and/or observation number for galaxy {id}:\\n\")\n",
    "        print(survey_obs)\n",
    "    \n",
    "    # Call and collect results\n",
    "    result = adjust_aperture(id, filter, survey, obs, phot_dir, save_plot=False)\n",
    "    if result:\n",
    "        adjusted_apertures.append(result)\n",
    "\n",
    "# After loop: create a DataFrame\n",
    "df_apertures = pd.DataFrame(adjusted_apertures)\n",
    "\n",
    "df_path = '/home/bpc/University/master/Red_Cardinal/photometry/aperture_table_rot.csv'\n",
    "\n",
    "# (optional) Save to CSV or integrate into photometry table\n",
    "df_apertures.to_csv(df_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily open any given FITS file with its corresponding ellipse region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Launch DS9 with the MIRI cutout and the overplotted aperture ---\n",
    "region_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/regions/\"\n",
    "cutout_dir = \"/home/bpc/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "phot_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/\"\n",
    "\n",
    "id = '10245'\n",
    "filter = 'F770W'\n",
    "survey_obs = 'primer004'\n",
    "cutout_path = os.path.join(cutout_dir, f'{id}_{filter}_cutout_{survey_obs}.fits')\n",
    "reg_path = os.path.join(region_dir, f'{id}_{survey_obs}_aperture.reg')\n",
    "subprocess.run([\"ds9\", cutout_path, \"-regions\", reg_path])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path =  '/home/bpc/University/master/Red_Cardinal/Flux_Aperture_PSFMatched_AperCorr_old.fits'\n",
    "\n",
    "table = Table.read(table_path)\n",
    "print(table[:5])\n",
    "table.info()\n",
    "print(table['Image_Err'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is where we do most of the work\n",
    "\n",
    "# Section to perform the actual photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's set some parameters straight:\n",
    "\n",
    "pixscale_arcsec = 0.11092  # arcsec per pixel\n",
    "\n",
    "pix_area_sr = 2.89208962133982e-13  # from MIRI header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_background(galaxy_id, filter, data, aperture_params, sigma=3.0, method='annulus', \n",
    "                   annulus_factor=3.0, box_factor=3.0, fig_path=None):\n",
    "    \"\"\"\n",
    "    Estimate background using a global 2D plane fit, then extract statistics from \n",
    "    either an elliptical annulus or a rectangular box.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    galaxy_id : str\n",
    "        The ID of the galaxy\n",
    "    filter : str\n",
    "        The band which is being observed\n",
    "    data : ndarray\n",
    "        The 2D image data\n",
    "    aperture_params : dict\n",
    "        Dictionary containing aperture parameters (x_center, y_center, a, b, theta)\n",
    "    sigma : float\n",
    "        Sigma clipping threshold\n",
    "    method : str\n",
    "        Method for background region selection ('annulus' or 'box')\n",
    "    annulus_factor : float\n",
    "        Factor by which to scale the inner ellipse to create the outer ellipse\n",
    "    box_factor : float\n",
    "        Factor to determine box size relative to the elliptical aperture\n",
    "    visualise : bool, optional\n",
    "        If True, display visualisation plots\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    - background_plane : ndarray\n",
    "        2D background model\n",
    "    - background_median : float\n",
    "        median background value within the annulus\n",
    "    - background_std : float\n",
    "        standard deviation of background model within the annulus (excluding clipped data)\n",
    "    - background_region_mask : ndarray\n",
    "        boolean mask showing the region used for background stats\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    x_center = aperture_params['x_center']\n",
    "    y_center = aperture_params['y_center']\n",
    "    a = aperture_params['a']\n",
    "    b = aperture_params['b']\n",
    "    theta = aperture_params['theta']    # in radians\n",
    "    \n",
    "    # Create source aperture\n",
    "    source_aperture = EllipticalAperture(\n",
    "        positions=(x_center, y_center),\n",
    "        a=a,\n",
    "        b=b,\n",
    "        theta=theta\n",
    "    )\n",
    "    \n",
    "    # Create mask for the source\n",
    "    source_mask = source_aperture.to_mask(method='center').to_image(data.shape)\n",
    "    source_mask_bool = source_mask.astype(bool)\n",
    "    \n",
    "    # Apply initial source mask to the data\n",
    "    masked_data = np.copy(data)\n",
    "    masked_data[source_mask_bool] = np.nan\n",
    "    \n",
    "    # Apply sigma clipping to the remaining background\n",
    "    sigma_clip = SigmaClip(sigma=sigma)\n",
    "    clipped_data = sigma_clip(masked_data)\n",
    "    \n",
    "    # Create a mask for sigma-clipped pixels (clipped_data.mask is True for clipped values)\n",
    "    sigma_clipped_mask = clipped_data.mask if hasattr(clipped_data, 'mask') else np.isnan(clipped_data)\n",
    "    \n",
    "    # Create a global mask for all valid background pixels (not in source, not sigma-clipped)\n",
    "    global_mask = ~source_mask_bool & ~np.isnan(data) & ~sigma_clipped_mask\n",
    "    \n",
    "    # Define indices for the full image\n",
    "    y, x = np.indices(data.shape)\n",
    "    \n",
    "    # Extract coordinates and values of all valid background pixels for global fitting\n",
    "    x_vals = x[global_mask].flatten()\n",
    "    y_vals = y[global_mask].flatten()\n",
    "    z_vals = data[global_mask].flatten()\n",
    "    \n",
    "    # Check if we have enough pixels for fitting\n",
    "    if len(z_vals) < 3:\n",
    "        raise ValueError(\"Not enough background pixels for fitting. Try adjusting parameters.\")\n",
    "    \n",
    "    # Fit a 2D plane (ax + by + c) to all valid background pixels\n",
    "    A = np.vstack([x_vals, y_vals, np.ones_like(x_vals)]).T\n",
    "    coeffs, residuals, rank, s = np.linalg.lstsq(A, z_vals, rcond=None)\n",
    "    alpha, beta, gamma = coeffs\n",
    "    \n",
    "    # Create the 2D background plane for the entire image\n",
    "    background_plane = alpha * x + beta * y + gamma\n",
    "    \n",
    "    # Define the background region\n",
    "    background_region_mask = None\n",
    "    region_name = None\n",
    "    \n",
    "    if method == 'annulus':\n",
    "        # Set minimum and maximum sizes for the annulus\n",
    "        min_pixels = 300  # Minimum number of pixels in the annulus for reliable background estimation\n",
    "        max_annulus_size = 40  # Roughly half of the 75x75 image size for large apertures\n",
    "        step_factor = 0.15  # Step size for expanding the annulus\n",
    "        max_attempts = 10\n",
    "        attempt = 0\n",
    "        \n",
    "        # Start with a slightly larger annulus than the source aperture\n",
    "        a_in = a * 2\n",
    "        b_in = b * 2\n",
    "        a_out = a_in * annulus_factor\n",
    "        b_out = b_in * annulus_factor\n",
    "        \n",
    "        if galaxy_id in ['12020', '17669', '7136']:\n",
    "            a_in *= 1.2\n",
    "            b_in *= 1.2\n",
    "            a_out *= 1.3\n",
    "            b_out *= 1.3\n",
    "        if galaxy_id in ['9871', '11136', '11137', '11494', '12340', '12717', '17793', '16874', '17517', '20397']:\n",
    "            a_out *= 0.7\n",
    "            b_out *= 0.7\n",
    "        \n",
    "        # Adjust the outer size until the annulus contains enough pixels\n",
    "        while attempt < max_attempts:\n",
    "            # Create the annulus\n",
    "            annulus = EllipticalAnnulus(\n",
    "                positions=(x_center, y_center),\n",
    "                a_in=a_in,\n",
    "                b_in=b_in,\n",
    "                a_out=min(a_out, max_annulus_size),\n",
    "                b_out=min(b_out, max_annulus_size),\n",
    "                theta=theta\n",
    "            )\n",
    "            \n",
    "            # Create mask for the annulus region\n",
    "            annulus_mask = annulus.to_mask(method='center').to_image(data.shape)\n",
    "            background_region_mask = annulus_mask.astype(bool) & ~np.isnan(data)\n",
    "            pixel_count = np.sum(background_region_mask)\n",
    "            region_name = \"Annulus\"\n",
    "            # If the annulus has enough pixels, break the loop\n",
    "            if pixel_count >= min_pixels:\n",
    "                break\n",
    "            \n",
    "            # Expand the annulus for the next attempt\n",
    "            a_out += a_in * step_factor\n",
    "            b_out += b_in * step_factor\n",
    "            attempt += 1\n",
    "            \n",
    "    elif method == 'box':\n",
    "        # Calculate box size based on the elliptical aperture\n",
    "        box_size = max(a, b) * box_factor\n",
    "        \n",
    "        # Create rectangular aperture for background region\n",
    "        box = RectangularAperture(\n",
    "            positions=(x_center, y_center),\n",
    "            w=box_size * 2,  # Width\n",
    "            h=box_size * 2,  # Height\n",
    "            theta=theta\n",
    "        )\n",
    "        \n",
    "        # Create mask for the box region, excluding the source\n",
    "        box_mask = box.to_mask(method='center').to_image(data.shape)\n",
    "        background_region_mask = box_mask.astype(bool) & ~source_mask_bool & ~np.isnan(data)\n",
    "        region_name = \"Box\"\n",
    "    else:\n",
    "        raise ValueError(\"Method must be either 'annulus' or 'box'\")\n",
    "    \n",
    "    # Gather all the pixels within the annulus that were NOT sigma-clipped\n",
    "    bkg_region_mask_clipped = ~sigma_clipped_mask & background_region_mask\n",
    "    data_plane_subtracted = data - background_plane\n",
    "    num_pixels_annulus = np.sum(bkg_region_mask_clipped)\n",
    "    \n",
    "    # The error on the background is the standard deviation of the background subtracted data\n",
    "    # within the annulus times the square root of the number of pixels within the region\n",
    "    background_std = np.std(data_plane_subtracted[bkg_region_mask_clipped]) * np.sqrt(num_pixels_annulus)\n",
    "    \n",
    "    # Extract background plane values for the entire annulus and calculate the median\n",
    "    bkg_plane_values = background_plane[background_region_mask]\n",
    "    background_median = np.median(bkg_plane_values)\n",
    "    \n",
    "    # Print background statistics\n",
    "    print(f\"Background Statistics:\")\n",
    "    print(f\"  Global 2D Plane coefficients: a={alpha:.6e}, b={beta:.6e}, c={gamma:.6f}\")\n",
    "    print(f\"  {region_name} region background median: {background_median:.6f}\")\n",
    "    print(f\"  {region_name} region background std dev: {background_std:.6f}\")\n",
    "    \n",
    "    # Create a mask visualisation\n",
    "    mask_vis = np.zeros_like(data, dtype=int)\n",
    "    mask_vis[~sigma_clipped_mask] = 1  # Pixels excluded by sigma clipping\n",
    "    mask_vis[background_region_mask] = 2  # Pixels in the annulus/rectangle\n",
    "    mask_vis[source_mask_bool] = 3  # Source pixels\n",
    "    \n",
    "    # Background-subtracted data\n",
    "    background_subtracted = data - background_plane\n",
    "    \n",
    "    # Store all necessary data for later visualisation\n",
    "    visualisation_data = {\n",
    "        'galaxy_id': galaxy_id,\n",
    "        'filter': filter,\n",
    "        'original_data': data,\n",
    "        'background_plane': background_plane,\n",
    "        'background_subtracted': background_subtracted,\n",
    "        'mask_vis': mask_vis,\n",
    "        'aperture_params': aperture_params,\n",
    "        'a_out': a_out if method == 'annulus' else box_size*2,\n",
    "        'b_out': b_out if method == 'annulus' else box_size*2,\n",
    "        'sigma': sigma,\n",
    "        'method': method,\n",
    "        'region_name': region_name,\n",
    "        'background_median': background_median,\n",
    "        'background_std': background_std,\n",
    "        'coeffs': (alpha, beta, gamma)\n",
    "    }\n",
    "    \n",
    "    # If requested, visualise the results now\n",
    "    if fig_path:\n",
    "        visualise_background(visualisation_data, fig_path=fig_path)\n",
    "    \n",
    "    return background_plane, background_median, background_std, background_region_mask\n",
    "\n",
    "\n",
    "def visualise_background(vis_data, fig_path=None):\n",
    "    \"\"\"\n",
    "    Create visualisations from the background estimation data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    vis_data : dict\n",
    "        Dictionary containing all data needed for visualisation\n",
    "    \"\"\"\n",
    "    # Extract data from the dictionary\n",
    "    data = vis_data['original_data']\n",
    "    background_plane = vis_data['background_plane']\n",
    "    background_subtracted = vis_data['background_subtracted']\n",
    "    mask_vis = vis_data['mask_vis']\n",
    "    aperture_params = vis_data['aperture_params']\n",
    "    sigma = vis_data['sigma']\n",
    "    region_name = vis_data['region_name']\n",
    "    galaxy_id = vis_data['galaxy_id']\n",
    "    filter = vis_data['filter']\n",
    "    \n",
    "    # Create aperture objects for plotting\n",
    "    x_center = aperture_params['x_center']\n",
    "    y_center = aperture_params['y_center']\n",
    "    a = aperture_params['a']\n",
    "    b = aperture_params['b']\n",
    "    theta = aperture_params['theta']\n",
    "    \n",
    "    source_aperture = EllipticalAperture(\n",
    "        positions=(x_center, y_center),\n",
    "        a=a,\n",
    "        b=b,\n",
    "        theta=theta\n",
    "    )\n",
    "    \n",
    "    # Create visualisations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    \n",
    "    # Original data with aperture\n",
    "    vmin = np.nanpercentile(data, 5)\n",
    "    vmax = np.nanpercentile(data, 95)\n",
    "    \n",
    "    zscale = ZScaleInterval()\n",
    "    #vmin, vmax = zscale.get_limits(data)\n",
    "    \n",
    "    im0 = axes[0, 0].imshow(data, origin='lower', cmap='magma', vmin=vmin, vmax=vmax)\n",
    "    plt.colorbar(im0, ax=axes[0, 0], label='Flux [MJy/(sr pixel)]')\n",
    "    \n",
    "    # Plot the source aperture\n",
    "    source_aperture.plot(ax=axes[0, 0], color='red', lw=1.5)\n",
    "    \n",
    "    # Plot the background region\n",
    "    if vis_data['method'] == 'annulus':\n",
    "        annulus = EllipticalAnnulus(\n",
    "            positions=(x_center, y_center),\n",
    "            a_in=a * 1.5,\n",
    "            b_in=b * 1.5,\n",
    "            a_out=vis_data['a_out'],\n",
    "            b_out=vis_data['b_out'],\n",
    "            theta=theta\n",
    "        )\n",
    "        annulus.plot(ax=axes[0, 0], color='white', lw=1.5)\n",
    "    else:  # box method\n",
    "        box_factor = 3.0 if 'box_factor' not in vis_data else vis_data['box_factor']\n",
    "        box_size = max(a, b) * box_factor\n",
    "        box = RectangularAperture(\n",
    "            positions=(x_center, y_center),\n",
    "            w=vis_data['a_out'],\n",
    "            h=vis_data['a_out'],\n",
    "            theta=theta\n",
    "        )\n",
    "        box.plot(ax=axes[0, 0], color='white', lw=1.5)\n",
    "    \n",
    "    axes[0, 0].set_title(\"Original Data with Aperture and Annulus\")\n",
    "    \n",
    "    # Background-subtracted data\n",
    "    vmin2 = np.nanpercentile(background_subtracted, 5)\n",
    "    vmax2 = np.nanpercentile(background_subtracted, 95)\n",
    "    \n",
    "    im1 = axes[0, 1].imshow(background_subtracted, origin='lower', cmap='magma', vmin=vmin2, vmax=vmax2)\n",
    "    plt.colorbar(im1, ax=axes[0, 1], label='Background-subtracted Flux [MJy/(sr pixel)]')\n",
    "    source_aperture.plot(ax=axes[0, 1], color='red', lw=1.5)\n",
    "    axes[0, 1].set_title(\"Background-subtracted Data with Aperture\")\n",
    "    \n",
    "    # Global 2D background plane\n",
    "    im2 = axes[1, 0].imshow(background_plane, origin='lower', cmap='viridis')\n",
    "    plt.colorbar(im2, ax=axes[1, 0], label='Background Flux [MJy/(sr pixel)')\n",
    "    axes[1, 0].set_title(\"Global 2D Background Plane\")\n",
    "        \n",
    "    # Mask visualisation\n",
    "    cmap = plt.cm.get_cmap('viridis', 4)\n",
    "    im3 = axes[1, 1].imshow(mask_vis, origin='lower', cmap=cmap, vmin=-0.5, vmax=3.5)\n",
    "    cbar = plt.colorbar(im3, ax=axes[1, 1], ticks=[0, 1, 2, 3])\n",
    "    cbar.set_ticklabels([f'Excluded\\n(Ï={sigma})', 'Used for fitting', \n",
    "                         f'{region_name} region', 'Source'])\n",
    "    axes[1, 1].set_title(\"Pixel Masks\")\n",
    "    \n",
    "    fig.suptitle(f'{filter}', fontsize=18)#, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if fig_path:\n",
    "        os.makedirs(fig_path, exist_ok=True)\n",
    "        if filter == 'F1800W':\n",
    "            filepath = os.path.join(fig_path, f'{galaxy_id}_{filter}.png')\n",
    "        else: \n",
    "            filepath = os.path.join(fig_path, f'{galaxy_id}.png')\n",
    "        plt.savefig(filepath, dpi=150)\n",
    "        plt.close(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psf(filter_name):\n",
    "    \"\"\"Read MIRI PSF file\"\"\"\n",
    "    psf_file = f'/home/bpc/University/master/Red_Cardinal/WebbPSF/PSF_MIRI_{filter_name}.fits'\n",
    "    with fits.open(psf_file) as psf:\n",
    "        return psf[0].data\n",
    "\n",
    "def get_aperture_params(galaxy_id, aperture_table):\n",
    "    \"\"\"Retrieve aperture parameters from the CSV table.\"\"\"\n",
    "    df = pd.read_csv(aperture_table)\n",
    "    row = df[df['ID'] == int(galaxy_id)].iloc[0]\n",
    "    return row['Apr_Xcenter'], row['Apr_Ycenter'], row['Apr_A'], row['Apr_B'], row['Apr_Theta'] * u.deg\n",
    "\n",
    "def calculate_aperture_correction(psf_data, aperture_params):\n",
    "    \"\"\"Calculate aperture correction for given PSF and aperture.\"\"\"\n",
    "    aperture = EllipticalAperture(\n",
    "        positions=(psf_data.shape[1] / 2, psf_data.shape[0] / 2),\n",
    "        a=aperture_params['a'],\n",
    "        b=aperture_params['b'],\n",
    "        theta=aperture_params['theta']\n",
    "    )\n",
    "    total_flux = np.sum(psf_data)\n",
    "    phot_table = aperture_photometry(psf_data, aperture)\n",
    "    flux_in_aperture = phot_table['aperture_sum'][0]\n",
    "    return total_flux / flux_in_aperture\n",
    "\n",
    "def get_fluxes(data, bkg_median_annulus, error_map, bkg_err, aperture):\n",
    "    \"\"\"Calculate flux and uncertainty from aperture photometry.\"\"\"\n",
    "    # Subtract the median background value within the annulus from the data\n",
    "    data_bkgsub = data - bkg_median_annulus\n",
    "    \n",
    "    # Sum flux within the aperture - baclground subtracted data\n",
    "    phot_table = aperture_photometry(data_bkgsub, aperture, method='exact')\n",
    "    flux = phot_table['aperture_sum'][0]    # in MJy/sr\n",
    "    \n",
    "    # Mask for aperture\n",
    "    aperture_mask = aperture.to_mask(method='exact')\n",
    "    mask = aperture_mask.to_image(data_bkgsub.shape)\n",
    "    \n",
    "    # Flux uncertainty from ERR extension\n",
    "    image_errors = error_map * mask\n",
    "    sum_image_errors = np.sqrt(np.sum(image_errors**2))\n",
    "    \n",
    "    # Number of pixels within the aperture\n",
    "    n_eff = aperture.area\n",
    "    \n",
    "    # To obtain the background flux within the aperture we multiply the median background within the annulus\n",
    "    # by the number of pixels within the aperture    \n",
    "    flux_bkg = n_eff * bkg_median_annulus\n",
    "    \n",
    "    # Total flux uncertainty\n",
    "    flux_error_tot = np.sqrt(sum_image_errors**2 + bkg_err**2)\n",
    "    \n",
    "    # Median error of the error map within the aperture\n",
    "    median_error = np.median(error_map)    \n",
    "    \n",
    "    # Convert everything to from MJy/sr to Jy\n",
    "    miri_scale = 0.11092  # arcsec per pixel\n",
    "    miri_scale_rad = miri_scale / 206265\n",
    "    omega_pix = miri_scale_rad**2\n",
    "    \n",
    "    conv_factor = 1e6 * omega_pix\n",
    "    \n",
    "    flux *= conv_factor\n",
    "    flux_bkg *= conv_factor\n",
    "    flux_error_tot *= conv_factor\n",
    "    median_error *= conv_factor\n",
    "    \n",
    "    # Now everything is in Jy!!\n",
    "    return flux, flux_error_tot, flux_bkg, median_error, n_eff\n",
    "\n",
    "# --- Main Loop ---\n",
    "\n",
    "def perform_photometry(cutout_files, aperture_table, psf_data, output_folder):\n",
    "    \"\"\"Main loop for photometry analysis.\"\"\"\n",
    "    photometry_results = []\n",
    "    \n",
    "    for fits_path in cutout_files:\n",
    "        \n",
    "        fits_name = os.path.basename(fits_path)\n",
    "        galaxy_id = fits_name.split('_')[0]\n",
    "        filter = fits_name.split('_')[1]\n",
    "        \n",
    "        print(f'Processing galaxy {galaxy_id}...')\n",
    "        \n",
    "        with fits.open(fits_path) as hdul:\n",
    "            data = hdul['SCI'].data if 'SCI' in hdul else hdul[1].data\n",
    "            error = hdul['ERR'].data if 'ERR' in hdul else hdul[2].data\n",
    "            \n",
    "        # --- Access aperture parameters ---\n",
    "        miri_x, miri_y, width, height, theta = get_aperture_params(galaxy_id, aperture_table)\n",
    "        aperture_params = {'x_center': miri_x, 'y_center': miri_y, 'a': width / 2, 'b': height / 2, 'theta': theta.to_value(u.rad)}\n",
    "        aperture = EllipticalAperture((miri_x, miri_y), a=width / 2, b=height / 2, theta=theta.to_value(u.rad))\n",
    "        \n",
    "        # --- Background subtraction ---\n",
    "        \n",
    "        # Set sigma for both filters\n",
    "        two_sigma = ['12332', '12282', '10314', '12164', '18332', '21452', '21477', '21541', '22606', '10592', '11136', '11142', \n",
    "                     '11420', '11451', '11494', '11716', '13103', '16419', '19042']\n",
    "        if galaxy_id in two_sigma:\n",
    "            sigma = 2.0\n",
    "        else:\n",
    "            sigma = 2.8\n",
    "\n",
    "        # Adjust sigma for F770W filter, but only if not already set to 2.0\n",
    "        if filter == 'F770W' and galaxy_id in ['7136', '7904', '7922', '8469', '11716', '16424', '17000', '17669', '11137']:\n",
    "            sigma = 2.0\n",
    "            \n",
    "        vis_path = '/home/bpc/University/master/Red_Cardinal/photometry/mosaic_fits/'\n",
    "        os.makedirs(vis_path, exist_ok=True)\n",
    "        fig_path = '/home/bpc/University/master/Red_Cardinal/photometry/mosaic_plots/'\n",
    "        file_path = os.path.join(vis_path, f'{galaxy_id}_{filter}.fits')\n",
    "        bkg_map, bkg_median, bkg_err, annulus_mask = get_background(galaxy_id, filter, data, aperture_params, sigma=sigma, \n",
    "                                                                        method='annulus', annulus_factor=3.0, \n",
    "                                                                        fig_path=fig_path)                                                                        \n",
    "        \n",
    "        # --- Store data in a FITS file for later plotting ---\n",
    "        plot_folder = os.path.join(output_folder, f'mosaic_fits/')\n",
    "        os.makedirs(plot_folder, exist_ok=True)\n",
    "        filename = os.path.join(plot_folder, f'{galaxy_id}_{filter}.fits')     \n",
    "        \n",
    "        # --- Obtain fluxes from photometry ---\n",
    "        flux, flux_err, flux_bkg, median_error, n_pix = get_fluxes(data, bkg_median, error, bkg_err, aperture)\n",
    "\n",
    "        # Aperture correctionbkg_rms_map\n",
    "        correction_factor = calculate_aperture_correction(psf_data, aperture_params)\n",
    "\n",
    "        # --- Apply aperture correction ---\n",
    "        flux *= correction_factor\n",
    "        flux_err *= correction_factor\n",
    "        flux_bkg *= correction_factor\n",
    "        flux_bkg_err = bkg_err * correction_factor\n",
    "        \n",
    "        # --- Convert fluxes into AB magnitudes ---\n",
    "        if flux > 0:\n",
    "            ab_mag = -2.5 * np.log10(flux) + 8.90\n",
    "        else: ab_mag = np.nan\n",
    "        \n",
    "        # Append results\n",
    "        photometry_results.append({\n",
    "            'Flux': flux,           # Flux within the aperture\n",
    "            'Flux_Err': flux_err,   # Total error on the fluxes (image error^2 + bkg_err^2)\n",
    "            'Image_Err': median_error,     # Median error of the ERR extension in the MIRI cutouts\n",
    "            'Flux_BKG': flux_bkg,   # Median flux within the annulus multiplied by the number of pixels within the aperture\n",
    "            'AB_Mag': ab_mag,       # AB magnitudes\n",
    "            'Flux_BKG_Err': flux_bkg_err,   # Std background error times square root of number of pixels within the annulus\n",
    "            'N_PIX': n_pix,         # Number of pixels within the aperture\n",
    "            'Apr_A': width,\n",
    "            'Apr_B': height,\n",
    "            'Apr_Xcenter': miri_x,\n",
    "            'Apr_Ycenter': miri_y,\n",
    "            'Apr_Theta': theta.to_value(u.deg),\n",
    "            'ID': int(galaxy_id)\n",
    "        })\n",
    "    \n",
    "    # Save to output table (assuming it's a pandas DataFrame)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_table = os.path.join(output_folder, f'results/photometry_table_{filter}.csv')\n",
    "    output_df = pd.DataFrame(photometry_results)\n",
    "    output_df.to_csv(output_table, index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = ['8465', '7922', '9871', '12202', '8843', '7904', '8338', '10021', '10245', '11136', '12340', '20397']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters ---\n",
    "cutouts_folder = \"/home/bpc/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "output_folder = '/home/bpc/University/master/Red_Cardinal/photometry/'\n",
    "aperture_table = '/home/bpc/University/master/Red_Cardinal/photometry/aperture_table_rot.csv'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get all possible F770W files\n",
    "all_f770w_files = glob.glob(os.path.join(cutouts_folder, f'*F770W*.fits'))\n",
    "\n",
    "# Group F770W files by galaxy ID and filter\n",
    "f770w_files = []\n",
    "galaxy_ids = set([os.path.basename(f).split('_')[0] for f in all_f770w_files])\n",
    "\n",
    "for galaxy_id in galaxy_ids:\n",
    "    # Find all F770W files for this galaxy ID\n",
    "    matching_files = [f for f in all_f770w_files if os.path.basename(f).startswith(galaxy_id)]\n",
    "    \n",
    "    # Prioritise PRIMER over COSMOS-Web\n",
    "    primer_files = [f for f in matching_files if 'primer' in f.lower()]\n",
    "    cweb_files = [f for f in matching_files if 'cweb' in f.lower()]\n",
    "    \n",
    "    if primer_files:\n",
    "        f770w_files.append(primer_files[0])  # Prefer PRIMER file\n",
    "    elif cweb_files:\n",
    "        f770w_files.append(cweb_files[0])  # Use CWEB only if no PRIMER available\n",
    "\n",
    "# Get all F1800W files\n",
    "f1800w_files = glob.glob(os.path.join(cutouts_folder, f'*F1800W*.fits'))\n",
    "\n",
    "\n",
    "psf_f770w = get_psf('F770W')\n",
    "psf_f1800w = get_psf('F1800W')\n",
    "\n",
    "perform_photometry(f770w_files, aperture_table, psf_f770w, output_folder)\n",
    "perform_photometry(f1800w_files, aperture_table, psf_f1800w, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge mosaics for the same galaxy IDs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = '/home/bpc/University/master/Red_Cardinal/photometry/mosaic_plots/'\n",
    "print(f\"Scanning {fig_path} for galaxy images to combine...\")\n",
    "\n",
    "# Get all F1800W images\n",
    "f1800w_pngs = glob.glob(os.path.join(fig_path, '*_F1800W.png'))\n",
    "\n",
    "# Track how many images we've combined\n",
    "combined_count = 0\n",
    "\n",
    "for f1800w_png in f1800w_pngs:\n",
    "    # Extract galaxy ID from filename\n",
    "    galaxy_id = os.path.basename(f1800w_png).replace('_F1800W.png', '')\n",
    "    f770w_png = os.path.join(fig_path, f'{galaxy_id}.png')\n",
    "    \n",
    "    # Check if the standard file exists\n",
    "    if os.path.exists(f770w_png):\n",
    "        try:\n",
    "            # Open both images\n",
    "            img_f770w = Image.open(f770w_png)\n",
    "            img_f1800w = Image.open(f1800w_png)\n",
    "            \n",
    "            # Get dimensions\n",
    "            width1, height1 = img_f770w.size\n",
    "            width2, height2 = img_f1800w.size\n",
    "            \n",
    "            # Create a new image with enough width for both images\n",
    "            combined_width = width1 + width2\n",
    "            combined_height = max(height1, height2)\n",
    "            combined_img = Image.new('RGB', (combined_width, combined_height), (255, 255, 255))\n",
    "            \n",
    "            # Paste both images\n",
    "            combined_img.paste(img_f770w, (0, 0))\n",
    "            combined_img.paste(img_f1800w, (width1, 0))\n",
    "            \n",
    "            # Save combined image\n",
    "            save_png = os.path.join(fig_path, f'{galaxy_id}.png')\n",
    "            combined_img.save(save_png)\n",
    "            \n",
    "            # Delete the F1800W file\n",
    "            os.remove(f1800w_png)\n",
    "            \n",
    "            combined_count += 1\n",
    "            print(f\"Combined images for galaxy {galaxy_id}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error combining images for galaxy {galaxy_id}: {e}\")\n",
    "\n",
    "print(f\"Combined {combined_count} galaxy image pairs.\")\n",
    "\n",
    "# Check if any F1800W images remain (no matching F770W image)\n",
    "remaining_f1800w = glob.glob(os.path.join(fig_path, '*_F1800W.png'))\n",
    "if remaining_f1800w:\n",
    "    print(f\"Note: {len(remaining_f1800w)} F1800W images have no matching standard image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce the table with the photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the contents of the original FITS files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = './../cutouts/7102_F770W_cutout_cweb1.fits'\n",
    "#with fits.open(fname) as hdul:\n",
    "    #hdul.info()\n",
    "\n",
    "\n",
    "fname = './../MIRI/PRIMER_003/jw01837-o003_t003_miri_f770w_i2d.fits'\n",
    "with fits.open(fname) as hdul:\n",
    "    hdul.info()\n",
    "\n",
    "fname = './../MIRI_shifted/PRIMER_003_shifted/jw01837-o003_t003_miri_f770w_i2d_shifted.fits'\n",
    "with fits.open(fname) as hdul:\n",
    "    hdul.info()\n",
    "              \n",
    "    \n",
    "fname = './../photometry/mosaic_fits/11136_F770W.fits'\n",
    "with fits.open(fname) as hdul:\n",
    "    hdul.info()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
