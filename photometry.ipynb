{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photometry on MIRI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import subprocess\n",
    "import miri_utils.photometry_tools as phot\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import FITSFixedWarning\n",
    "from astropy.table import Table\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=FITSFixedWarning)\n",
    "\n",
    "\n",
    "cutout_dir = \"/home/bpc/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "phot_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section to obtain modified apertures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect Amirs table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path =  '/home/bpc/University/master/Red_Cardinal/Flux_Aperture_PSFMatched_AperCorr_old.fits'\n",
    "\n",
    "table = Table.read(table_path)\n",
    "#print(table[:5])\n",
    "table.info()\n",
    "print(table.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and call the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_dir = \"/home/bpc/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "phot_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/\"\n",
    "\n",
    "# Get all FITS file paths\n",
    "fits_files = glob.glob(os.path.join(cutout_dir, '*.fits'))\n",
    "\n",
    "# Get the basenames of the FITS files\n",
    "fits_fnames = [os.path.basename(f) for f in fits_files]\n",
    "\n",
    "adjusted_apertures = []\n",
    "\n",
    "for fname in fits_fnames:\n",
    "    id = fname.split('_')[0]\n",
    "    filter = fname.split('_')[1]\n",
    "    if filter == 'F1800W': continue\n",
    "    survey_obs = fname.split('_')[3]\n",
    "    if '003' in survey_obs:\n",
    "        survey = 'primer'\n",
    "        obs = '003'\n",
    "    elif '004' in survey_obs:\n",
    "        survey = 'primer'\n",
    "        obs = '004'\n",
    "    elif '1' in survey_obs:\n",
    "        survey = 'cweb'\n",
    "        obs = '1'\n",
    "    elif '2' in survey_obs:\n",
    "        survey = 'cweb'\n",
    "        obs = '2'\n",
    "    else:\n",
    "        print(f\"Unknown survey and/or observation number for galaxy {id}:\\n\")\n",
    "        print(survey_obs)\n",
    "    \n",
    "    # Call and collect results\n",
    "    result = phot.adjust_aperture(id, filter, survey, obs, phot_dir, save_plot=False)\n",
    "    if result:\n",
    "        adjusted_apertures.append(result)\n",
    "\n",
    "# After loop: create a DataFrame\n",
    "df_apertures = pd.DataFrame(adjusted_apertures)\n",
    "\n",
    "df_path = '/home/bpc/University/master/Red_Cardinal/photometry/aperture_table_v2.csv'\n",
    "\n",
    "# (optional) Save to CSV or integrate into photometry table\n",
    "df_apertures.to_csv(df_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily open any given FITS file with its corresponding ellipse region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Launch DS9 with the MIRI cutout and the overplotted aperture ---\n",
    "region_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/regions/\"\n",
    "cutout_dir = \"/home/bpc/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "phot_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/\"\n",
    "\n",
    "id = '10245'\n",
    "filter = 'F770W'\n",
    "survey_obs = 'primer004'\n",
    "cutout_path = os.path.join(cutout_dir, f'{id}_{filter}_cutout_{survey_obs}.fits')\n",
    "reg_path = os.path.join(region_dir, f'{id}_{survey_obs}_aperture.reg')\n",
    "subprocess.run([\"ds9\", cutout_path, \"-regions\", reg_path])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path =  '/home/bpc/University/master/Red_Cardinal/Flux_Aperture_PSFMatched_AperCorr_old.fits'\n",
    "\n",
    "table = Table.read(table_path)\n",
    "print(table[:5])\n",
    "table.info()\n",
    "print(table['Image_Err'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is where we do most of the work\n",
    "\n",
    "# Section to perform the actual photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's set some parameters straight:\n",
    "\n",
    "pixscale_arcsec = 0.11092  # arcsec per pixel\n",
    "\n",
    "pix_area_sr = 2.89208962133982e-13  # from MIRI header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the code should be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = ['8465', '7922', '9871', '12202', '8843', '7904', '8338', '10021', '10245', '11136', '12340', '20397']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters ---\n",
    "cutouts_folder = \"/home/bpc/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "output_folder = '/home/bpc/University/master/Red_Cardinal/photometry/'\n",
    "aperture_table_small = '/home/bpc/University/master/Red_Cardinal/photometry/aperture_table_small.csv'\n",
    "aperture_table_big = '/home/bpc/University/master/Red_Cardinal/photometry/aperture_table_big.csv'\n",
    "#fig_path = '/home/bpc/University/master/Red_Cardinal/photometry/Plots_MIRI_phot_v3/'\n",
    "fig_path = None\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get all possible F770W files\n",
    "all_f770w_files = glob.glob(os.path.join(cutouts_folder, f'*F770W*.fits'))\n",
    "\n",
    "# Group F770W files by galaxy ID and filter\n",
    "f770w_files = []\n",
    "galaxy_ids = set([os.path.basename(f).split('_')[0] for f in all_f770w_files])\n",
    "\n",
    "for galaxy_id in galaxy_ids:\n",
    "    # Find all F770W files for this galaxy ID\n",
    "    matching_files = [f for f in all_f770w_files if os.path.basename(f).startswith(galaxy_id)]\n",
    "    \n",
    "    # Handle special case for galaxy 11853\n",
    "    if galaxy_id == '11853':\n",
    "        # Use the cweb2 file if available\n",
    "        cweb2_files = [f for f in matching_files if 'cweb2' in f.lower()]\n",
    "        if cweb2_files:\n",
    "            f770w_files.append(cweb2_files[0])\n",
    "            continue  # Skip to the next galaxy\n",
    "    \n",
    "    # Prioritise PRIMER over COSMOS-Web\n",
    "    primer_files = [f for f in matching_files if 'primer' in f.lower()]\n",
    "    cweb_files = [f for f in matching_files if 'cweb' in f.lower()]\n",
    "    \n",
    "    if primer_files:\n",
    "        f770w_files.append(primer_files[0])  # Prefer PRIMER file\n",
    "    elif cweb_files:\n",
    "        f770w_files.append(cweb_files[0])  # Use CWEB only if no PRIMER available\n",
    "\n",
    "# Get all F1800W files\n",
    "f1800w_files = glob.glob(os.path.join(cutouts_folder, f'*F1800W*.fits'))\n",
    "\n",
    "psf_f770w = phot.get_psf('F770W')\n",
    "psf_f1800w = phot.get_psf('F1800W')\n",
    "\n",
    "# Small aperture without aperture correction:\n",
    "\n",
    "phot.perform_photometry(f770w_files, aperture_table_small, output_folder, \n",
    "                        psf_f770w, suffix='_small_no_corr',\n",
    "                        sigma=2.0, annulus_factor=3.0\n",
    ")\n",
    "\n",
    "phot.perform_photometry(f1800w_files, aperture_table_small, output_folder, \n",
    "                        psf_f1800w, suffix='_small_no_corr',\n",
    "                        sigma=2.0, annulus_factor=3.0\n",
    ")\n",
    "\n",
    "# Big Aperture without aperture correction:\n",
    "\n",
    "phot.perform_photometry(f770w_files, aperture_table_big, output_folder, \n",
    "                        psf_f770w, suffix='_big_no_corr',\n",
    "                        sigma=2.0, annulus_factor=3.0\n",
    ")\n",
    "\n",
    "phot.perform_photometry(f1800w_files, aperture_table_big, output_folder, \n",
    "                        psf_f1800w, suffix='_big_no_corr',\n",
    "                        sigma=2.0, annulus_factor=3.0\n",
    ")\n",
    "\n",
    "# Plotting:\n",
    "\n",
    "if fig_path:\n",
    "    phot.combine_figures(fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the FITS table for small and big aperture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small aperture\n",
    "\n",
    "# Your existing code to save CSV files for each filter\n",
    "fits_table_small = f'Flux_SmallAperture_NoCorr_MIRI.fits'\n",
    "f770w_fname = 'phot_table_F770W_small_no_corr.csv'\n",
    "f1800w_fname = 'phot_table_F1800W_small_no_corr.csv'\n",
    "\n",
    "# Now create the combined FITS table\n",
    "phot.combine_filter_csv_to_fits(f770w_fname, f1800w_fname, fits_table_name=fits_table_small)\n",
    "\n",
    "\n",
    "\n",
    "# Big aperture\n",
    "\n",
    "# Your existing code to save CSV files for each filter\n",
    "fits_table_big = f'Flux_BigAperture_NoCorr_MIRI.fits'\n",
    "f770w_fname = 'phot_table_F770W_big_no_corr.csv'\n",
    "f1800w_fname = 'phot_table_F1800W_big_no_corr.csv'\n",
    "\n",
    "# Now create the combined FITS table\n",
    "phot.combine_filter_csv_to_fits(f770w_fname, f1800w_fname, fits_table_name=fits_table_big)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1_path =  '/home/bpc/University/master/Red_Cardinal/photometry/results/Flux_Aperture_PSFMatched_AperCorr_MIRI_v3.fits'\n",
    "\n",
    "print(\"Smaller aperture:\")\n",
    "table = Table.read(table1_path)\n",
    "row = table[table['ID']=='7934']\n",
    "print(row)\n",
    "row = table[table['ID']=='12202']\n",
    "print(row)\n",
    "row = table[table['ID']=='11136']\n",
    "print(row)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Bigger aperture:\")\n",
    "table2_path = '/home/bpc/University/master/Red_Cardinal/photometry/results/Flux_Aperture_PSFMatched_AperCorr_MIRI_v2.fits'\n",
    "table = Table.read(table2_path)\n",
    "row = table[table['ID']=='7934']\n",
    "print(row)\n",
    "row = table[table['ID']=='12202']\n",
    "print(row)\n",
    "row = table[table['ID']=='11136']\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the two catalogues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the two tables\n",
    "table_small_path =  '/home/bpc/University/master/Red_Cardinal/photometry/results/Flux_SmallAperture_NoCorr_MIRI.fits'\n",
    "table_big_path =  '/home/bpc/University/master/Red_Cardinal/photometry/results/Flux_BigAperture_NoCorr_MIRI.fits'\n",
    "\n",
    "\n",
    "table_small = Table.read(table_small_path)\n",
    "table_big = Table.read(table_big_path)\n",
    "\n",
    "# Convert ID columns to string for alignment\n",
    "ids1 = [id.decode() if isinstance(id, bytes) else str(id) for id in table_small['ID']]\n",
    "ids2 = [id.decode() if isinstance(id, bytes) else str(id) for id in table_big['ID']]\n",
    "\n",
    "# Match common IDs\n",
    "common_ids = sorted(set(ids1) & set(ids2))\n",
    "print(f\"Found {len(common_ids)} common galaxies\")\n",
    "\n",
    "# Collect differences for each band (F770W = index 0, F1800W = index 1)\n",
    "diffs = {'Flux': [], 'Apr_Corr': []}\n",
    "bands = ['F770W', 'F1800W']\n",
    "\n",
    "for idx in [0, 1]:\n",
    "    flux_diffs = []\n",
    "    corr_diffs = []\n",
    "    \n",
    "    for gid in common_ids:\n",
    "        i1 = ids1.index(gid)\n",
    "        i2 = ids2.index(gid)\n",
    "\n",
    "        flux_small = table_small['Flux'][i1][idx]*1e6\n",
    "        flux_big = table_big['Flux'][i2][idx]*1e6\n",
    "        corr_small = table_small['Apr_Corr'][i1][idx] if 'Apr_Corr' in table_small.colnames else np.nan\n",
    "        corr_big = table_big['Apr_Corr'][i2][idx] if 'Apr_Corr' in table_big.colnames else np.nan\n",
    "\n",
    "        # Only compare valid fluxes\n",
    "        if np.isfinite(flux_small) and np.isfinite(flux_big):\n",
    "            flux_diffs.append(flux_big - flux_small)\n",
    "        \n",
    "        if np.isfinite(corr_small) and np.isfinite(corr_big):\n",
    "            corr_diffs.append(corr_big - corr_small)\n",
    "    \n",
    "    diffs['Flux'].append(flux_diffs)\n",
    "    diffs['Apr_Corr'].append(corr_diffs)\n",
    "\n",
    "    # Print basic statistics\n",
    "    print(f\"\\n📊 Band: {bands[idx]}\")\n",
    "    print(f\"Flux difference: mean={np.mean(flux_diffs):.3e}, median={np.median(flux_diffs):.3e}, std={np.std(flux_diffs):.3e}\")\n",
    "    print(f\"Aperture correction difference: mean={np.mean(corr_diffs):.3f}, median={np.median(corr_diffs):.3f}, std={np.std(corr_diffs):.3f}\")\n",
    "\n",
    "\n",
    "# --- Plotting ---\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.85)\n",
    "\n",
    "for i, band in enumerate(bands):\n",
    "    flux_diffs = diffs['Flux'][i]\n",
    "    corr_diffs = diffs['Apr_Corr'][i]\n",
    "\n",
    "    # Flux\n",
    "    ax_flux = axs[i, 0]\n",
    "    ax_flux.hist(flux_diffs, bins=30, alpha=0.7, color='cornflowerblue')\n",
    "    ax_flux.set_title(f\"{band} Flux Difference\")\n",
    "    ax_flux.set_xlabel(\"Flux_large_apr - Flux_small_apr [µJy]\")\n",
    "\n",
    "    text_flux = '\\n'.join((\n",
    "        f\"Mean:   {np.mean(flux_diffs):.2f} µJy\",\n",
    "        f\"Median: {np.median(flux_diffs):.2f} µJy\",\n",
    "        f\"Std:    {np.std(flux_diffs):.2f} µJy\"\n",
    "    ))\n",
    "    ax_flux.text(0.25, 0.95, text_flux, transform=ax_flux.transAxes,\n",
    "                 fontsize=9, verticalalignment='top', horizontalalignment='right', bbox=props)\n",
    "\n",
    "    # Aperture Correction\n",
    "    ax_corr = axs[i, 1]\n",
    "    ax_corr.hist(corr_diffs, bins=30, alpha=0.7, color='darkorange')\n",
    "    ax_corr.set_title(f\"{band} Aperture Correction Difference\")\n",
    "    ax_corr.set_xlabel(\"Corr_large_apr - Corr_small_apr\")\n",
    "\n",
    "    text_corr = '\\n'.join((\n",
    "        f\"Mean:   {np.mean(corr_diffs):.2f}\",\n",
    "        f\"Median: {np.median(corr_diffs):.2f}\",\n",
    "        f\"Std:    {np.std(corr_diffs):.2f}\"\n",
    "    ))\n",
    "    ax_corr.text(0.2, 0.95, text_corr, transform=ax_corr.transAxes,\n",
    "                 fontsize=9, verticalalignment='top', horizontalalignment='right', bbox=props)\n",
    "\n",
    "plt.suptitle('Comparison between fluxes using small and large aperture')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instead is the CLAUDE version of the above analysis - as always completely overpowered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phot_dir = '/home/bpc/University/master/Red_Cardinal/photometry/'\n",
    "\n",
    "table_small_path = os.path.join(phot_dir, 'aperture_table_small.csv')\n",
    "table_big_path = os.path.join(phot_dir, 'aperture_table_big.csv')\n",
    "fig_path = os.path.join(phot_dir, 'aperture_comparisons/aperture_statistics_log.png')\n",
    "summary_doc_path = os.path.join(phot_dir, 'aperture_comparisons/summary_statistics.txt')\n",
    "\n",
    "phot.compare_aperture_statistics(table_small_path, table_big_path, fig_path, summary_doc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect galaxy IDs and their corresponding observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NIRCam_table =  '/home/bpc/University/master/Red_Cardinal/Flux_Aperture_PSFMatched_AperCorr_old.fits'\n",
    "table = Table.read(NIRCam_table)\n",
    "table.info()\n",
    "f444w_ids = list(table['ID'])\n",
    "\n",
    "MIRI_table = '/home/bpc/University/master/Red_Cardinal/photometry/results/Flux_Aperture_PSFMatched_AperCorr_MIRI.fits'\n",
    "table = Table.read(MIRI_table)\n",
    "table.info()\n",
    "f770w_ids = list(table['ID'])\n",
    "\n",
    "cutout_dir = '/home/bpc/University/master/Red_Cardinal/cutouts_phot/'\n",
    "f1800w_ids = glob.glob(os.path.join(cutout_dir, '*F1800W*.fits'))\n",
    "for i, f in enumerate(f1800w_ids):\n",
    "    f = os.path.basename(f).split('_')[0]\n",
    "    f1800w_ids[i] = f\n",
    "\n",
    "# Convert the arrays to sets for efficient comparison\n",
    "set_f444w = set(f444w_ids)\n",
    "set_f770w = set(f770w_ids)\n",
    "set_f1800w = set(f1800w_ids)\n",
    "\n",
    "# 1) IDs in all 3 arrays\n",
    "in_all_three = set_f444w & set_f770w & set_f1800w\n",
    "\n",
    "# 2) IDs in f444w_ids and f770w_ids only (not in f1800w_ids)\n",
    "in_f444w_and_f770w_only = (set_f444w & set_f770w) - set_f1800w\n",
    "\n",
    "# 3) IDs only in f444w_ids and not in the other 2\n",
    "only_in_f444w = set_f444w - set_f770w - set_f1800w\n",
    "\n",
    "# Convert back to sorted lists if needed\n",
    "in_all_three = sorted(list(in_all_three))\n",
    "in_f444w_and_f770w_only = sorted(list(in_f444w_and_f770w_only))\n",
    "only_in_f444w = sorted(list(only_in_f444w))\n",
    "\n",
    "print(f\"{len(in_all_three)} IDs in all three arrays: {in_all_three}\")\n",
    "print(f\"{len(in_f444w_and_f770w_only)} IDs in f444w_ids and f770w_ids only: {in_f444w_and_f770w_only}\")\n",
    "print(f\"{len(only_in_f444w)} IDs only in f444w_ids: {only_in_f444w}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the contents of the original FITS files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = './../cutouts/7102_F770W_cutout_cweb1.fits'\n",
    "#with fits.open(fname) as hdul:\n",
    "    #hdul.info()\n",
    "\n",
    "\n",
    "fname = './../MIRI/PRIMER_003/jw01837-o003_t003_miri_f770w_i2d.fits'\n",
    "with fits.open(fname) as hdul:\n",
    "    hdul.info()\n",
    "\n",
    "fname = './../MIRI_shifted/PRIMER_003_shifted/jw01837-o003_t003_miri_f770w_i2d_shifted.fits'\n",
    "with fits.open(fname) as hdul:\n",
    "    hdul.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section to compare my aperture photometry to the photometry of the COSMOS-Web2025 catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "from astropy.io import ascii, fits\n",
    "from astropy.table import Table, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the big table to the necessary columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "\n",
    "# Read full table once (on a powerful machine)\n",
    "#full = Table.read(\"/home/bpc/University/master/Red_Cardinal/catalogues/COSMOSWeb_mastercatalog_v1_photom_primary.fits\")\n",
    "\n",
    "# Extract only the needed columns\n",
    "#small = full['id', 'ra', 'dec', 'flux_auto_f770w', 'flux_err_auto_f770w', 'mag_auto_f770w']\n",
    "\n",
    "# Save to new FITS or CSV\n",
    "#small.write(\"/home/bpc/University/master/Red_Cardinal/catalogues/COSMOSWeb_reduced.fits\", overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "cweb_path = '/home/bpc/University/master/Red_Cardinal/catalogues/COSMOSWeb_reduced.fits'\n",
    "my_path = '/home/bpc/University/master/Red_Cardinal/photometry/results/Flux_Aperture_PSFMatched_AperCorr_MIRI_v3.fits'\n",
    "cat_path = '/home/bpc/University/master/Red_Cardinal/catalogues/cat_targets.fits'\n",
    "\n",
    "my_table = Table.read(my_path, hdu=1)\n",
    "cosmos_table = Table.read(cweb_path, hdu=1)\n",
    "my_cat = Table.read(cat_path, hdu=1)\n",
    "fits.info(my_path)\n",
    "fits.info(cweb_path)\n",
    "#print(my_cat.columns)\n",
    "\n",
    "# Rename ID column to id to match other catalogues\n",
    "my_table.rename_column('ID', 'id')\n",
    "\n",
    "# Reduce catalogue\n",
    "my_cat_small = my_cat['id', 'ra', 'dec']\n",
    "\n",
    "# Force type setting\n",
    "my_table['id'] = my_table['id'].astype(str)\n",
    "my_cat_small['id'] = my_cat_small['id'].astype(str)\n",
    "\n",
    "# Match according to IDs\n",
    "matched = join(my_table, my_cat_small, keys=('id'), join_type='inner')\n",
    "\n",
    "print(matched.columns)\n",
    "\n",
    "matched.write('/home/bpc/University/master/Red_Cardinal/catalogues/Flux_Aperture_PSFMatched_AperCorr_MIRI_ra_dec.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build coordinates\n",
    "coords_my = SkyCoord(ra=my_cat['ra']*u.deg, dec=my_cat['dec']*u.deg)\n",
    "coords_cosmos = SkyCoord(ra=cosmos_table['ra']*u.deg, dec=cosmos_table['dec']*u.deg)\n",
    "\n",
    "# Match (within 0.3 arcsec, for instance)\n",
    "idx, d2d, _ = coords_my.match_to_catalog_sky(coords_cosmos)\n",
    "match_mask = d2d < 0.3 * u.arcsec\n",
    "\n",
    "# Build matched table\n",
    "my_matched = my_table[match_mask]\n",
    "cosmos_matched = cosmos_table[idx[match_mask]]\n",
    "\n",
    "# Combine tables: rename columns to avoid name collision\n",
    "cosmos_matched.rename_columns(\n",
    "    cosmos_matched.colnames,\n",
    "    [name + \"_cosmos\" if name in my_matched.colnames else name for name in cosmos_matched.colnames]\n",
    ")\n",
    "\n",
    "# Stack into one comparison table\n",
    "from astropy.table import hstack\n",
    "#sky_matched = hstack([my_matched, cosmos_matched])\n",
    "\n",
    "# Merge horizontally\n",
    "sky_matched = hstack([my_matched, cosmos_matched])\n",
    "\n",
    "sky_matched.write('/home/bpc/University/master/Red_Cardinal/catalogues/COSMOSWeb_matched.fits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "import matplotlib.patches as patches\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_and_prepare_data(fits_file_path):\n",
    "    \"\"\"\n",
    "    Load the FITS table and prepare data for comparison\n",
    "    \"\"\"\n",
    "    # Load the FITS table\n",
    "    table = Table.read(fits_file_path)\n",
    "    \n",
    "    # Extract F770W data from multi-dimensional arrays\n",
    "    # For Flux and Flux_Err, take the first value (F770W filter)\n",
    "    flux_personal = []\n",
    "    flux_err_personal = []\n",
    "    ab_mag_personal = []\n",
    "    \n",
    "    for i in range(len(table)):\n",
    "        # Handle Flux (F770W is first element)\n",
    "        if table['Flux'].mask[i][0] == False:\n",
    "            flux_val = table['Flux'][i]*1e6 # convert to µJy\n",
    "            if hasattr(flux_val, '__len__') and len(flux_val) > 0:\n",
    "                flux_personal.append(flux_val[0])\n",
    "            else:\n",
    "                flux_personal.append(flux_val)\n",
    "        else:\n",
    "            flux_personal.append(np.nan)\n",
    "            \n",
    "        # Handle Flux_Err (F770W is first element)\n",
    "        if table['Flux_Err'].mask[i][0] == False:\n",
    "            flux_err_val = table['Flux_Err'][i]*1e6 # convert to µJy\n",
    "            if hasattr(flux_err_val, '__len__') and len(flux_err_val) > 0:\n",
    "                flux_err_personal.append(flux_err_val[0])\n",
    "            else:\n",
    "                flux_err_personal.append(flux_err_val)\n",
    "        else:\n",
    "            flux_err_personal.append(np.nan)\n",
    "            \n",
    "        # Handle AB_Mag (F770W is first element)\n",
    "        if table['AB_Mag'].mask[i][0] == False:\n",
    "            ab_mag_val = table['AB_Mag'][i]\n",
    "            if hasattr(ab_mag_val, '__len__') and len(ab_mag_val) > 0:\n",
    "                ab_mag_personal.append(ab_mag_val[0])\n",
    "            else:\n",
    "                ab_mag_personal.append(ab_mag_val)\n",
    "        else:\n",
    "            ab_mag_personal.append(np.nan)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    flux_personal = np.array(flux_personal)\n",
    "    flux_err_personal = np.array(flux_err_personal)\n",
    "    ab_mag_personal = np.array(ab_mag_personal)\n",
    "    \n",
    "    # Extract public catalogue data\n",
    "    flux_public = np.array(table['flux_auto_f770w'])\n",
    "    flux_err_public = np.array(table['flux_err_auto_f770w'])\n",
    "    mag_public = np.array(table['mag_auto_f770w'])\n",
    "    \n",
    "    # Create masks for valid data\n",
    "    valid_flux = (~np.isnan(flux_personal)) & (~np.isnan(flux_public)) & \\\n",
    "                 (flux_personal > 0) & (flux_public > 0)\n",
    "    valid_flux_err = (~np.isnan(flux_err_personal)) & (~np.isnan(flux_err_public)) & \\\n",
    "                     (flux_err_personal > 0) & (flux_err_public > 0)\n",
    "    valid_mag = (~np.isnan(ab_mag_personal)) & (~np.isnan(mag_public))\n",
    "    \n",
    "    return {\n",
    "        'table': table,\n",
    "        'flux_personal': flux_personal,\n",
    "        'flux_err_personal': flux_err_personal,\n",
    "        'ab_mag_personal': ab_mag_personal,\n",
    "        'flux_public': flux_public,\n",
    "        'flux_err_public': flux_err_public,\n",
    "        'mag_public': mag_public,\n",
    "        'valid_flux': valid_flux,\n",
    "        'valid_flux_err': valid_flux_err,\n",
    "        'valid_mag': valid_mag\n",
    "    }\n",
    "\n",
    "def calculate_statistics(x, y, valid_mask):\n",
    "    \"\"\"\n",
    "    Calculate comparison statistics\n",
    "    \"\"\"\n",
    "    if np.sum(valid_mask) < 3:\n",
    "        return {}\n",
    "    \n",
    "    x_valid = x[valid_mask]\n",
    "    y_valid = y[valid_mask]\n",
    "    \n",
    "    # Linear correlation\n",
    "    corr_coef, p_value = stats.pearsonr(x_valid, y_valid)\n",
    "    \n",
    "    # Calculate residuals and statistics\n",
    "    residuals = y_valid - x_valid\n",
    "    mean_residual = np.mean(residuals)\n",
    "    std_residual = np.std(residuals)\n",
    "    rms_residual = np.sqrt(np.mean(residuals**2))\n",
    "    \n",
    "    # Fractional differences for positive values\n",
    "    frac_diff = (y_valid - x_valid) / x_valid\n",
    "    mean_frac_diff = np.mean(frac_diff)\n",
    "    std_frac_diff = np.std(frac_diff)\n",
    "    \n",
    "    return {\n",
    "        'correlation': corr_coef,\n",
    "        'p_value': p_value,\n",
    "        'mean_residual': mean_residual,\n",
    "        'std_residual': std_residual,\n",
    "        'rms_residual': rms_residual,\n",
    "        'mean_frac_diff': mean_frac_diff,\n",
    "        'std_frac_diff': std_frac_diff,\n",
    "        'n_objects': len(x_valid)\n",
    "    }\n",
    "\n",
    "def create_comparison_plot(data):\n",
    "    \"\"\"\n",
    "    Create comprehensive comparison plots\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # Define color scheme\n",
    "    colors = {'scatter': '#1f77b4', 'line': '#ff7f0e', 'hist': '#2ca02c'}\n",
    "    \n",
    "    # 1. Flux comparison (log-log scale)\n",
    "    ax1 = plt.subplot(3, 4, 1)\n",
    "    valid_flux = data['valid_flux']\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        \n",
    "        ax1.scatter(x_flux, y_flux, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(x_flux), np.min(y_flux))\n",
    "        max_val = max(np.max(x_flux), np.max(y_flux))\n",
    "        ax1.plot([min_val, max_val], [min_val, max_val], '--', color=colors['line'], lw=2)\n",
    "        \n",
    "        ax1.set_xscale('log')\n",
    "        ax1.set_yscale('log')\n",
    "        ax1.set_xlabel('Personal Catalogue Flux (µJy)')\n",
    "        ax1.set_ylabel('Public Catalogue Flux (µJy)')\n",
    "        ax1.set_title('Flux Comparison (F770W)')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        stats_flux = calculate_statistics(x_flux, y_flux, np.ones(len(x_flux), dtype=bool))\n",
    "        if stats_flux:\n",
    "            ax1.text(0.05, 0.95, f'r = {stats_flux[\"correlation\"]:.3f}\\nN = {stats_flux[\"n_objects\"]}', \n",
    "                    transform=ax1.transAxes, verticalalignment='top', \n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 2. Flux error comparison (log-log scale)\n",
    "    ax2 = plt.subplot(3, 4, 2)\n",
    "    valid_flux_err = data['valid_flux_err']\n",
    "    if np.sum(valid_flux_err) > 0:\n",
    "        x_err = data['flux_err_personal'][valid_flux_err]\n",
    "        y_err = data['flux_err_public'][valid_flux_err]\n",
    "        \n",
    "        ax2.scatter(x_err, y_err, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(x_err), np.min(y_err))\n",
    "        max_val = max(np.max(x_err), np.max(y_err))\n",
    "        ax2.plot([min_val, max_val], [min_val, max_val], '--', color=colors['line'], lw=2)\n",
    "        \n",
    "        ax2.set_xscale('log')\n",
    "        ax2.set_yscale('log')\n",
    "        ax2.set_xlabel('Personal Catalogue Flux Error (µJy)')\n",
    "        ax2.set_ylabel('Public Catalogue Flux Error (µJy)')\n",
    "        ax2.set_title('Flux Error Comparison (F770W)')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        stats_err = calculate_statistics(x_err, y_err, np.ones(len(x_err), dtype=bool))\n",
    "        if stats_err:\n",
    "            ax2.text(0.05, 0.95, f'r = {stats_err[\"correlation\"]:.3f}\\nN = {stats_err[\"n_objects\"]}', \n",
    "                    transform=ax2.transAxes, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 3. AB Magnitude comparison\n",
    "    ax3 = plt.subplot(3, 4, 3)\n",
    "    valid_mag = data['valid_mag']\n",
    "    if np.sum(valid_mag) > 0:\n",
    "        x_mag = data['ab_mag_personal'][valid_mag]\n",
    "        y_mag = data['mag_public'][valid_mag]\n",
    "        \n",
    "        ax3.scatter(x_mag, y_mag, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(x_mag), np.min(y_mag))\n",
    "        max_val = max(np.max(x_mag), np.max(y_mag))\n",
    "        ax3.plot([min_val, max_val], [min_val, max_val], '--', color=colors['line'], lw=2)\n",
    "        \n",
    "        ax3.set_xlabel('Personal Catalogue AB Mag')\n",
    "        ax3.set_ylabel('Public Catalogue AB Mag')\n",
    "        ax3.set_title('AB Magnitude Comparison (F770W)')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        stats_mag = calculate_statistics(x_mag, y_mag, np.ones(len(x_mag), dtype=bool))\n",
    "        if stats_mag:\n",
    "            ax3.text(0.05, 0.95, f'r = {stats_mag[\"correlation\"]:.3f}\\nN = {stats_mag[\"n_objects\"]}', \n",
    "                    transform=ax3.transAxes, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 4. Signal-to-noise ratio comparison\n",
    "    ax4 = plt.subplot(3, 4, 4)\n",
    "    valid_snr = data['valid_flux'] & data['valid_flux_err']\n",
    "    if np.sum(valid_snr) > 0:\n",
    "        snr_personal = data['flux_personal'][valid_snr] / data['flux_err_personal'][valid_snr]\n",
    "        snr_public = data['flux_public'][valid_snr] / data['flux_err_public'][valid_snr]\n",
    "        \n",
    "        ax4.scatter(snr_personal, snr_public, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(snr_personal), np.min(snr_public))\n",
    "        max_val = max(np.max(snr_personal), np.max(snr_public))\n",
    "        ax4.plot([min_val, max_val], [min_val, max_val], '--', color=colors['line'], lw=2)\n",
    "        \n",
    "        ax4.set_xlabel('Personal Catalogue S/N')\n",
    "        ax4.set_ylabel('Public Catalogue S/N')\n",
    "        ax4.set_title('Signal-to-Noise Ratio Comparison')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        stats_snr = calculate_statistics(snr_personal, snr_public, np.ones(len(snr_personal), dtype=bool))\n",
    "        if stats_snr:\n",
    "            ax4.text(0.05, 0.95, f'r = {stats_snr[\"correlation\"]:.3f}\\nN = {stats_snr[\"n_objects\"]}', \n",
    "                    transform=ax4.transAxes, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 5. Flux residuals vs flux\n",
    "    ax5 = plt.subplot(3, 4, 5)\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        residuals = y_flux - x_flux\n",
    "        \n",
    "        ax5.scatter(x_flux, residuals, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        ax5.axhline(y=0, color=colors['line'], linestyle='--', lw=2)\n",
    "        ax5.set_xscale('log')\n",
    "        ax5.set_xlabel('Personal Catalogue Flux (µJy)')\n",
    "        ax5.set_ylabel('Flux Residuals (Public - Personal)')\n",
    "        ax5.set_title('Flux Residuals vs Flux')\n",
    "        ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Fractional flux differences\n",
    "    ax6 = plt.subplot(3, 4, 6)\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        frac_diff = (y_flux - x_flux) / x_flux\n",
    "        \n",
    "        ax6.scatter(x_flux, frac_diff, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        ax6.axhline(y=0, color=colors['line'], linestyle='--', lw=2)\n",
    "        ax6.set_xscale('log')\n",
    "        ax6.set_xlabel('Personal Catalogue Flux (µJy)')\n",
    "        ax6.set_ylabel('Fractional Flux Difference')\n",
    "        ax6.set_title('Fractional Flux Differences')\n",
    "        ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 7. Magnitude residuals vs magnitude\n",
    "    ax7 = plt.subplot(3, 4, 7)\n",
    "    if np.sum(valid_mag) > 0:\n",
    "        x_mag = data['ab_mag_personal'][valid_mag]\n",
    "        y_mag = data['mag_public'][valid_mag]\n",
    "        mag_residuals = y_mag - x_mag\n",
    "        \n",
    "        ax7.scatter(x_mag, mag_residuals, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        ax7.axhline(y=0, color=colors['line'], linestyle='--', lw=2)\n",
    "        ax7.set_xlabel('Personal Catalogue AB Mag')\n",
    "        ax7.set_ylabel('Magnitude Residuals (Public - Personal)')\n",
    "        ax7.set_title('Magnitude Residuals vs Magnitude')\n",
    "        ax7.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 8. Error bar comparison\n",
    "    ax8 = plt.subplot(3, 4, 8)\n",
    "    if np.sum(valid_flux) & np.sum(valid_flux_err) > 0:\n",
    "        valid_both = valid_flux & valid_flux_err\n",
    "        x_flux = data['flux_personal'][valid_both]\n",
    "        y_flux = data['flux_public'][valid_both]\n",
    "        x_err = data['flux_err_personal'][valid_both]\n",
    "        y_err = data['flux_err_public'][valid_both]\n",
    "        \n",
    "        # Plot a subset of points with error bars to avoid cluttering\n",
    "        n_plot = min(50, len(x_flux))\n",
    "        indices = np.random.choice(len(x_flux), n_plot, replace=False)\n",
    "        \n",
    "        ax8.errorbar(x_flux[indices], y_flux[indices], \n",
    "                    xerr=x_err[indices], yerr=y_err[indices],\n",
    "                    fmt='o', alpha=0.6, capsize=3, color=colors['scatter'])\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(x_flux), np.min(y_flux))\n",
    "        max_val = max(np.max(x_flux), np.max(y_flux))\n",
    "        ax8.plot([min_val, max_val], [min_val, max_val], '--', color=colors['line'], lw=2)\n",
    "        \n",
    "        ax8.set_xscale('log')\n",
    "        ax8.set_yscale('log')\n",
    "        ax8.set_xlabel('Personal Catalogue Flux (µJy)')\n",
    "        ax8.set_ylabel('Public Catalogue Flux (µJy)')\n",
    "        ax8.set_title(f'Flux with Error Bars (N={n_plot} random subset)')\n",
    "        ax8.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 9. Flux histogram comparison\n",
    "    ax9 = plt.subplot(3, 4, 9)\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        \n",
    "        bins = np.logspace(np.log10(min(np.min(x_flux), np.min(y_flux))), \n",
    "                          np.log10(max(np.max(x_flux), np.max(y_flux))), 20)\n",
    "        \n",
    "        ax9.hist(x_flux, bins=bins, alpha=0.6, label='Personal', color=colors['scatter'])\n",
    "        ax9.hist(y_flux, bins=bins, alpha=0.6, label='Public', color=colors['line'])\n",
    "        ax9.set_xscale('log')\n",
    "        ax9.set_xlabel('Flux (µJy)')\n",
    "        ax9.set_ylabel('Number of Objects')\n",
    "        ax9.set_title('Flux Distribution Comparison')\n",
    "        ax9.legend()\n",
    "        ax9.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 10. Magnitude histogram comparison\n",
    "    ax10 = plt.subplot(3, 4, 10)\n",
    "    if np.sum(valid_mag) > 0:\n",
    "        x_mag = data['ab_mag_personal'][valid_mag]\n",
    "        y_mag = data['mag_public'][valid_mag]\n",
    "        \n",
    "        bins = np.linspace(min(np.min(x_mag), np.min(y_mag)), \n",
    "                          max(np.max(x_mag), np.max(y_mag)), 20)\n",
    "        \n",
    "        ax10.hist(x_mag, bins=bins, alpha=0.6, label='Personal', color=colors['scatter'])\n",
    "        ax10.hist(y_mag, bins=bins, alpha=0.6, label='Public', color=colors['line'])\n",
    "        ax10.set_xlabel('AB Magnitude')\n",
    "        ax10.set_ylabel('Number of Objects')\n",
    "        ax10.set_title('Magnitude Distribution Comparison')\n",
    "        ax10.legend()\n",
    "        ax10.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 11. Residuals histogram\n",
    "    ax11 = plt.subplot(3, 4, 11)\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        frac_diff = (y_flux - x_flux) / x_flux\n",
    "        \n",
    "        ax11.hist(frac_diff, bins=30, alpha=0.7, color=colors['hist'])\n",
    "        ax11.axvline(x=0, color=colors['line'], linestyle='--', lw=2)\n",
    "        ax11.axvline(x=np.median(frac_diff), color='red', linestyle='-', lw=2, label=f'Median: {np.median(frac_diff):.3f}')\n",
    "        ax11.set_xlabel('Fractional Flux Difference')\n",
    "        ax11.set_ylabel('Number of Objects')\n",
    "        ax11.set_title('Fractional Difference Distribution')\n",
    "        ax11.legend()\n",
    "        ax11.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 12. Summary statistics text\n",
    "    ax12 = plt.subplot(3, 4, 12)\n",
    "    ax12.axis('off')\n",
    "    \n",
    "    summary_text = \"PHOTOMETRY COMPARISON SUMMARY\\n\\n\"\n",
    "    \n",
    "    if np.sum(valid_flux) > 0:\n",
    "        stats_flux = calculate_statistics(data['flux_personal'][valid_flux], \n",
    "                                        data['flux_public'][valid_flux], \n",
    "                                        np.ones(np.sum(valid_flux), dtype=bool))\n",
    "        if stats_flux:\n",
    "            summary_text += f\"FLUX COMPARISON (N={stats_flux['n_objects']}):\\n\"\n",
    "            summary_text += f\"  Correlation: {stats_flux['correlation']:.3f}\\n\"\n",
    "            summary_text += f\"  Mean fractional diff: {stats_flux['mean_frac_diff']:.3f}\\n\"\n",
    "            summary_text += f\"  Std fractional diff: {stats_flux['std_frac_diff']:.3f}\\n\\n\"\n",
    "    \n",
    "    if np.sum(valid_mag) > 0:\n",
    "        stats_mag = calculate_statistics(data['ab_mag_personal'][valid_mag], \n",
    "                                       data['mag_public'][valid_mag], \n",
    "                                       np.ones(np.sum(valid_mag), dtype=bool))\n",
    "        if stats_mag:\n",
    "            summary_text += f\"MAGNITUDE COMPARISON (N={stats_mag['n_objects']}):\\n\"\n",
    "            summary_text += f\"  Correlation: {stats_mag['correlation']:.3f}\\n\"\n",
    "            summary_text += f\"  Mean residual: {stats_mag['mean_residual']:.3f} mag\\n\"\n",
    "            summary_text += f\"  RMS residual: {stats_mag['rms_residual']:.3f} mag\\n\\n\"\n",
    "    \n",
    "    summary_text += f\"DATA COVERAGE:\\n\"\n",
    "    summary_text += f\"  Total objects: {len(data['table'])}\\n\"\n",
    "    summary_text += f\"  Valid flux measurements: {np.sum(valid_flux)}\\n\"\n",
    "    summary_text += f\"  Valid flux errors: {np.sum(valid_flux_err)}\\n\"\n",
    "    summary_text += f\"  Valid magnitudes: {np.sum(valid_mag)}\\n\"\n",
    "    \n",
    "    ax12.text(0.05, 0.95, summary_text, transform=ax12.transAxes, \n",
    "             verticalalignment='top', fontfamily='monospace', fontsize=10,\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    #plt.suptitle('MIRI F770W Photometry Comparison: Personal vs Public Catalogue', \n",
    "    #            fontsize=24, y=0.98)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Main execution function\n",
    "def analyze_photometry_comparison(fits_file_path, output_plot_path=None):\n",
    "    \"\"\"\n",
    "    Main function to perform photometry comparison analysis\n",
    "    \"\"\"\n",
    "    print(\"Loading and preparing data...\")\n",
    "    data = load_and_prepare_data(fits_file_path)\n",
    "    \n",
    "    print(\"Creating comparison plots...\")\n",
    "    fig = create_comparison_plot(data)\n",
    "    \n",
    "    if output_plot_path:\n",
    "        print(f\"Saving plot to {output_plot_path}\")\n",
    "        plt.savefig(output_plot_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PHOTOMETRY COMPARISON ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    valid_flux = data['valid_flux']\n",
    "    valid_mag = data['valid_mag']\n",
    "    \n",
    "    if np.sum(valid_flux) > 0:\n",
    "        stats_flux = calculate_statistics(data['flux_personal'][valid_flux], \n",
    "                                        data['flux_public'][valid_flux], \n",
    "                                        np.ones(np.sum(valid_flux), dtype=bool))\n",
    "        if stats_flux:\n",
    "            print(f\"\\nFLUX COMPARISON ({stats_flux['n_objects']} objects):\")\n",
    "            print(f\"  Pearson correlation coefficient: {stats_flux['correlation']:.4f}\")\n",
    "            print(f\"  Mean fractional difference: {stats_flux['mean_frac_diff']:.4f}\")\n",
    "            print(f\"  Standard deviation of fractional differences: {stats_flux['std_frac_diff']:.4f}\")\n",
    "            print(f\"  RMS of absolute residuals: {stats_flux['rms_residual']:.4f} µJy\")\n",
    "    \n",
    "    if np.sum(valid_mag) > 0:\n",
    "        stats_mag = calculate_statistics(data['ab_mag_personal'][valid_mag], \n",
    "                                       data['mag_public'][valid_mag], \n",
    "                                       np.ones(np.sum(valid_mag), dtype=bool))\n",
    "        if stats_mag:\n",
    "            print(f\"\\nMAGNITUDE COMPARISON ({stats_mag['n_objects']} objects):\")\n",
    "            print(f\"  Pearson correlation coefficient: {stats_mag['correlation']:.4f}\")\n",
    "            print(f\"  Mean magnitude residual: {stats_mag['mean_residual']:.4f} mag\")\n",
    "            print(f\"  Standard deviation of residuals: {stats_mag['std_residual']:.4f} mag\")\n",
    "            print(f\"  RMS of residuals: {stats_mag['rms_residual']:.4f} mag\")\n",
    "    \n",
    "    print(f\"\\nDATA COVERAGE:\")\n",
    "    print(f\"  Total objects in table: {len(data['table'])}\")\n",
    "    print(f\"  Objects with valid flux measurements: {np.sum(valid_flux)}\")\n",
    "    print(f\"  Objects with valid magnitude measurements: {np.sum(valid_mag)}\")\n",
    "    \n",
    "    return data, fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Replace with your FITS file path\n",
    "fits_file_path = '/home/bpc/University/master/Red_Cardinal/catalogues/COSMOSWeb_id_matched.fits'\n",
    "\n",
    "\n",
    "# Optional: specify output path for the plot\n",
    "output_plot_path = '/home/bpc/University/master/Red_Cardinal/photometry/photometry_comparisons/photometry_comparison_plot.png'\n",
    "\n",
    "# Run the analysis\n",
    "data, fig = analyze_photometry_comparison(fits_file_path, output_plot_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
