{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photometry on MIRI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import subprocess\n",
    "import miri_utils.photometry_tools as phot\n",
    "import pickle as pkl\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import FITSFixedWarning\n",
    "from astropy.table import Table, join\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=FITSFixedWarning)\n",
    "\n",
    "\n",
    "cutout_dir = \"/Users/benjamincollins/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "phot_dir = \"/Users/benjamincollins/University/master/Red_Cardinal/photometry/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section to obtain modified apertures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect Amirs table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path =  '/Users/benjamincollins/University/master/Red_Cardinal/catalogues/Flux_Aperture_PSFMatched_AperCorr_old.fits'\n",
    "table_path =  '/Users/benjamincollins/University/master/Red_Cardinal/photometry/phot_tables/Photometry_Table_MIRI_v6.fits'\n",
    "\n",
    "table = Table.read(table_path)\n",
    "#print(table[:5])\n",
    "table.info()\n",
    "print(table.columns)\n",
    "print(table['ID'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and call the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_dir = \"/Users/benjamincollins/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "phot_dir = \"/Users/benjamincollins/University/master/Red_Cardinal/photometry/\"\n",
    "mask_folder = \"/Users/benjamincollins/University/master/Red_Cardinal/photometry/apertures/masks/\"\n",
    "\n",
    "\n",
    "# Get all FITS file paths\n",
    "fits_files = glob.glob(os.path.join(cutout_dir, '*.fits'))\n",
    "\n",
    "# Get the basenames of the FITS files\n",
    "fits_fnames = [os.path.basename(f) for f in fits_files]\n",
    "\n",
    "adjusted_apertures = []\n",
    "\n",
    "for fname in fits_fnames:\n",
    "    id = fname.split('_')[0]\n",
    "    filter = fname.split('_')[1]\n",
    "    survey_obs = fname.split('_')[3]\n",
    "    \n",
    "    if '003' in survey_obs:\n",
    "        survey = 'primer'\n",
    "        obs = '003'\n",
    "    elif '004' in survey_obs:\n",
    "        survey = 'primer'\n",
    "        obs = '004'\n",
    "    elif 'cweb1' in survey_obs:\n",
    "        survey = 'cweb'\n",
    "        obs = '1'\n",
    "    elif 'cweb2' in survey_obs:\n",
    "        survey = 'cweb'\n",
    "        obs = '2'\n",
    "    elif 'cos3d1' in survey_obs:\n",
    "        survey = 'cos3d'\n",
    "        obs = '1'\n",
    "    elif 'cos3d2' in survey_obs:\n",
    "        survey = 'cos3d'\n",
    "        obs = '2'\n",
    "    else:\n",
    "        print(f\"Unknown survey and/or observation number for galaxy {id}:\\n\")\n",
    "        print(survey_obs)\n",
    "    \n",
    "    # Call and collect results\n",
    "    result = phot.adjust_aperture(id, filter, survey, obs, phot_dir, mask_folder=mask_folder, rescale=True)\n",
    "    \n",
    "    if result:\n",
    "        adjusted_apertures.append(result)\n",
    "\n",
    "# After loop: create a DataFrame\n",
    "df_apertures = pd.DataFrame(adjusted_apertures)\n",
    "\n",
    "# v5 for manually modified ellipse sizes\n",
    "df_path = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/apertures/aperture_table_small.csv'\n",
    "\n",
    "# (optional) Save to CSV or integrate into photometry table\n",
    "#df_apertures.to_csv(df_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily open any given FITS file with its corresponding ellipse region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Launch DS9 with the MIRI cutout and the overplotted aperture ---\n",
    "region_dir = \"/Users/benjamincollins/University/master/Red_Cardinal/photometry/regions/\"\n",
    "cutout_dir = \"/Users/benjamincollins/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "phot_dir   = \"/Users/benjamincollins/University/master/Red_Cardinal/photometry/\"\n",
    "\n",
    "id = '10245'\n",
    "filter = 'F770W'\n",
    "survey_obs = 'primer004'\n",
    "cutout_path = os.path.join(cutout_dir, f'{id}_{filter}_cutout_{survey_obs}.fits')\n",
    "reg_path = os.path.join(region_dir, f'{id}_{survey_obs}_aperture.reg')\n",
    "subprocess.run([\"ds9\", cutout_path, \"-regions\", reg_path])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path =  '/Users/benjamincollins/University/master/Red_Cardinal/Flux_Aperture_PSFMatched_AperCorr_old.fits'\n",
    "\n",
    "table = Table.read(table_path)\n",
    "print(table[:5])\n",
    "table.info()\n",
    "print(table['Image_Err'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this cell for updated photometry input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters ---\n",
    "cutouts_folder = \"/Users/benjamincollins/University/master/Red_Cardinal/cutouts_phot/\"\n",
    "#aperture_table = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/aperture_table_v5.csv'\n",
    "#fig_path = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/Plots_MIRI_phot_v5/'\n",
    "#fig_path = None\n",
    "\n",
    "# Get all possible F770W files\n",
    "all_f770w_files = glob.glob(os.path.join(cutouts_folder, f'*F770W*.fits'))\n",
    "\n",
    "# Group F770W files by galaxy ID and filter\n",
    "f770w_files = []\n",
    "galaxy_ids = set([os.path.basename(f).split('_')[0] for f in all_f770w_files])\n",
    "\n",
    "#galaxy_ids = ['8465', '7922', '9871', '12202', '8843', '7904', '8338', '10021', '10245', '11136', '12340', '20397']\n",
    "\n",
    "\n",
    "for galaxy_id in galaxy_ids:\n",
    "    # Find all F770W files for this galaxy ID\n",
    "    matching_files = [f for f in all_f770w_files if os.path.basename(f).startswith(galaxy_id)]\n",
    "    \n",
    "    # Handle special case for galaxy 11853\n",
    "    if galaxy_id == '11853':\n",
    "        # Use the cweb2 file if available\n",
    "        cweb2_files = [f for f in matching_files if 'cweb2' in f.lower()]\n",
    "        if cweb2_files:\n",
    "            f770w_files.append(cweb2_files[0])\n",
    "            continue  # Skip to the next galaxy\n",
    "    \n",
    "    # Prioritise PRIMER over COSMOS-Web\n",
    "    primer_files = [f for f in matching_files if 'primer' in f.lower()]\n",
    "    cweb_files = [f for f in matching_files if 'cweb' in f.lower()]\n",
    "    \n",
    "    if primer_files:\n",
    "        f770w_files.append(primer_files[0])  # Prefer PRIMER file\n",
    "    elif cweb_files:\n",
    "        f770w_files.append(cweb_files[0])  # Use CWEB only if no PRIMER available\n",
    "\n",
    "\n",
    "# Get all F1000W files\n",
    "f1000w_files = glob.glob(os.path.join(cutouts_folder, f'*F1000W*.fits'))\n",
    "\n",
    "# Get all F1800W files\n",
    "f1800w_files = glob.glob(os.path.join(cutouts_folder, f'*F1800W*.fits'))\n",
    "\n",
    "# Get all F1800W files\n",
    "f2100w_files = glob.glob(os.path.join(cutouts_folder, f'*F2100W*.fits'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section to compare different aperture sizes with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "## STEP 1:   PERFORM PHOTOMETRY     ##\n",
    "######################################\n",
    "\n",
    "output_folder = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "aperture_table_small = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/apertures/aperture_table_small.csv'\n",
    "\n",
    "phot.perform_photometry(f770w_files, aperture_table_small, output_folder, suffix='small_v3', apply_aper_corr=False)\n",
    "phot.perform_photometry(f1000w_files, aperture_table_small, output_folder, suffix='small_v3', apply_aper_corr=False)\n",
    "phot.perform_photometry(f1800w_files, aperture_table_small, output_folder, suffix='small_v3', apply_aper_corr=False)\n",
    "phot.perform_photometry(f2100w_files, aperture_table_small, output_folder, suffix='small_v3', apply_aper_corr=False)\n",
    "\n",
    "aperture_table_big = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/apertures/aperture_table_big.csv'\n",
    "\n",
    "phot.perform_photometry(f770w_files, aperture_table_big, output_folder, suffix='big_v3', apply_aper_corr=False)\n",
    "phot.perform_photometry(f1000w_files, aperture_table_big, output_folder, suffix='big_v3', apply_aper_corr=False)\n",
    "phot.perform_photometry(f1800w_files, aperture_table_big, output_folder, suffix='big_v3', apply_aper_corr=False)\n",
    "phot.perform_photometry(f2100w_files, aperture_table_big, output_folder, suffix='big_v3', apply_aper_corr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "## STEP 2:   CREATE FITS TABLE      ##\n",
    "######################################\n",
    "\n",
    "results_dir = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/results/'\n",
    "\n",
    "fits_table_small = 'Flux_SmallAperture_NoCorr_MIRI_v3.fits'\n",
    "\n",
    "f770w_fname  = os.path.join(results_dir, 'phot_table_F770W_small_v3.csv')\n",
    "f1000w_fname = os.path.join(results_dir, 'phot_table_F1000W_small_v3.csv')\n",
    "f1800w_fname = os.path.join(results_dir, 'phot_table_F1800W_small_v3.csv')\n",
    "f2100w_fname = os.path.join(results_dir, 'phot_table_F2100W_small_v3.csv')\n",
    "\n",
    "csv_paths = [f770w_fname, f1000w_fname, f1800w_fname, f2100w_fname]\n",
    "\n",
    "# Now create the combined FITS table\n",
    "phot.create_fits_table_from_csv(csv_paths, output_file=fits_table_small)\n",
    "\n",
    "\n",
    "\n",
    "fits_table_big = 'Flux_BigAperture_NoCorr_MIRI_v3.fits'\n",
    "\n",
    "f770w_fname  = os.path.join(results_dir, 'phot_table_F770W_big_v3.csv')\n",
    "f1000w_fname = os.path.join(results_dir, 'phot_table_F1000W_big_v3.csv')\n",
    "f1800w_fname = os.path.join(results_dir, 'phot_table_F1800W_big_v3.csv')\n",
    "f2100w_fname = os.path.join(results_dir, 'phot_table_F2100W_big_v3.csv')\n",
    "\n",
    "csv_paths = [f770w_fname, f1000w_fname, f1800w_fname, f2100w_fname]\n",
    "\n",
    "# Now create the combined FITS table\n",
    "phot.create_fits_table_from_csv(csv_paths, output_file=fits_table_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look at the tables and compare the effect of the aperture correction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the two tables\n",
    "table_small_path = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/phot_tables/Flux_SmallAperture_NoCorr_MIRI_v3.fits'\n",
    "table_big_path = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/phot_tables/Flux_BigAperture_NoCorr_MIRI_v3.fits'\n",
    "\n",
    "table_small = Table.read(table_small_path)\n",
    "filters_small = table_small['Filters']\n",
    "\n",
    "non_detections = {\n",
    "    'F770W': [11137, 17793, 8843, 12175, 7696, 7185, 8465, 19098, 12443, 12202, 21547, 9517, 9901, 10415, 12213, \n",
    "              21451, 11853, 11086, 22606, 18769, 9809, 11481, 21472, 19681, 12513, 21218, 12133, 16615, 10600, 11247, 20720, 17534], \n",
    "    'F1000W': [17984, 12513, 12164, 12133, 11716, 16615, 16424, 12202, 11723, 11853, 13297, 18327, 12443, 17534], \n",
    "    'F1800W': [12164, 11716, 10565, 10054, 11723, 12175, 19024, 8465, 8338, 18769, 7102, 10400, 12513, 19681, 7904, \n",
    "               10339, 12133, 10600, 9517, 10415, 11247, 12213, 11451, 7934], \n",
    "    'F2100W': [17984, 12164, 11716, 16516, 11723, 11853, 12175, 16474, 12443, 12513, 12133, 16615, 16424, 12202, \n",
    "               12332, 17517, 12014, 11247, 13297, 12213, 17916, 17534]\n",
    "    }\n",
    "\n",
    "phot.compare_aperture_statistics(table_small_path, table_big_path, summary_doc_path=\"summary_aperture_comparison.md\", non_detections=non_detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and display aperture statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_file = '/Users/benjamincollins/University/Master/Red_Cardinal/photometry/apertures/aperture_comparisons/comparison_data.pkl'\n",
    "with open(stats_file, 'rb') as f:\n",
    "    stats = pkl.load(f)\n",
    "    \n",
    "non_detections = {\n",
    "    'F770W': [11137, 17793, 8843, 12175, 7696, 7185, 8465, 19098, 12443, 12202, 21547, 9517, 9901, 10415, 12213, \n",
    "              21451, 11853, 11086, 22606, 18769, 9809, 11481, 21472, 19681, 12513, 21218, 12133, 16615, 10600, 11247, 20720, 17534], \n",
    "    'F1000W': [17984, 12513, 12164, 12133, 11716, 16615, 16424, 12202, 11723, 11853, 13297, 18327, 12443, 17534], \n",
    "    'F1800W': [12164, 11716, 10565, 10054, 11723, 12175, 19024, 8465, 8338, 18769, 7102, 10400, 12513, 19681, 7904, \n",
    "               10339, 12133, 10600, 9517, 10415, 11247, 12213, 11451, 7934, 19098], \n",
    "    'F2100W': [17984, 12164, 11716, 16516, 11723, 11853, 12175, 16474, 12443, 12513, 12133, 16615, 16424, 12202, \n",
    "               12332, 17517, 12014, 11247, 13297, 12213, 17916, 17534]\n",
    "    }\n",
    "\n",
    "fig_path = '/Users/benjamincollins/University/Master/Red_Cardinal/photometry/apertures/aperture_comparisons/'\n",
    "phot.plot_aperture_summary(stats, non_detections, scaling=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create statistics plot for the appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_file = '/Users/benjamincollins/University/Master/Red_Cardinal/photometry/apertures/aperture_comparisons/comparison_data.pkl'\n",
    "with open(stats_file, 'rb') as f:\n",
    "    stats_dict = pkl.load(f)\n",
    " \n",
    "appendix_fig = '/Users/benjamincollins/University/Master/Red_Cardinal/photometry/apertures/aperture_comparisons/appendix_figure_new.png'\n",
    "\n",
    "non_detections = {\n",
    "    # I include ID 11451 here as I had to manually remove the outlier. It is, however, a detection.\n",
    "    'F770W': [11137, 17793, 8843, 12175, 7696, 7185, 8465, 19098, 12443, 12202, 21547, 9517, 9901, 10415, 12213, \n",
    "              21451, 11853, 11086, 22606, 18769, 9809, 11481, 21472, 19681, 12513, 21218, 12133, 16615, 10600, 11247, 20720, 17534, 11451], \n",
    "    'F1000W': [17984, 12513, 12164, 12133, 11716, 16615, 16424, 12202, 11723, 11853, 13297, 18327, 12443, 17534], \n",
    "    'F1800W': [12164, 11716, 10565, 10054, 11723, 12175, 19024, 8465, 8338, 18769, 7102, 10400, 12513, 19681, 7904, \n",
    "               10339, 12133, 10600, 9517, 10415, 11247, 12213, 11451, 7934, 19098], # also added 19098 here as it is plagued by detector artefacts \n",
    "    'F2100W': [17984, 12164, 11716, 16516, 11723, 11853, 12175, 16474, 12443, 12513, 12133, 16615, 16424, 12202, \n",
    "               12332, 17517, 12014, 11247, 13297, 12213, 17916, 17534]\n",
    "    }\n",
    "\n",
    "phot.plot_appendix_figure(data_comparison=stats_dict, non_detections=non_detections, fig_path=appendix_fig, scaling='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to deal with the outlier! ID 11451 is a detection, but its source is not centred on the image, therefore the aperture sizes yield inconsistent results.\n",
    "\n",
    "Outlier in F770W with ratio 1.74 for galaxy ID 11420\n",
    "Outlier in F770W with ratio 3.47 for galaxy ID 11451\n",
    "Outlier in F770W with ratio 1.65 for galaxy ID 17669\n",
    "Outlier in F770W with ratio 1.54 for galaxy ID 19024\n",
    "Outlier in F770W with ratio 1.71 for galaxy ID 8338\n",
    "\n",
    "Outlier in F1800W with ratio 1.53 for galaxy ID 11494\n",
    "Outlier in F1800W with ratio 1.54 for galaxy ID 16874\n",
    "Outlier in F1800W with ratio 1.62 for galaxy ID 19098\n",
    "Outlier in F1800W with ratio 1.67 for galaxy ID 19563\n",
    "Outlier in F1800W with ratio 1.52 for galaxy ID 9871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "phot.show_apertures(11451, 'F770W')\n",
    "phot.show_apertures(8338, 'F770W')\n",
    "phot.show_apertures(11420, 'F770W')\n",
    "phot.show_apertures(17669, 'F770W')\n",
    "phot.show_apertures(19024, 'F770W')\n",
    "\n",
    "    \n",
    "phot.show_apertures(11494, 'F1800W')\n",
    "phot.show_apertures(16874, 'F1800W')\n",
    "phot.show_apertures(19098, 'F1800W')\n",
    "phot.show_apertures(19563, 'F1800W')\n",
    "phot.show_apertures(9871, 'F1800W')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils.aperture import EllipticalAperture\n",
    "\n",
    "objid = 13174\n",
    "band = \"F2100W\"\n",
    "\n",
    "aperture_table = \"/Users/benjamincollins/University/Master/Red_Cardinal/photometry/apertures/aperture_table.csv\"\n",
    "df = pd.read_csv(aperture_table, index_col=False)\n",
    "\n",
    "ap = df.loc[df['ID'] == objid].squeeze()\n",
    "print(ap['Apr_A'])\n",
    "\n",
    "vis_data = phot.load_vis(f'/Users/benjamincollins/University/master/Red_Cardinal/photometry/vis_data/{objid}_{band}.h5')\n",
    "output_file= os.path.join(f'/Users/benjamincollins/University/master/Red_Cardinal/photometry/apertures/aperture_comparisons/{objid}_{band}.png')\n",
    "\n",
    "# Extract data from the dictionary\n",
    "image_data = vis_data['original_data']\n",
    "background_plane = vis_data['background_plane']\n",
    "background_subtracted = vis_data['background_subtracted']\n",
    "segm_mask = vis_data['segmentation_mask']\n",
    "mask_vis = vis_data['mask_vis']\n",
    "aperture_params = vis_data['aperture_params']\n",
    "sigma = vis_data['sigma']\n",
    "region_name = vis_data['region_name']\n",
    "galaxy_id = vis_data['galaxy_id']\n",
    "filter = vis_data['filter']\n",
    "\n",
    "# Create aperture objects for plotting\n",
    "x_center = aperture_params['x_center']\n",
    "y_center = aperture_params['y_center']\n",
    "a = aperture_params['a']\n",
    "b = aperture_params['b']\n",
    "theta = aperture_params['theta']\n",
    "\n",
    "big_aperture = EllipticalAperture(\n",
    "    positions=(x_center, y_center),\n",
    "    a=a,\n",
    "    b=b,\n",
    "    theta=theta\n",
    ")\n",
    "\n",
    "small_aperture = EllipticalAperture(\n",
    "    positions=(x_center, y_center),\n",
    "    a=a/2,\n",
    "    b=b/2,\n",
    "    theta=ap['Apr_Theta']\n",
    ")\n",
    "\n",
    "\n",
    "# Create figure with three subplots in a horizontal row\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "# Background-subtracted data\n",
    "vmin = np.nanpercentile(background_subtracted, 5)\n",
    "vmax = np.nanpercentile(background_subtracted, 95)\n",
    "\n",
    "im1 = ax.imshow(background_subtracted, origin='lower', cmap='gray', vmin=vmin, vmax=vmax)\n",
    "small_aperture.plot(ax=ax, color='red', lw=2, label='Small Aperture')\n",
    "big_aperture.plot(ax=ax, color='blue', lw=3, label='Large Aperture')\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "    \n",
    "# Tight layout and saving the figure‚\n",
    "plt.tight_layout()\n",
    "#plt.suptitle(f'Galaxy ID {galaxy_id} - {filter}', fontsize=14)\n",
    "plt.subplots_adjust(top=0.85)  # Adjust to prevent overlap with annotation\n",
    "plt.savefig(output_file, dpi=150)\n",
    "plt.show()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section of the notebook dealing with detection statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phot_table_path = '/Users/benjamincollins/University/master/Red_Cardinal/miri_photometry_v1/Photometry_Table_MIRI.fits'\n",
    "phot_table_path = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/phot_tables/Photometry_Table_MIRI_v6.fits'\n",
    "table = Table.read(phot_table_path)\n",
    "flux = table['Flux']\n",
    "err  = table['Flux_Err']\n",
    "\n",
    "bands = ['F770W', 'F1000W', 'F1800W', 'F2100W']\n",
    "auto_flags = {band: [] for band in bands}\n",
    "\n",
    "gal_ids = [id.decode() if isinstance(id, bytes) else str(id) for id in table['ID']]\n",
    "\n",
    "sn_threshold = 3.0\n",
    "\n",
    "# Collect all data for comprehensive analysis\n",
    "for idx, band in enumerate(bands):  # bands = [\"F770W\", \"F1000W\", \"F1800W\", \"F2100W\"]\n",
    "\n",
    "    print(\"Analysing band: \", band)\n",
    "    for gid in gal_ids:\n",
    "        index = gal_ids.index(gid)\n",
    "\n",
    "        # Fluxes (convert to µJy)\n",
    "        flux = table['Flux'][index][idx] * 1e6\n",
    "        flux_err = table['Flux_Err'][index][idx] * 1e6\n",
    "        \n",
    "        if gid == \"11723\": \n",
    "            print(f\"Galaxy ID: {gid}, Band: {band}, Flux: {flux:.2f} µJy, Flux Error: {flux_err:.2f} µJy, S/N: {flux/flux_err:.2f}\")\n",
    "        \n",
    "        # Skip if any crucial value is invalid\n",
    "        if not (np.isfinite(flux) and (flux > 0) and np.isfinite(flux_err)):\n",
    "            continue\n",
    "        sn = flux / flux_err    \n",
    "        if sn < sn_threshold or flux <= 0:\n",
    "            print(f\"Galaxy ID: {gid}, Band: {band}, S/N: {sn:.2f}, Flux: {flux:.2f} µJy, Flux Error: {flux_err:.2f} µJy\")\n",
    "            auto_flags[band].append(int(gid))\n",
    "            \n",
    "print(auto_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_file = '/Users/benjamincollins/University/Master/Red_Cardinal/photometry/apertures/aperture_comparisons/comparison_data.pkl'\n",
    "with open(stats_file, 'rb') as f:\n",
    "    data_comparison = pkl.load(f)\n",
    "\n",
    "outliers = phot.analyse_outliers(data_comparison, flags=auto_flags, threshold=2.0)\n",
    "display(outliers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's figure out where the huge discrepancy comes from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_flags = {\n",
    "        \"F770W\": [7696,7730,8465,8843,9517,9809,9901,9986,10415,10600,11086,11137,\n",
    "            11247,11451,11481,11853,12133,12175,12202,12213,12443,12513,16424,16615,\n",
    "            17534,17793,18769,19024,19098,19307,19681,20720,21218,21424,21451,\n",
    "            21472,21477,21547,22606], \n",
    "        \"F1000W\": [11716,11723,11853,12133,12164,12202,12332,12443,12513,13297,16424,\n",
    "                    16615,17534,17793,17984,18327,19307],\n",
    "        \"F1800W\": [7102,7904,7922,7934,8338,8465,9517,10054,10128,10339,10400,10415,\n",
    "                    10565,10592,10600,11142,11247,11420,11451,11716,11723,12014,12133,\n",
    "                    12164,12175,12202,12213,12332,12513,16419,18332,18769,19024,19098,\n",
    "                    19393,19563,19681,21451],\n",
    "        \"F2100W\": [7102,11142,11247,11494,11716,11723,11853,12014,12133,12164,12175,\n",
    "                    12202,12213,12332,12443,12513,13297,16419,16424,16474,16516,16615,\n",
    "                    16874,17000,17517,17534,17842,17916,17984,18094]\n",
    "    }\n",
    "\n",
    "auto_flags = {\n",
    "    'F770W': [7185, 7696, 9809, 9901, 10415, 11247, 11481, 12133, 12175, 12443, 12513, 16615, 17534, 17793, 20720, 21218, 21451, 22606], \n",
    "    'F1000W': [11716, 11723, 12202, 13297, 16424, 17534, 17984, 18327], \n",
    "    'F1800W': [7904, 9517, 10054, 10339, 10415, 10565, 10600, 11247, 11451, 12133, 18769], \n",
    "    'F2100W': [11247, 11716, 11723, 12133, 12202, 12332, 16516, 16615, 17517, 17534, 17916, 17984]\n",
    "    }\n",
    "\n",
    "\n",
    "manual_only = {k: v for k, v in manual_flags.items() if k not in auto_flags}\n",
    "auto_only   = {k: v for k, v in auto_flags.items() if k not in manual_flags}\n",
    "both        = {k: v for k, v in manual_flags.items() if k in auto_flags}\n",
    "\n",
    "# Find discrepancies in overlapping keys\n",
    "discrepant_filters = {}\n",
    "for gal in set(manual_flags) & set(auto_flags): # loop through galaxies in both dicts\n",
    "    diff = set(manual_flags[gal]) ^ set(auto_flags[gal])    # gives you the symmetric difference\n",
    "    if diff:\n",
    "        discrepant_filters[gal] = diff\n",
    "\n",
    "from astropy.visualization import ZScaleInterval, ImageNormalize, AsinhStretch\n",
    "\n",
    "bands = ['F770W', 'F1000W', 'F1800W', 'F2100W']\n",
    "\n",
    "for band in bands:\n",
    "    ids = discrepant_filters.get(band, [])\n",
    "    offset = 0\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    for i, objid in enumerate(ids):\n",
    "        \n",
    "        try:\n",
    "            vis_data = phot.load_vis(f\"/Users/benjamincollins/University/Master/Red_Cardinal/photometry/vis_data/{objid}_{band}.h5\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"⚠️ No visualisation data file found for {objid} in {band}\")\n",
    "            continue\n",
    "        \n",
    "        nrows = int(np.ceil(len(ids)/4))\n",
    "        ax = plt.subplot(nrows, 4, i+1)\n",
    "    \n",
    "        try:\n",
    "            \n",
    "            img = vis_data[\"background_subtracted\"]\n",
    "            \n",
    "            image_data = vis_data[\"original_data\"]\n",
    "            source_mask_bool = vis_data[\"source_mask\"]\n",
    "            segm_mask = vis_data[\"segmentation_mask\"]\n",
    "            combined_mask = source_mask_bool | segm_mask | np.isnan(image_data)\n",
    "\n",
    "            clean_image = np.where(combined_mask, np.nan, img)\n",
    "            \n",
    "            # Normalisation: auto scale + asinh stretch\n",
    "            interval = ZScaleInterval()\n",
    "            vmin, vmax = interval.get_limits(img)\n",
    "            norm = ImageNormalize(vmin=vmin, vmax=vmax, stretch=AsinhStretch())\n",
    "            \n",
    "            plt.imshow(img, origin=\"lower\", cmap=\"inferno\", norm=norm)\n",
    "            plt.title(f\"Galaxy {objid} - {band}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not process {objid}: {e}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    #plt.subplots_adjust(top=0.94, hspace=0.35, wspace=0.3)\n",
    "        \n",
    "    # Save with high DPI for appendix quality\n",
    "    #plt.savefig(fig_path, dpi=200, bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()\n",
    "    #plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a new routine to investigate these in-between cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\"F770W\", \"F1000W\", \"F1800W\", \"F2100W\"]\n",
    "\n",
    "discrepant = {}\n",
    "\n",
    "for band in bands:\n",
    "    discrepant_ids = discrepant_filters.get(band, [])  # your list\n",
    "    \n",
    "    nondetections = []    \n",
    "    results = []\n",
    "    for objid in discrepant_ids:\n",
    "        \n",
    "        vis_path = f\"/Users/benjamincollins/University/Master/Red_Cardinal/photometry/vis_data/{objid}_{band}.h5\"\n",
    "        try:\n",
    "            vis_data = phot.load_vis(vis_path)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ No visualisation data file found at {vis_path}\")\n",
    "            continue\n",
    "        \n",
    "        info = phot.recompute_empirical_snr(vis_data=vis_data, n_random=200)\n",
    "        \n",
    "        if info['sn'] < 3.0:\n",
    "            print(f\"⚠️ Galaxy {objid} in {band} has recomputed S/N < 3.0: {info['sn']}\")\n",
    "            nondetections.append(objid)\n",
    "        else:\n",
    "            print(f\"✅ Galaxy {objid} in {band} has recomputed S/N = {info['sn']}\")\n",
    "        \n",
    "        results.append(dict(objid=objid, empirical_snr=info['sn'],\n",
    "                            flux=info['flux'], flux_err=info['flux_err']))\n",
    "\n",
    "    discrepant[band] = nondetections\n",
    "        \n",
    "\n",
    "    # quick table-style print\n",
    "    print(f\"\\n\\nFilter {band}:\")\n",
    "    for r in results:\n",
    "        print(r)\n",
    "\n",
    "print(discrepant)\n",
    "#print(snr_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_flags = {\n",
    "    'F770W': [7185, 7696, 9809, 9901, 10415, 11247, 11481, 12133, 12175, 12443, 12513, 16615, 17534, 17793, 20720, 21218, 21451, 22606, 11723], \n",
    "    'F1000W': [11716, 11723, 12202, 13297, 16424, 17534, 17984, 18327], \n",
    "    'F1800W': [7904, 9517, 10054, 10339, 10415, 10565, 10600, 11247, 11451, 12133, 18769], \n",
    "    'F2100W': [11247, 11716, 11723, 12133, 12202, 12332, 16516, 16615, 17517, 17534, 17916, 17984]\n",
    "    }\n",
    "\n",
    "discrepant = {\n",
    "    'F770W': [11137, 8843, 11853, 11086, 7185, 18769, 8465, 19098, 21472, 19681, 10600, 12202, 21547, 9517, 12213], \n",
    "    'F1000W': [12513, 12164, 12133, 16615, 11853, 12443], \n",
    "    'F1800W': [12164, 12175, 8465, 8338, 10400, 12213, 7102, 11716, 11723, 19024, 12513, 19681, 7934], \n",
    "    'F2100W': [12164, 12175, 12443, 16424, 12213, 11853, 16474, 12513, 12014, 13297]\n",
    "    }\n",
    "\n",
    "bands = [\"F770W\", \"F1000W\", \"F1800W\", \"F2100W\"]\n",
    " \n",
    "final_nondetections = {}\n",
    "for band in bands:\n",
    "    final_nondetections[band] = list(set(discrepant.get(band, [])) | set(auto_flags.get(band, [])))\n",
    "    \n",
    "print(final_nondetections)\n",
    "\n",
    "#fits_table_v5 = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/phot_tables/Flux_Aperture_PSFMatched_AperCorr_MIRI_v5.fits'\n",
    "fits_table_v5 = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/phot_tables/Photometry_Table_MIRI_v6.fits'\n",
    "\n",
    "stats_path = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/results/galaxy_stats_thesis.md'\n",
    "fig_path = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/plots/heat_maps/miri_coverage_long_v3.png'\n",
    "\n",
    "phot.plot_galaxy_filter_matrix(fits_table_v5, fig_path=fig_path, title='MIRI Coverage\\n', cols=3)\n",
    "\n",
    "fig_path = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/plots/heat_maps/miri_detections_long_v3.png'\n",
    "\n",
    "phot.plot_galaxy_filter_matrix(fits_table_v5, fig_path=fig_path, title='MIRI Detections\\n', nondetections=final_nondetections, cols=3)\n",
    "\n",
    "phot.write_detection_stats(fits_table_v5, stats_path=stats_path, nondetections=final_nondetections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section to compare my aperture photometry to the photometry of the COSMOS-Web2025 catalogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Perform the photometry again for my data using the updated and corrected photometry\n",
    "2) Combine the tables into a single FITS output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "## STEP 1:   PERFORM PHOTOMETRY     ##\n",
    "######################################\n",
    "\n",
    "phot.perform_photometry(f770w_files, aperture_table_small, output_folder, suffix='small_v2')\n",
    "\n",
    "phot.perform_photometry(f1800w_files, aperture_table_small, output_folder, suffix='small_v2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "## STEP 2:   CREATE FITS TABLE      ##\n",
    "######################################\n",
    "\n",
    "fits_table_v5 = 'Photometry_Table_MIRI.fits'\n",
    "\n",
    "results_dir = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/results/'\n",
    "\n",
    "f770w_fname  = os.path.join(results_dir, 'phot_table_F770W_v5.csv')\n",
    "f1000w_fname = os.path.join(results_dir, 'phot_table_F1000W_v5.csv')\n",
    "f1800w_fname = os.path.join(results_dir, 'phot_table_F1800W_v5.csv')\n",
    "f2100w_fname = os.path.join(results_dir, 'phot_table_F2100W_v5.csv')\n",
    "\n",
    "csv_paths = [f770w_fname, f1000w_fname, f1800w_fname, f2100w_fname]\n",
    "\n",
    "# Now create the combined FITS table\n",
    "phot.create_fits_table_from_csv(csv_paths, output_file=fits_table_v5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-match galaxies between catalogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from astropy.table import hstack\n",
    "\n",
    "cweb_path = '/Users/benjamincollins/University/master/Red_Cardinal/COSMOS-Web_DR1/COSMOSWeb_reduced.fits'\n",
    "#my_path = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/results/Flux_Aperture_PSFMatched_AperCorr_MIRI_v4.fits'\n",
    "my_path = '/Users/benjamincollins/University/Master/Red_Cardinal/miri_photometry_v1/Photometry_Table_MIRI.fits'\n",
    "cat_path = '/Users/benjamincollins/University/master/Red_Cardinal/cat_targets.fits'\n",
    "\n",
    "my_table = Table.read(my_path, hdu=1)\n",
    "cosmos_table = Table.read(cweb_path, hdu=1)\n",
    "my_cat = Table.read(cat_path, hdu=1)\n",
    "fits.info(my_path)\n",
    "fits.info(cweb_path)\n",
    "#print(my_cat.columns)\n",
    "\n",
    "# Rename ID column to id to match other catalogues\n",
    "my_table.rename_column('ID', 'id')\n",
    "\n",
    "# Reduce catalogue\n",
    "my_cat_small = my_cat['id', 'ra', 'dec']\n",
    "\n",
    "# Force type setting\n",
    "my_table['id'] = my_table['id'].astype(str)\n",
    "my_cat_small['id'] = my_cat_small['id'].astype(str)\n",
    "\n",
    "# Match according to IDs\n",
    "matched = join(my_table, my_cat_small, keys=('id'), join_type='inner')\n",
    "\n",
    "print(matched.columns)\n",
    "\n",
    "#matched.write('/Users/benjamincollins/University/master/Red_Cardinal/COSMOS-Web_DR1/Phot_Table_id_matched.fits', overwrite=True)\n",
    "\n",
    "ids_my = matched['id']\n",
    "ids_cosmos = cosmos_table['id'].astype(str)\n",
    "#match_mask = ids_my.match_to_id\n",
    "\n",
    "# Build coordinates\n",
    "coords_my = SkyCoord(ra=matched['ra']*u.deg, dec=matched['dec']*u.deg)\n",
    "coords_cosmos = SkyCoord(ra=cosmos_table['ra']*u.deg, dec=cosmos_table['dec']*u.deg)\n",
    "\n",
    "# Match (within 0.3 arcsec, for instance)\n",
    "idx, d2d, _ = coords_my.match_to_catalog_sky(coords_cosmos)\n",
    "match_mask = d2d < 0.2 * u.arcsec\n",
    "\n",
    "# Build matched table\n",
    "my_matched = matched[match_mask]    # important to take the matched catalogue!\n",
    "cosmos_matched = cosmos_table[idx[match_mask]]\n",
    "\n",
    "# Combine tables: rename columns to avoid name collision\n",
    "cosmos_matched.rename_columns(\n",
    "    cosmos_matched.colnames,\n",
    "    [name + \"_cosmos\" if name in my_matched.colnames else name for name in cosmos_matched.colnames]\n",
    ")\n",
    "\n",
    "# Merge horizontally\n",
    "sky_matched = hstack([my_matched, cosmos_matched])\n",
    "\n",
    "print(sky_matched.columns)\n",
    "sky_matched.info()\n",
    "\n",
    "sky_matched.write('/Users/benjamincollins/University/master/Red_Cardinal/COSMOS-Web_DR1/Phot_Table_sky_matched.fits', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and call huge plotting function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a 3x3 massive grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_and_prepare_data(fits_file_path):\n",
    "    \"\"\"\n",
    "    Load the FITS table and prepare data for comparison\n",
    "    \"\"\"\n",
    "    # Load the FITS table\n",
    "    table = Table.read(fits_file_path)\n",
    "    \n",
    "    # Extract F770W data from multi-dimensional arrays\n",
    "    # For Flux and Flux_Err, take the first value (F770W filter)\n",
    "    flux_personal = []\n",
    "    flux_err_personal = []\n",
    "    ab_mag_personal = []\n",
    "    \n",
    "    for i in range(len(table)):\n",
    "        # Handle Flux (F770W is first element)\n",
    "        if table['Flux'].mask[i][0] == False:\n",
    "            flux_val = table['Flux'][i]*1e6 # convert to µJy\n",
    "            if hasattr(flux_val, '__len__') and len(flux_val) > 0:\n",
    "                flux_personal.append(flux_val[0])\n",
    "            else:\n",
    "                flux_personal.append(flux_val)\n",
    "        else:\n",
    "            flux_personal.append(np.nan)\n",
    "            \n",
    "        # Handle Flux_Err (F770W is first element)\n",
    "        if table['Flux_Err'].mask[i][0] == False:\n",
    "            flux_err_val = table['Flux_Err'][i]*1e6 # convert to µJy\n",
    "            if hasattr(flux_err_val, '__len__') and len(flux_err_val) > 0:\n",
    "                flux_err_personal.append(flux_err_val[0])\n",
    "            else:\n",
    "                flux_err_personal.append(flux_err_val)\n",
    "        else:\n",
    "            flux_err_personal.append(np.nan)\n",
    "            \n",
    "        # Handle AB_Mag (F770W is first element)\n",
    "        if table['AB_Mag'].mask[i][0] == False:\n",
    "            ab_mag_val = table['AB_Mag'][i]\n",
    "            if hasattr(ab_mag_val, '__len__') and len(ab_mag_val) > 0:\n",
    "                ab_mag_personal.append(ab_mag_val[0])\n",
    "            else:\n",
    "                ab_mag_personal.append(ab_mag_val)\n",
    "        else:\n",
    "            ab_mag_personal.append(np.nan)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    flux_personal = np.array(flux_personal)\n",
    "    flux_err_personal = np.array(flux_err_personal)\n",
    "    ab_mag_personal = np.array(ab_mag_personal)\n",
    "    \n",
    "    # Extract public catalogue data\n",
    "    flux_public = np.array(table['flux_auto_f770w'])\n",
    "    flux_err_public = np.array(table['flux_err_auto_f770w'])\n",
    "    mag_public = np.array(table['mag_auto_f770w'])\n",
    "    \n",
    "    # Create masks for valid data\n",
    "    valid_flux = (~np.isnan(flux_personal)) & (~np.isnan(flux_public)) & \\\n",
    "                 (flux_personal > 0) & (flux_public > 0)\n",
    "    valid_flux_err = (~np.isnan(flux_personal)) & (~np.isnan(flux_public)) & \\\n",
    "                     (flux_personal > 0) & (flux_public > 0)\n",
    "    \n",
    "    return {\n",
    "        'table': table,\n",
    "        'flux_personal': flux_personal,\n",
    "        'flux_err_personal': flux_err_personal,\n",
    "        'ab_mag_personal': ab_mag_personal,\n",
    "        'flux_public': flux_public,\n",
    "        'flux_err_public': flux_err_public,\n",
    "        'mag_public': mag_public,\n",
    "        'valid_flux': valid_flux,\n",
    "        'valid_flux_err': valid_flux_err\n",
    "    }\n",
    "\n",
    "def calculate_statistics(x, y, valid_mask):\n",
    "    \"\"\"\n",
    "    Calculate comparison statistics\n",
    "    \"\"\"\n",
    "    if np.sum(valid_mask) < 3:\n",
    "        return {}\n",
    "    \n",
    "    x_valid = x[valid_mask]\n",
    "    y_valid = y[valid_mask]\n",
    "    \n",
    "    # Linear correlation\n",
    "    corr_coef, p_value = stats.pearsonr(x_valid, y_valid)\n",
    "    \n",
    "    # Calculate residuals and statistics\n",
    "    residuals = y_valid - x_valid\n",
    "    mean_residual = np.mean(residuals)\n",
    "    median_residual = np.median(residuals)\n",
    "    std_residual = np.std(residuals)\n",
    "    rms_residual = np.sqrt(np.mean(residuals**2))\n",
    "    \n",
    "    # Fractional differences for positive values\n",
    "    frac_diff = (y_valid - x_valid) / x_valid\n",
    "    median_frac_diff = np.median(frac_diff)\n",
    "    mean_frac_diff = np.mean(frac_diff)\n",
    "    std_frac_diff = np.std(frac_diff)\n",
    "    \n",
    "    return {\n",
    "        'correlation': corr_coef,\n",
    "        'p_value': p_value,\n",
    "        'median_residual': median_residual,\n",
    "        'mean_residual': mean_residual,\n",
    "        'std_residual': std_residual,\n",
    "        'rms_residual': rms_residual,\n",
    "        'median_frac_diff': median_frac_diff,\n",
    "        'mean_frac_diff': mean_frac_diff,\n",
    "        'std_frac_diff': std_frac_diff,\n",
    "        'n_objects': len(x_valid)\n",
    "    }\n",
    "\n",
    "def create_comparison_plot(data):\n",
    "    \"\"\"\n",
    "    Create comprehensive comparison plots\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    # Define color scheme\n",
    "    colors = {'scatter': '#1f77b4', 'line': '#ff7f0e', 'hist': '#2ca02c'}\n",
    "    \n",
    "    # 1. Flux comparison (log-log scale)\n",
    "    ax1 = plt.subplot(3, 3, 1)\n",
    "    valid_flux = data['valid_flux']\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        \n",
    "        ax1.scatter(x_flux, y_flux, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(x_flux), np.min(y_flux))\n",
    "        max_val = max(np.max(x_flux), np.max(y_flux))\n",
    "        ax1.plot([min_val, max_val], [min_val, max_val], '--', color=colors['line'], lw=2)\n",
    "        \n",
    "        ax1.set_xscale('log')\n",
    "        ax1.set_yscale('log')\n",
    "        ax1.set_xlabel('This Work Flux (µJy)')\n",
    "        ax1.set_ylabel('COSMOS-Web DR1 Catalogue Flux (µJy)')\n",
    "        ax1.set_title('Flux Comparison (F770W)')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        stats_flux = calculate_statistics(x_flux, y_flux, np.ones(len(x_flux), dtype=bool))\n",
    "        if stats_flux:\n",
    "            ax1.text(0.05, 0.95, f'r = {stats_flux[\"correlation\"]:.3f}\\nN = {stats_flux[\"n_objects\"]}', \n",
    "                    transform=ax1.transAxes, verticalalignment='top', \n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 2. Flux error comparison (log-log scale)\n",
    "    ax2 = plt.subplot(3, 3, 2)\n",
    "    valid_flux_err = data['valid_flux_err']\n",
    "    if np.sum(valid_flux_err) > 0:\n",
    "        x_err = data['flux_err_personal'][valid_flux_err]\n",
    "        y_err = data['flux_err_public'][valid_flux_err]\n",
    "        \n",
    "        ax2.scatter(x_err, y_err, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(x_err), np.min(y_err))\n",
    "        max_val = max(np.max(x_err), np.max(y_err))\n",
    "        ax2.plot([min_val, max_val], [min_val, max_val], '--', color=colors['line'], lw=2)\n",
    "        \n",
    "        ax2.set_xscale('log')\n",
    "        ax2.set_yscale('log')\n",
    "        ax2.set_xlabel('This Work Flux Error (µJy)')\n",
    "        ax2.set_ylabel('COSMOS-Web DR1 Catalogue Flux Error (µJy)')\n",
    "        ax2.set_title('Flux Error Comparison (F770W)')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        stats_err = calculate_statistics(x_err, y_err, np.ones(len(x_err), dtype=bool))\n",
    "        if stats_err:\n",
    "            ax2.text(0.05, 0.95, f'r = {stats_err[\"correlation\"]:.3f}\\nN = {stats_err[\"n_objects\"]}', \n",
    "                    transform=ax2.transAxes, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    \n",
    "    # 3. Signal-to-noise ratio comparison\n",
    "    ax3 = plt.subplot(3, 3, 3)\n",
    "    valid_snr = data['valid_flux'] & data['valid_flux_err']\n",
    "    if np.sum(valid_snr) > 0:\n",
    "        snr_personal = data['flux_personal'][valid_snr] / data['flux_err_personal'][valid_snr]\n",
    "        snr_public = data['flux_public'][valid_snr] / data['flux_err_public'][valid_snr]\n",
    "        \n",
    "        max_idx = np.argmax(snr_public)\n",
    "        \n",
    "        snr_personal = np.delete(snr_personal, max_idx)\n",
    "        snr_public = np.delete(snr_public, max_idx)\n",
    "        \n",
    "        ax3.scatter(snr_personal, snr_public, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(snr_personal), np.min(snr_public))\n",
    "        max_val = max(np.max(snr_personal), np.max(snr_public))\n",
    "        ax3.plot([min_val, max_val], [min_val, max_val], '--', color=colors['line'], lw=2)\n",
    "        \n",
    "        ax3.set_xlabel('This Work S/N')\n",
    "        ax3.set_ylabel('COSMOS-Web DR1 Catalogue S/N')\n",
    "        ax3.set_title('Signal-to-Noise Ratio Comparison')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        stats_snr = calculate_statistics(snr_personal, snr_public, np.ones(len(snr_personal), dtype=bool))\n",
    "        if stats_snr:\n",
    "            ax3.text(0.05, 0.95, f'r = {stats_snr[\"correlation\"]:.3f}\\nN = {stats_snr[\"n_objects\"]}', \n",
    "                    transform=ax3.transAxes, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 4. Flux residuals vs flux\n",
    "    ax4 = plt.subplot(3, 3, 4)\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        residuals = y_flux - x_flux\n",
    "        \n",
    "        ax4.scatter(x_flux, residuals, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        ax4.axhline(y=0, color=colors['line'], linestyle='--', lw=2)\n",
    "        ax4.set_xscale('log')\n",
    "        ax4.set_xlabel('This Work Flux (µJy)')\n",
    "        ax4.set_ylabel('Flux Residuals (COSMOS-Web DR1 - This Work)')\n",
    "        ax4.set_title('Flux Residuals vs Flux')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Fractional flux differences\n",
    "    ax5 = plt.subplot(3, 3, 5)\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        frac_diff = (y_flux - x_flux) / x_flux\n",
    "        \n",
    "        ax5.scatter(x_flux, frac_diff, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        ax5.axhline(y=0, color=colors['line'], linestyle='--', lw=2)\n",
    "        ax5.set_xscale('log')\n",
    "        ax5.set_xlabel('This Work Flux (µJy)')\n",
    "        ax5.set_ylabel('Fractional Flux Difference')\n",
    "        ax5.set_title('Fractional Flux Differences')\n",
    "        ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Error bar comparison\n",
    "    ax6 = plt.subplot(3, 3, 6)\n",
    "    if np.sum(valid_flux) & np.sum(valid_flux_err) > 0:\n",
    "        valid_both = valid_flux & valid_flux_err\n",
    "        x_flux = data['flux_personal'][valid_both]\n",
    "        y_flux = data['flux_public'][valid_both]\n",
    "        x_err = data['flux_err_personal'][valid_both]\n",
    "        y_err = data['flux_err_public'][valid_both]\n",
    "        \n",
    "        # Plot a subset of points with error bars to avoid cluttering\n",
    "        #n_plot = min(50, len(x_flux))\n",
    "        #indices = np.random.choice(len(x_flux), n_plot, replace=False)\n",
    "        \n",
    "        ax6.errorbar(x_flux, y_flux, \n",
    "                    xerr=x_err, yerr=y_err,\n",
    "                    fmt='o', alpha=0.6, capsize=3, color=colors['scatter'])\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(x_flux), np.min(y_flux))\n",
    "        max_val = max(np.max(x_flux), np.max(y_flux))\n",
    "        ax6.plot([min_val, max_val], [min_val, max_val], '--', color=colors['line'], lw=2)\n",
    "        \n",
    "        ax6.loglog()\n",
    "        ax6.set_xlabel('This Work Flux (µJy)')\n",
    "        ax6.set_ylabel('COSMOS-Web DR1 Catalogue Flux (µJy)')\n",
    "        ax6.set_title(f'Flux with Error Bars')\n",
    "        ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 7. Flux histogram comparison\n",
    "    ax7 = plt.subplot(3, 3, 7)\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        \n",
    "        bins = np.logspace(np.log10(min(np.min(x_flux), np.min(y_flux))), \n",
    "                          np.log10(max(np.max(x_flux), np.max(y_flux))), 20)\n",
    "        \n",
    "        ax7.hist(x_flux, bins=bins, alpha=0.6, label='This Work', color=colors['scatter'])\n",
    "        ax7.hist(y_flux, bins=bins, alpha=0.6, label='COSMOS-Web DR1', color=colors['line'])\n",
    "        ax7.set_xscale('log')\n",
    "        ax7.set_xlabel('Flux (µJy)')\n",
    "        ax7.set_ylabel('Number of Objects')\n",
    "        ax7.set_title('Flux Distribution Comparison')\n",
    "        ax7.legend()\n",
    "        ax7.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 8. Residuals histogram\n",
    "    ax8 = plt.subplot(3, 3, 8)\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        frac_diff = (y_flux - x_flux) / x_flux\n",
    "        \n",
    "        ax8.hist(frac_diff, bins=30, alpha=0.7, color=colors['hist'])\n",
    "        ax8.axvline(x=0, color=colors['line'], linestyle='--', lw=2)\n",
    "        ax8.axvline(x=np.median(frac_diff), color='red', linestyle='-', lw=2, label=f'Median: {np.median(frac_diff):.3f}')\n",
    "        ax8.axvline(x=np.mean(frac_diff), color='blue', linestyle='-', lw=2, label=f'Mean: {np.mean(frac_diff):.3f}')\n",
    "        ax8.set_xlabel('Fractional Flux Difference')\n",
    "        ax8.set_ylabel('Number of Objects')\n",
    "        ax8.set_title('Fractional Difference Distribution')\n",
    "        ax8.legend()\n",
    "        ax8.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 9. Summary statistics text\n",
    "    ax12 = plt.subplot(3, 3, 9)\n",
    "    ax12.axis('off')\n",
    "    \n",
    "    summary_text = \"\\n  PHOTOMETRY COMPARISON SUMMARY  \\n\\n\"\n",
    "    \n",
    "    if np.sum(valid_flux) > 0:\n",
    "        stats_flux = calculate_statistics(data['flux_personal'][valid_flux], \n",
    "                                        data['flux_public'][valid_flux], \n",
    "                                        np.ones(np.sum(valid_flux), dtype=bool))\n",
    "        if stats_flux:\n",
    "            summary_text += f\"  FLUX COMPARISON (N={stats_flux['n_objects']}):  \\n\"\n",
    "            summary_text += f\"    Correlation: {stats_flux['correlation']:.3f}  \\n\"\n",
    "            summary_text += f\"    Median fractional diff: {stats_flux['median_frac_diff']:.3f}  \\n\"\n",
    "            summary_text += f\"    Mean fractional diff: {stats_flux['mean_frac_diff']:.3f}  \\n\"\n",
    "            summary_text += f\"    Std fractional diff: {stats_flux['std_frac_diff']:.3f}  \\n\\n\"\n",
    "    \n",
    "    summary_text += f\"  DATA COVERAGE:\\n\"\n",
    "    summary_text += f\"    Total objects: {len(data['table'])}  \\n\"\n",
    "    summary_text += f\"    Valid flux measurements: {np.sum(valid_flux)}  \\n\"\n",
    "    \n",
    "    ax12.text(0.05, 0.95, summary_text, transform=ax12.transAxes, \n",
    "             verticalalignment='top', fontfamily='monospace', fontsize=14,\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Main execution function\n",
    "def analyse_photometry_comparison(fits_file_path, output_plot_path=None):\n",
    "    \"\"\"\n",
    "    Main function to perform photometry comparison analysis\n",
    "    \"\"\"\n",
    "    print(\"Loading and preparing data...\")\n",
    "    data = load_and_prepare_data(fits_file_path)\n",
    "    \n",
    "    print(\"Creating comparison plots...\")\n",
    "    fig = create_comparison_plot(data)\n",
    "    \n",
    "    if output_plot_path:\n",
    "        print(f\"Saving plot to {output_plot_path}\")\n",
    "        plt.savefig(output_plot_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PHOTOMETRY COMPARISON ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    valid_flux = data['valid_flux']\n",
    "    \n",
    "    if np.sum(valid_flux) > 0:\n",
    "        stats_flux = calculate_statistics(data['flux_personal'][valid_flux], \n",
    "                                        data['flux_public'][valid_flux], \n",
    "                                        np.ones(np.sum(valid_flux), dtype=bool))\n",
    "        if stats_flux:\n",
    "            print(f\"\\nFLUX COMPARISON ({stats_flux['n_objects']} objects):\")\n",
    "            print(f\"  Pearson correlation coefficient: {stats_flux['correlation']:.4f}\")\n",
    "            print(f\"  Mean fractional difference: {stats_flux['mean_frac_diff']:.4f}\")\n",
    "            print(f\"  Standard deviation of fractional differences: {stats_flux['std_frac_diff']:.4f}\")\n",
    "            print(f\"  RMS of absolute residuals: {stats_flux['rms_residual']:.4f} µJy\")\n",
    "    \n",
    "    print(f\"\\nDATA COVERAGE:\")\n",
    "    print(f\"  Total objects in table: {len(data['table'])}\")\n",
    "    print(f\"  Objects with valid flux measurements: {np.sum(valid_flux)}\")\n",
    "    \n",
    "    return data, fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a 3x2, more thesis-appropriate grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clean_appendix_plot(data):\n",
    "    \"\"\"\n",
    "    Create a clean 3x2 appendix plot with the most essential comparisons\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(9, 10))\n",
    "    \n",
    "    # Define color scheme\n",
    "    colors = {'scatter': '#1f77b4', 'line': '#ff7f0e', 'hist': '#2ca02c', 'error': '#d62728'}\n",
    "    \n",
    "    # 1. Flux comparison with error bars (TOP LEFT)\n",
    "    ax1 = plt.subplot(3, 2, 1)\n",
    "    valid_flux = data['valid_flux']\n",
    "    valid_flux_err = data['valid_flux_err']\n",
    "    \n",
    "    if np.sum(valid_flux) & np.sum(valid_flux_err) > 0:\n",
    "        valid_both = valid_flux & valid_flux_err\n",
    "        x_flux = data['flux_personal'][valid_both]\n",
    "        y_flux = data['flux_public'][valid_both]\n",
    "        x_err = data['flux_err_personal'][valid_both]\n",
    "        y_err = data['flux_err_public'][valid_both]\n",
    "        \n",
    "        ax1.errorbar(x_flux, y_flux, \n",
    "                    xerr=x_err, yerr=y_err,\n",
    "                    fmt='o', alpha=0.7, capsize=2, markersize=4, \n",
    "                    color=colors['scatter'], ecolor=colors['scatter'])\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(x_flux), np.min(y_flux))\n",
    "        max_val = max(np.max(x_flux), np.max(y_flux))\n",
    "        ax1.plot([min_val, max_val], [min_val, max_val], '--', \n",
    "                color=colors['line'], lw=2, label='1:1 line')\n",
    "        \n",
    "        ax1.loglog()\n",
    "        ax1.set_xlabel('This Work F770W Flux (µJy)', fontsize=13)\n",
    "        ax1.set_ylabel('COSMOS2025 F770W Flux (µJy)', fontsize=13)\n",
    "        ax1.set_title('(a) Flux Comparison', fontsize=14, fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.legend(fontsize=11)\n",
    "        \n",
    "        # Add statistics\n",
    "        stats_flux = calculate_statistics(x_flux, y_flux, np.ones(len(x_flux), dtype=bool))\n",
    "        if stats_flux:\n",
    "            ax1.text(0.05, 0.95, f'r = {stats_flux[\"correlation\"]:.3f}\\nN = {stats_flux[\"n_objects\"]}', \n",
    "                    transform=ax1.transAxes, verticalalignment='top', fontsize=12,\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='gray'))\n",
    "    \n",
    "    # 2. Flux error comparison (TOP MIDDLE)\n",
    "    ax2 = plt.subplot(3, 2, 2)\n",
    "    if np.sum(valid_flux_err) > 0:\n",
    "        x_err = data['flux_err_personal'][valid_flux_err]\n",
    "        y_err = data['flux_err_public'][valid_flux_err]\n",
    "        \n",
    "        ax2.scatter(x_err, y_err, alpha=0.7, s=40, color=colors['error'], \n",
    "                   edgecolors='white', linewidth=0.5)\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(x_err), np.min(y_err))\n",
    "        max_val = max(np.max(x_err), np.max(y_err))\n",
    "        ax2.plot([min_val, max_val], [min_val, max_val], '--', \n",
    "                color=colors['line'], lw=2, label='1:1 line')\n",
    "        \n",
    "        ax2.set_xscale('log')\n",
    "        ax2.set_yscale('log')\n",
    "        ax2.set_xlabel('This Work Flux Error (µJy)', fontsize=13)\n",
    "        ax2.set_ylabel('COSMOS2025 Flux Error (µJy)', fontsize=13)\n",
    "        ax2.set_title('(b) Flux Error Comparison', fontsize=14, fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend(fontsize=11)\n",
    "        \n",
    "        # Add statistics\n",
    "        stats_err = calculate_statistics(x_err, y_err, np.ones(len(x_err), dtype=bool))\n",
    "        if stats_err:\n",
    "            ax2.text(0.05, 0.95, f'r = {stats_err[\"correlation\"]:.3f}\\nN = {stats_err[\"n_objects\"]}', \n",
    "                    transform=ax2.transAxes, verticalalignment='top', fontsize=12,\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='gray'))\n",
    "    \n",
    "    # 3. Fractional flux differences (TOP RIGHT)\n",
    "    ax3 = plt.subplot(3, 2, 3)\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        frac_diff = (y_flux - x_flux) / x_flux\n",
    "        \n",
    "        ax3.scatter(x_flux, frac_diff, alpha=0.7, s=40, color=colors['scatter'], \n",
    "                   edgecolors='white', linewidth=0.5)\n",
    "        ax3.axhline(y=0, color=colors['line'], linestyle='--', lw=2)\n",
    "        #ax3.axhline(y=np.median(frac_diff), color=colors['error'], linestyle='-', lw=2, \n",
    "        #           label=f'Median: {np.median(frac_diff):.3f} µJy')\n",
    "        \n",
    "        ax3.set_xscale('log')\n",
    "        ax3.set_xlabel('This Work F770W Flux (µJy)', fontsize=13)\n",
    "        ax3.set_ylabel('Fractional Flux Difference\\n(COSMOS2025 - This Work) / This Work', fontsize=13)\n",
    "        ax3.set_title('(c) Systematic Differences', fontsize=14, fontweight='bold')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        #ax3.legend(fontsize=11)\n",
    "        \n",
    "        # Add statistics\n",
    "        ax3.text(0.95, 0.95, f'σ = {np.std(frac_diff):.3f}\\nRMS = {np.sqrt(np.mean(frac_diff**2)):.3f}', \n",
    "                transform=ax3.transAxes, verticalalignment='top', horizontalalignment='right', fontsize=12,\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='gray'))\n",
    "    \n",
    "    # 4. Flux histogram comparison (BOTTOM LEFT)\n",
    "    ax4 = plt.subplot(3, 2, 4)\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        \n",
    "        bins = np.logspace(np.log10(min(np.min(x_flux), np.min(y_flux))), \n",
    "                          np.log10(max(np.max(x_flux), np.max(y_flux))), 20)\n",
    "        \n",
    "        ax4.hist(x_flux, bins=bins, alpha=0.7, label='This Work', \n",
    "                color=colors['scatter'], edgecolor='white', linewidth=0.5)\n",
    "        ax4.hist(y_flux, bins=bins, alpha=0.7, label='COSMOS2025', \n",
    "                color=colors['line'], edgecolor='white', linewidth=0.5)\n",
    "        ax4.set_xscale('log')\n",
    "        ax4.set_xlabel('F770W Flux (µJy)', fontsize=13)\n",
    "        ax4.set_ylabel('Number of Objects', fontsize=13)\n",
    "        ax4.set_title('(d) Flux Distribution Comparison', fontsize=14, fontweight='bold')\n",
    "        ax4.legend(fontsize=11)\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Residuals histogram (BOTTOM MIDDLE)\n",
    "    ax5 = plt.subplot(3, 2, 5)\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        frac_diff = (y_flux - x_flux) / x_flux\n",
    "        \n",
    "        ax5.hist(frac_diff, bins=30, alpha=0.8, color=colors['hist'], \n",
    "                edgecolor='white', linewidth=0.5)\n",
    "        #ax5.axvline(x=0, color=colors['line'], linestyle='--', lw=2, label='Zero')\n",
    "        ax5.axvline(x=np.median(frac_diff), color=colors['error'], linestyle='-', lw=2, \n",
    "                   label=f'Median: {np.median(frac_diff):.3f} µJy')\n",
    "        ax5.axvline(x=np.mean(frac_diff), color='purple', linestyle='-', lw=2, \n",
    "                   label=f'Mean: {np.mean(frac_diff):.3f} µJy')\n",
    "        ax5.set_xlabel('Fractional Flux Difference', fontsize=13)\n",
    "        ax5.set_ylabel('Number of Objects', fontsize=13)\n",
    "        ax5.set_title('(e) Residuals Distribution', fontsize=14, fontweight='bold')\n",
    "        ax5.legend(fontsize=11)\n",
    "        ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Summary statistics (BOTTOM RIGHT)\n",
    "    ax6 = plt.subplot(3, 2, 6)\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    summary_text = \"PHOTOMETRY VALIDATION\\nSUMMARY STATISTICS\\n\" + \"=\"*25 + \"\\n\\n\"\n",
    "    \n",
    "    if np.sum(valid_flux) > 0:\n",
    "        stats_flux = calculate_statistics(data['flux_personal'][valid_flux], \n",
    "                                        data['flux_public'][valid_flux], \n",
    "                                        np.ones(np.sum(valid_flux), dtype=bool))\n",
    "        if stats_flux:\n",
    "            summary_text += \"FLUX COMPARISON:\\n\"\n",
    "            summary_text += f\"  • Matched objects: {stats_flux['n_objects']}\\n\"\n",
    "            summary_text += f\"  • Pearson correlation: {stats_flux['correlation']:.4f}\\n\"\n",
    "            summary_text += f\"  • Mean frac. difference: {stats_flux['mean_frac_diff']:.4f}\\n\"\n",
    "            summary_text += f\"  • Std frac. difference: {stats_flux['std_frac_diff']:.4f}\\n\"\n",
    "            summary_text += f\"  • RMS residual: {stats_flux['rms_residual']:.2f} µJy\\n\\n\"\n",
    "    \n",
    "    if np.sum(valid_flux_err) > 0:\n",
    "        stats_err = calculate_statistics(data['flux_err_personal'][valid_flux_err], \n",
    "                                       data['flux_err_public'][valid_flux_err], \n",
    "                                       np.ones(np.sum(valid_flux_err), dtype=bool))\n",
    "        if stats_err:\n",
    "            summary_text += \"ERROR COMPARISON:\\n\"\n",
    "            summary_text += f\"  • Error correlation: {stats_err['correlation']:.4f}\\n\"\n",
    "            summary_text += f\"  • Mean error ratio: {stats_err['mean_frac_diff']+1:.4f}\"\n",
    "    \n",
    "    ax6.text(0.05, 0.95, summary_text, transform=ax6.transAxes, \n",
    "             verticalalignment='top', fontfamily='monospace', fontsize=11,\n",
    "             bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.1, edgecolor='gray'))\n",
    "    \n",
    "    #ax6.set_title('(f) Summary & Assessment', fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.35, wspace=0.35)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Updated main function for the clean appendix version\n",
    "def analyse_photometry_comparison(fits_file_path, output_plot_path=None, plot_type='appendix'):\n",
    "    \"\"\"\n",
    "    Create clean 3x2 appendix figure for photometry validation\n",
    "    \"\"\"\n",
    "    print(\"Loading and preparing data...\")\n",
    "    data = load_and_prepare_data(fits_file_path)\n",
    "    \n",
    "    print(\"Creating clean appendix validation plot...\")\n",
    "    if plot_type == 'appendix':\n",
    "        fig = create_clean_appendix_plot(data)\n",
    "        output_plot_path = os.path.join(output_plot_path, \"phot_comp_appendix_v2.png\")\n",
    "    elif plot_type == 'thesis':\n",
    "        fig = create_reduced_comparison_plot(data)\n",
    "        output_plot_path = os.path.join(output_plot_path, \"phot_comp_thesis.png\")\n",
    "    else: fig = None\n",
    "\n",
    "    if output_plot_path and fig:\n",
    "        print(f\"Saving plot to {output_plot_path}\")\n",
    "        plt.savefig(output_plot_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return data, fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thesis-ready comparison plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reduced_comparison_plot(data):\n",
    "    \"\"\"\n",
    "    Create a condensed thesis-ready comparison plot (2x1 format)\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # Define color scheme\n",
    "    colors = {'scatter': '#1f77b4', 'line': '#ff7f0e', 'hist': '#2ca02c', 'error': '#d62728'}\n",
    "    \n",
    "    # 1. Main flux comparison (log-log scale) - TOP LEFT\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    valid_flux = data['valid_flux']\n",
    "    valid_flux_err = data['valid_flux_err']\n",
    "    \n",
    "    if np.sum(valid_flux) & np.sum(valid_flux_err) > 0:\n",
    "        valid_both = valid_flux & valid_flux_err\n",
    "        x_flux = data['flux_personal'][valid_both]\n",
    "        y_flux = data['flux_public'][valid_both]\n",
    "        x_err = data['flux_err_personal'][valid_both]\n",
    "        y_err = data['flux_err_public'][valid_both]\n",
    "        \n",
    "        # Plot a subset of points with error bars to avoid cluttering\n",
    "        #n_plot = min(50, len(x_flux))\n",
    "        #indices = np.random.choice(len(x_flux), n_plot, replace=False)\n",
    "        \n",
    "        ax1.errorbar(x_flux, y_flux, \n",
    "                    xerr=x_err, yerr=y_err,\n",
    "                    fmt='o', alpha=0.6, capsize=3, color=colors['scatter'])\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(x_flux), np.min(y_flux))\n",
    "        max_val = max(np.max(x_flux), np.max(y_flux))\n",
    "        ax1.plot([min_val, max_val], [min_val, max_val], '--', color=colors['line'], lw=2, label='1:1 line')\n",
    "        ax1.legend()\n",
    "        ax1.loglog()\n",
    "        ax1.set_xlabel('This Work Flux (µJy)')\n",
    "        ax1.set_ylabel('COSMOS2025 Flux (µJy)')\n",
    "        ax1.set_title(f'Flux Comparison')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Signal-to-noise ratio comparison - TOP RIGHT\n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "    valid_snr = data['valid_flux'] & data['valid_flux_err']\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        frac_diff = (y_flux - x_flux) / x_flux\n",
    "        \n",
    "        ax2.scatter(x_flux, frac_diff, alpha=0.6, s=30, color=colors['scatter'])\n",
    "        #ax2.axhline(y=0, color=colors['line'], linestyle='--', lw=2, label='Zero difference')\n",
    "        ax2.axhline(y=np.median(frac_diff), color=colors['error'], linestyle='-', lw=2, \n",
    "                   label=f'Median: {np.median(frac_diff):.3f} µJy')\n",
    "        ax2.set_xscale('log')\n",
    "        ax2.set_xlabel('This Work Flux (µJy)')\n",
    "        ax2.set_ylabel(r'$\\Delta$ f')\n",
    "        ax2.set_title('Fractional Flux Differences')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # 2. Flux error comparison (TOP MIDDLE)\n",
    "    ax2 = plt.subplot(1, 2, 1)\n",
    "    if np.sum(valid_flux_err) > 0:\n",
    "        x_err = data['flux_err_personal'][valid_flux_err]\n",
    "        y_err = data['flux_err_public'][valid_flux_err]\n",
    "        \n",
    "        ax2.scatter(x_err, y_err, alpha=0.7, s=40, color=colors['error'], \n",
    "                   edgecolors='white', linewidth=0.5)\n",
    "        \n",
    "        # Add 1:1 line\n",
    "        min_val = min(np.min(x_err), np.min(y_err))\n",
    "        max_val = max(np.max(x_err), np.max(y_err))\n",
    "        ax2.plot([min_val, max_val], [min_val, max_val], '--', \n",
    "                color=colors['line'], lw=2, label='1:1 line')\n",
    "        \n",
    "        ax2.set_xscale('log')\n",
    "        ax2.set_yscale('log')\n",
    "        ax2.set_xlabel('This Work Flux Error (µJy)')\n",
    "        ax2.set_ylabel('COSMOS2025 Flux Error (µJy)')\n",
    "        ax2.set_title('Flux Error Comparison')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend(fontsize=11)\n",
    "        \n",
    "        # Add statistics\n",
    "        stats_err = calculate_statistics(x_err, y_err, np.ones(len(x_err), dtype=bool))\n",
    "        if stats_err:\n",
    "            ax2.text(0.05, 0.95, f'r = {stats_err[\"correlation\"]:.3f}\\nN = {stats_err[\"n_objects\"]}', \n",
    "                    transform=ax2.transAxes, verticalalignment='top', fontsize=12,\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='gray'))\n",
    "    \n",
    "    # 4. Flux histogram comparison (BOTTOM LEFT)\n",
    "    ax4 = plt.subplot(1, 2, 2)\n",
    "    if np.sum(valid_flux) > 0:\n",
    "        x_flux = data['flux_personal'][valid_flux]\n",
    "        y_flux = data['flux_public'][valid_flux]\n",
    "        \n",
    "        bins = np.logspace(np.log10(min(np.min(x_flux), np.min(y_flux))), \n",
    "                          np.log10(max(np.max(x_flux), np.max(y_flux))), 20)\n",
    "        \n",
    "        ax4.hist(x_flux, bins=bins, alpha=0.7, label='This Work', \n",
    "                color=colors['scatter'], edgecolor='white', linewidth=0.5)\n",
    "        ax4.hist(y_flux, bins=bins, alpha=0.7, label='COSMOS2025', \n",
    "                color=colors['line'], edgecolor='white', linewidth=0.5)\n",
    "        ax4.set_xscale('log')\n",
    "        ax4.set_xlabel('F770W Flux (µJy)')\n",
    "        ax4.set_ylabel('Number of Objects')\n",
    "        ax4.set_title('Flux Distribution Comparison')\n",
    "        ax4.legend(fontsize=11)\n",
    "        ax4.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Replace with your FITS file path\n",
    "fits_file_path = '/Users/benjamincollins/University/master/Red_Cardinal/COSMOS-Web_DR1/Phot_Table_sky_matched.fits'\n",
    "\n",
    "\n",
    "# Optional: specify output path for the plot\n",
    "output_plot_path = '/Users/benjamincollins/University/master/Red_Cardinal/COSMOS-Web_DR1/plots/'\n",
    "\n",
    "# Run the analysis\n",
    "data, fig = analyse_photometry_comparison(fits_file_path, output_plot_path, plot_type='appendix')\n",
    "\n",
    "#data = load_and_prepare_data(fits_file_path)\n",
    "create_reduced_comparison_plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section to perform photometry with all 4 filters (F770W, F1000W, F1800W, F2100W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing the photometry became much easier now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aperture_table = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/apertures/aperture_table_v5.csv'\n",
    "output_folder = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/'\n",
    "\n",
    "phot.perform_photometry(f770w_files, aperture_table, output_folder, suffix='v7')\n",
    "\n",
    "phot.perform_photometry(f1000w_files, aperture_table, output_folder, suffix='v7')\n",
    "\n",
    "phot.perform_photometry(f1800w_files, aperture_table, output_folder, suffix='v7')\n",
    "\n",
    "phot.perform_photometry(f2100w_files, aperture_table, output_folder, suffix='v7')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now combine the csv files into one big table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_table_v6 = 'Photometry_Table_MIRI_v7.fits'\n",
    "\n",
    "results_dir = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/results/'\n",
    "\n",
    "f770w_fname  = os.path.join(results_dir, 'phot_table_F770W_v6.csv')\n",
    "f1000w_fname = os.path.join(results_dir, 'phot_table_F1000W_v6.csv')\n",
    "f1800w_fname = os.path.join(results_dir, 'phot_table_F1800W_v6.csv')\n",
    "f2100w_fname = os.path.join(results_dir, 'phot_table_F2100W_v6.csv')\n",
    "\n",
    "csv_paths = [f770w_fname, f1000w_fname, f1800w_fname, f2100w_fname]\n",
    "\n",
    "# Now create the combined FITS table\n",
    "phot.create_fits_table_from_csv(csv_paths, output_file=fits_table_v6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to read and interpret the flags:\n",
    "fits_table_v5 = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/phot_tables/Flux_Aperture_PSFMatched_AperCorr_MIRI_v5.fits'\n",
    "table = Table.read(fits_table_v5)\n",
    "\n",
    "for i, gid in enumerate(table['ID']):\n",
    "    filters_available = table['Filters'][i].split(',')\n",
    "    has_companion = table['Flag_Com'][i]\n",
    "    artifact_flags = table['Flag_Art'][i]\n",
    "    \n",
    "    print(f\"Galaxy {gid}: Companion = {has_companion}\")\n",
    "    for j, filt in enumerate(filters_available):\n",
    "        has_artifact = artifact_flags[j]\n",
    "        print(f\"  {filt}: Artifact = {has_artifact}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how the heatmap looks with only detections displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nondetections = {\n",
    "        \"F770W\": [7696,7730,8465,8843,9517,9809,9901,9986,10415,10600,11086,11137,\n",
    "            11247,11451,11481,11853,12133,12175,12202,12213,12443,12513,16424,16615,\n",
    "            17534,17793,18769,19024,19098,19307,19681,20720,21218,21424,21451,\n",
    "            21472,21477,21547,22606],\n",
    "        \"F1000W\": [11716,11723,11853,12133,12164,12202,12332,12443,12513,13297,16424,\n",
    "                    16615,17534,17793,17984,18327,19307],\n",
    "        \"F1800W\": [7102,7904,7922,7934,8338,8465,9517,10054,10128,10339,10400,10415,\n",
    "                    10565,10592,10600,11142,11247,11420,11451,11716,11723,12014,12133,\n",
    "                    12164,12175,12202,12213,12332,12513,16419,18332,18769,19024,19098,\n",
    "                    19393,19563,19681,21451],\n",
    "        \"F2100W\": [7102,11142,11247,11494,11716,11723,11853,12014,12133,12164,12175,\n",
    "                    12202,12213,12332,12443,12513,13297,16419,16424,16474,16516,16615,\n",
    "                    16874,17000,17517,17534,17842,17916,17984,18094]\n",
    "    }\n",
    "\n",
    "det_f770w = [7102,7136,7185,7549,7904,7922,7934,8013,8338,8469,8500,9180,9395,9519,\n",
    "             9871,10021,10054,10128,10245,10314,10339,10400,10565,10592,11136,11142,\n",
    "             11420,11494,11716,11723,12014,12020,12148,12164,12282,12332,12340,12443,\n",
    "             12717,13103,16419,16474,16516,16874,17000,17517,17669,18332,18977,19393,\n",
    "             19563,20238,20397,21165,21452,21541,22199]\n",
    "\n",
    "det_f1000w = [7102,11136,11142,11494,12020,12282,12340,12717,13103,13174,16419,16474,\n",
    "              16516,17000,17517,17669,17842,18252]\n",
    "\n",
    "det_f1800w = [8500,9871,10021,10245,10314,11136,11494,12020,12282,12717,13103,16874,\n",
    "              18977]\n",
    "\n",
    "det_f2100w = [11136,12020,12282,12340,12717,13103,13174,17669,18139,18252]\n",
    "\n",
    "detections = {\n",
    "    'F770W': det_f770w,\n",
    "    'F1000W': det_f1000w,\n",
    "    'F1800W': det_f1800w,\n",
    "    'F2100W': det_f2100w\n",
    "}\n",
    "\n",
    "\n",
    "print(len(det_f770w))\n",
    "print(len(det_f1000w))\n",
    "print(len(det_f1800w))\n",
    "print(len(det_f2100w))\n",
    "\n",
    "#fits_table_v5 = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/phot_tables/Flux_Aperture_PSFMatched_AperCorr_MIRI_v5.fits'\n",
    "#fig_path = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/miri_detections_v3.png'\n",
    "#stats_path = '~/University/master/Red_Cardinal/photometry/miri_detections.txt'\n",
    "#phot.galaxy_statistics(fits_table_v5, fig_path=fig_path, detections=detections, cols=2)\n",
    "\n",
    "#fig_path = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/miri_coverage_v3.png'\n",
    "#phot.galaxy_statistics(fits_table_v5, fig_path=fig_path, cols=2)\n",
    "#phot.plot_galaxy_filter_matrix(fits_table_v5, fig_path, 'MIRI Detections', detections)\n",
    "\n",
    "#fig_path = '~/University/master/Red_Cardinal/photometry/miri_coverage.png'\n",
    "#phot.plot_galaxy_filter_matrix(fits_table_v5, fig_path, 'MIRI Coverage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for my newest function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_dir = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/vis_data_small/'\n",
    "mosaic_dir = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/mosaic_plots_v2/'\n",
    "plane_sub_dir = '/Users/benjamincollins/University/master/Red_Cardinal/photometry/plots/plane_sub/'\n",
    "\n",
    "phot.create_mosaics(vis_dir, mosaic_dir=mosaic_dir, plane_sub_dir=plane_sub_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for mask visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils.aperture import EllipticalAperture, EllipticalAnnulus, aperture_photometry\n",
    "\n",
    "vis_data = phot.load_vis('/Users/benjamincollins/University/master/Red_Cardinal/photometry/vis_data/21424_F770W.h5')\n",
    "\n",
    "# Extract data from the dictionary\n",
    "image_data = vis_data['original_data']\n",
    "background_plane = vis_data['background_plane']\n",
    "background_subtracted = vis_data['background_subtracted']\n",
    "segm_mask = vis_data['segmentation_mask']\n",
    "mask_vis = vis_data['mask_vis']\n",
    "aperture_params = vis_data['aperture_params']\n",
    "sigma = vis_data['sigma']\n",
    "region_name = vis_data['region_name']\n",
    "galaxy_id = vis_data['galaxy_id']\n",
    "filter = vis_data['filter']\n",
    "\n",
    "# Create aperture objects for plotting\n",
    "x_center = aperture_params['x_center']\n",
    "y_center = aperture_params['y_center']\n",
    "a = aperture_params['a']\n",
    "b = aperture_params['b']\n",
    "theta = aperture_params['theta']\n",
    "\n",
    "source_aperture = EllipticalAperture(\n",
    "    positions=(x_center, y_center),\n",
    "    a=a,\n",
    "    b=b,\n",
    "    theta=theta\n",
    ")\n",
    "\n",
    "# Create figure with three subplots in a horizontal row\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4.3))\n",
    "\n",
    "# Background-subtracted data\n",
    "vmin = np.nanpercentile(background_subtracted, 5)\n",
    "vmax = np.nanpercentile(background_subtracted, 95)\n",
    "\n",
    "im1 = axes[0].imshow(background_subtracted, origin='lower', cmap='magma', vmin=vmin, vmax=vmax)\n",
    "plt.colorbar(im1, ax=axes[0], label='Background-subtracted Flux [MJy/(sr pixel)]')\n",
    "source_aperture.plot(ax=axes[0], color='blue', lw=4)\n",
    "\n",
    "# Mask visualisation\n",
    "cmap = plt.cm.get_cmap('viridis', 4)\n",
    "im3 = axes[1].imshow(mask_vis, origin='lower', cmap=cmap, vmin=-0.5, vmax=3.5)\n",
    "cbar = plt.colorbar(im3, ax=axes[1], ticks=[0, 1, 2, 3])\n",
    "cbar.set_ticklabels([f'Excluded\\n', 'Used for fitting', \n",
    "                        f'{region_name} region', 'Source'])\n",
    "    \n",
    "# Tight layout and saving the figure‚\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.85)  # Adjust to prevent overlap with annotation\n",
    "plt.savefig(os.path.join('/Users/benjamincollins/University/master/Red_Cardinal/random_plots/21424_regions.png'), dpi=150)\n",
    "plt.close(fig)\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
