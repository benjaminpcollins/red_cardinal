{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photometry on MIRI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import subprocess\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS, FITSFixedWarning\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "from astropy.stats import SigmaClip\n",
    "\n",
    "from photutils.aperture import EllipticalAperture, aperture_photometry\n",
    "from photutils.background import Background2D, MedianBackground\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=FITSFixedWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect Amirs table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path =  '/home/bpc/University/master/Red_Cardinal/Flux_Aperture_PSFMatched_AperCorr_old.fits'\n",
    "\n",
    "table = Table.read(table_path)\n",
    "print(table[:5])\n",
    "table.info()\n",
    "print(table.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's choose a galaxy, read its aperture data and overplot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cutout(file_path, index=1):\n",
    "    \"\"\"Loads a FITS cutout file and extracts the data, header, and WCS.\"\"\"\n",
    "    try:\n",
    "        with fits.open(file_path) as hdu:\n",
    "            data = hdu[index].data\n",
    "            header = hdu[index].header\n",
    "            wcs = WCS(header)\n",
    "        return data, wcs\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None, None\n",
    "\n",
    "def adjust_aperture(galaxy_id, filter, survey, obs, output_folder, save_plot=False):\n",
    "    \n",
    "    # --- Load the FITS table ---\n",
    "    #table_path =  '/home/bpc/University/master/Red_Cardinal/Flux_Aperture_PSFMatched_AperCorr_old.fits'\n",
    "    #aperture_table = Table.read(table_path)\n",
    "    table_path =  '/home/bpc/University/master/Red_Cardinal/aperture_table.csv'\n",
    "    df = pd.read_csv(table_path)\n",
    "    \n",
    "    # --- Select the galaxy by ID ---\n",
    "    #row = aperture_table[aperture_table['ID'] == galaxy_id][0]\n",
    "    galaxy_id = int(galaxy_id)\n",
    "    row = df[df['ID'] == galaxy_id].iloc[0]\n",
    "\n",
    "    # --- Read in rotation angle of MIRI FITS file ---\n",
    "    angle_file = '/home/bpc/University/master/Red_Cardinal/rotation_angles.json'\n",
    "    with open(angle_file, \"r\") as f:\n",
    "        angles = json.load(f)\n",
    "    angle = angles[f\"angle_{survey}{obs}\"]\n",
    "    \n",
    "    # --- Read WCS from NIRCam image ---\n",
    "    nircam_path = f\"/home/bpc/University/master/Red_Cardinal/NIRCam/F444W_cutouts/{galaxy_id}_F444W_cutout.fits\"\n",
    "    nircam_data, nircam_wcs = load_cutout(nircam_path)\n",
    "\n",
    "    # --- Convert NIRCam pixel coordinates to sky ---\n",
    "    sky_coord = nircam_wcs.pixel_to_world(row['Apr_Xcenter'], row['Apr_Ycenter'])\n",
    "\n",
    "    # --- Open MIRI cutout image ---\n",
    "    miri_path = f\"/home/bpc/University/master/Red_Cardinal/cutouts/{galaxy_id}_{filter}_cutout_{survey}{obs}.fits\"\n",
    "    miri_data, miri_wcs = load_cutout(miri_path)\n",
    "\n",
    "    # --- Convert sky coords to MIRI pixel coordinates ---\n",
    "    miri_x, miri_y = miri_wcs.world_to_pixel(sky_coord)\n",
    "\n",
    "    # --- Create elliptical region in MIRI pixel space ---\n",
    "    nircam_scale = 0.03    # arcsec/pixel\n",
    "    miri_scale = 0.11092  # arcsec per pixel\n",
    "    \n",
    "    # arcsec/pixel\n",
    "    scale_factor = nircam_scale / miri_scale\n",
    "    \n",
    "    # --- Specify parameters for the ellips ---\n",
    "    width = row['Apr_A'] * scale_factor\n",
    "    height = row['Apr_B'] * scale_factor\n",
    "    theta = -row['Apr_Theta']\n",
    "    theta_new = ((theta - angle) % 180) * u.deg\n",
    "    \n",
    "    # --- Create region file and check if folder exists ---\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    reg_file = os.path.join(output_folder, f'regions/{galaxy_id}_{survey}{obs}_aperture.reg') \n",
    "    \n",
    "    # --- Write to DS9-compatible region file ---\n",
    "    with open(reg_file, \"w\") as fh:\n",
    "        fh.write(\"# Region file format: DS9 version 4.1\\n\")\n",
    "        fh.write(\"global color=red dashlist=8 3 width=2 font=\\\"helvetica 10 normal\\\" \"\n",
    "                \"select=1 highlite=1 dash=0 fixed=0 edit=1 move=1 delete=1 include=1 source=1\\n\")\n",
    "        fh.write(\"image\\n\")\n",
    "        fh.write(f\"ellipse({miri_x:.2f},{miri_y:.2f},{width:.2f},{height:.2f},{theta_new:.2f})\\n\")\n",
    "\n",
    "    if save_plot:\n",
    "        \n",
    "        # --- Clean and prepare the MIRI data for plotting ---\n",
    "        miri_clean = np.copy(miri_data)\n",
    "        finite_vals = miri_clean[np.isfinite(miri_clean)].flatten()\n",
    "        \n",
    "        # Sort and get lowest 80% values\n",
    "        sorted_vals = np.sort(finite_vals)\n",
    "        cutoff_index = int(0.8 * len(sorted_vals))\n",
    "        background_vals = sorted_vals[:cutoff_index]\n",
    "        background_mean = np.mean(background_vals)\n",
    "\n",
    "        # Replace NaNs or infs with background mean\n",
    "        miri_clean[~np.isfinite(miri_clean)] = background_mean\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6,6))\n",
    "        ax.imshow(miri_clean, origin='lower', cmap='gray', vmin=np.percentile(miri_clean, 5), vmax=np.percentile(miri_clean, 99))\n",
    "\n",
    "        # Original ellipse (without rotation correction)\n",
    "        ellipse_original = Ellipse(\n",
    "            xy=(miri_x, miri_y),\n",
    "            width=width,\n",
    "            height=height,\n",
    "            angle=theta,  # Just the original Î¸!\n",
    "            edgecolor='red',\n",
    "            facecolor='none',\n",
    "            lw=2,\n",
    "            label='Original Ellipse'\n",
    "        )\n",
    "        ax.add_patch(ellipse_original)\n",
    "\n",
    "        ellipse = Ellipse(\n",
    "            xy=(miri_x, miri_y),\n",
    "            width=width,\n",
    "            height=height,\n",
    "            angle=theta_new.to_value(u.deg),\n",
    "            edgecolor='blue',\n",
    "            linestyle='--',  # maybe dashed to differentiate\n",
    "            facecolor='none',\n",
    "            lw=2,\n",
    "            label='Rotated Ellipse'\n",
    "        )\n",
    "        ax.add_patch(ellipse)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ax.set_title(f\"Galaxy {galaxy_id} - {filter} ({survey}{obs})\")\n",
    "        ax.set_xlim(miri_x - 30, miri_x + 30)\n",
    "        ax.set_ylim(miri_y - 30, miri_y + 30)\n",
    "        ax.legend(loc='upper right')\n",
    "        \n",
    "        # Save figure\n",
    "        png_path = os.path.join(output_folder, f'masks/{galaxy_id}_{survey}{obs}_aperture_overlay.png')\n",
    "        plt.savefig(png_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        \n",
    "    # Collect modified aperture data\n",
    "    aperture_info = {\n",
    "    'Flux': np.nan,           # You don't have these yet\n",
    "    'Flux_Err': np.nan,        \n",
    "    'Image_Err': np.nan,       \n",
    "    'Flux_BKG': np.nan,        \n",
    "    'AB_Mag': np.nan,          \n",
    "    'Flux_BKG_Err': np.nan,    \n",
    "    'N_PIX': np.nan,           \n",
    "    'Apr_A': width,            # Rescaled aperture\n",
    "    'Apr_B': height,\n",
    "    'Apr_Xcenter': miri_x,\n",
    "    'Apr_Ycenter': miri_y,\n",
    "    'Apr_Theta': theta_new.to_value(u.deg),\n",
    "    'ID': galaxy_id\n",
    "    }\n",
    "    \n",
    "    return aperture_info\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and call the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_dir = \"/home/bpc/University/master/Red_Cardinal/cutouts/\"\n",
    "phot_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/\"\n",
    "\n",
    "# Get all FITS file paths\n",
    "fits_files = glob.glob(os.path.join(cutout_dir, '*.fits'))\n",
    "\n",
    "# Get the basenames of the FITS files\n",
    "fits_fnames = [os.path.basename(f) for f in fits_files]\n",
    "\n",
    "adjusted_apertures = []\n",
    "\n",
    "for fname in fits_fnames:\n",
    "    id = fname.split('_')[0]\n",
    "    filter = fname.split('_')[1]\n",
    "    if filter == 'F1800W': continue\n",
    "    survey_obs = fname.split('_')[3]\n",
    "    if '003' in survey_obs:\n",
    "        survey = 'primer'\n",
    "        obs = '003'\n",
    "    elif '004' in survey_obs:\n",
    "        survey = 'primer'\n",
    "        obs = '004'\n",
    "    elif '1' in survey_obs:\n",
    "        survey = 'cweb'\n",
    "        obs = '1'\n",
    "    elif '2' in survey_obs:\n",
    "        survey = 'cweb'\n",
    "        obs = '2'\n",
    "    else:\n",
    "        print(f\"Unknown survey and/or observation number for galaxy {id}:\\n\")\n",
    "        print(survey_obs)\n",
    "    \n",
    "    # Call and collect results\n",
    "    result = adjust_aperture(id, filter, survey, obs, phot_dir, save_plot=False)\n",
    "    if result:\n",
    "        adjusted_apertures.append(result)\n",
    "\n",
    "# After loop: create a DataFrame\n",
    "df_apertures = pd.DataFrame(adjusted_apertures)\n",
    "\n",
    "df_path = '/home/bpc/University/master/Red_Cardinal/photometry/adjusted_apertures.csv'\n",
    "\n",
    "# (optional) Save to CSV or integrate into photometry table\n",
    "df_apertures.to_csv(df_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily open any given FITS file with its corresponding ellipse region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Launch DS9 with the MIRI cutout and the overplotted aperture ---\n",
    "region_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/regions/\"\n",
    "cutout_dir = \"/home/bpc/University/master/Red_Cardinal/cutouts/\"\n",
    "phot_dir = \"/home/bpc/University/master/Red_Cardinal/photometry/\"\n",
    "\n",
    "id = '20397'\n",
    "filter = 'F770W'\n",
    "survey_obs = 'cweb2'\n",
    "cutout_path = os.path.join(cutout_dir, f'{id}_{filter}_cutout_{survey_obs}.fits')\n",
    "reg_path = os.path.join(region_dir, f'{id}_{survey_obs}_aperture.reg')\n",
    "subprocess.run([\"ds9\", cutout_path, \"-regions\", reg_path])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path =  '/home/bpc/University/master/Red_Cardinal/Flux_Aperture_PSFMatched_AperCorr_old.fits'\n",
    "\n",
    "table = Table.read(table_path)\n",
    "print(table[:5])\n",
    "table.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section to perform the actual photometry\n",
    "\n",
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import subprocess\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS, FITSFixedWarning\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "from astropy.stats import SigmaClip\n",
    "\n",
    "from photutils.aperture import EllipticalAperture, aperture_photometry\n",
    "from photutils.background import Background2D, MedianBackground\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=FITSFixedWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's set some parameters straight:\n",
    "\n",
    "pixscale_arcsec = 0.11092  # arcsec per pixel\n",
    "\n",
    "pix_area_sr = 2.89208962133982e-13  # from MIRI header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Functions ---\n",
    "\n",
    "def get_psf(filter_name):\n",
    "    \"\"\"Read MIRI PSF file\"\"\"\n",
    "    psf_file = f'/home/bpc/University/master/Red_Cardinal/WebbPSF/PSF_MIRI_{filter_name}.fits'\n",
    "    with fits.open(psf_file) as psf:\n",
    "        return psf[0].data\n",
    "\n",
    "def get_aperture_params(galaxy_id, aperture_table):\n",
    "    \"\"\"Retrieve aperture parameters from the CSV table.\"\"\"\n",
    "    df = pd.read_csv(aperture_table)\n",
    "    row = df[df['ID'] == int(galaxy_id)].iloc[0]\n",
    "    return row['Apr_Xcenter'], row['Apr_Ycenter'], row['Apr_A'], row['Apr_B'], row['Apr_Theta'] * u.deg\n",
    "\n",
    "def calculate_aperture_correction(psf_data, aperture_params):\n",
    "    \"\"\"Calculate aperture correction for given PSF and aperture.\"\"\"\n",
    "    aperture = EllipticalAperture(\n",
    "        positions=(psf_data.shape[1] / 2, psf_data.shape[0] / 2),\n",
    "        a=aperture_params['a'],\n",
    "        b=aperture_params['b'],\n",
    "        theta=aperture_params['theta']\n",
    "    )\n",
    "    total_flux = np.sum(psf_data)\n",
    "    phot_table = aperture_photometry(psf_data, aperture)\n",
    "    flux_in_aperture = phot_table['aperture_sum'][0]\n",
    "    return total_flux / flux_in_aperture\n",
    "\n",
    "def get_flux_and_uncertainty(data_bkgsub, aperture, background_rms):\n",
    "    \"\"\"Calculate flux and uncertainty from aperture photometry.\"\"\"\n",
    "    phot_table = aperture_photometry(data_bkgsub, aperture, method='exact')\n",
    "    flux = phot_table['aperture_sum'][0]\n",
    "    n_pix = np.pi * aperture.a * aperture.b\n",
    "    flux_uncertainty = np.sqrt(n_pix) * np.median(background_rms)\n",
    "    return flux, flux_uncertainty, n_pix\n",
    "\n",
    "def get_background(data):\n",
    "    \"\"\"Subtract background using a model.\"\"\"\n",
    "    bkg = Background2D(\n",
    "        data,\n",
    "        box_size=5,\n",
    "        filter_size=3,\n",
    "        sigma_clip=SigmaClip(sigma=3.0),\n",
    "        bkg_estimator=MedianBackground(),\n",
    "        exclude_percentile=1.0,  # a bit less aggressive\n",
    "        coverage_mask=np.isnan(data)\n",
    "    )\n",
    "    return bkg.background, bkg.background_rms, bkg.background_mesh_masked\n",
    "\n",
    "def save_masked_cutout(galaxy_id, bkg, aperture_params, filter, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Create a Primary HDU\n",
    "    hdu = fits.PrimaryHDU(bkg)\n",
    "    \n",
    "    # Add aperture info to header\n",
    "    hdr = hdu.header\n",
    "    hdr['Apr_Xcenter'] = aperture_params['x_center']\n",
    "    hdr['Apr_Ycenter'] = aperture_params['y_center']\n",
    "    hdr['Apr_A'] = aperture_params['a']\n",
    "    hdr['Apr_B'] = aperture_params['b']\n",
    "    hdr['Apr_Theta'] = aperture_params['theta']\n",
    "    \n",
    "    output_path = os.path.join(output_folder, f\"{galaxy_id}_{filter}_masked.fits\")\n",
    "    hdu.writeto(output_path, overwrite=True)\n",
    "\n",
    "    #print(f\"Saved masked cutout for {galaxy_id} at {output_path}\")\n",
    "    \n",
    "# --- Main Loop ---\n",
    "\n",
    "def perform_photometry(cutout_files, aperture_table, psf_data, output_folder):\n",
    "    \"\"\"Main loop for photometry analysis.\"\"\"\n",
    "    photometry_results = []\n",
    "    \n",
    "    for fits_path in cutout_files:\n",
    "        \n",
    "        fits_name = os.path.basename(fits_path)\n",
    "        galaxy_id = fits_name.split('_')[0]\n",
    "        filter = fits_name.split('_')[1]\n",
    "        \n",
    "        with fits.open(fits_path) as hdul:\n",
    "            data = hdul[1].data\n",
    "        \n",
    "        # Background subtraction\n",
    "        background, background_rms, background_mesh_masked = get_background(data)\n",
    "        data_bkgsub = data - background\n",
    "        flux_bkg = np.median(background)\n",
    "        flux_bkg_err = np.median(background_rms)\n",
    "        \n",
    "        #print(np.nanmin(background), np.nanmax(background))\n",
    "        \n",
    "        if np.allclose(data, data_bkgsub, equal_nan=True):\n",
    "            print(\"Warning: background subtraction does not do anything!\")\n",
    "        \n",
    "        # Aperture parameters\n",
    "        miri_x, miri_y, width, height, theta = get_aperture_params(galaxy_id, aperture_table)\n",
    "        aperture = EllipticalAperture((miri_x, miri_y), a=width / 2, b=height / 2, theta=theta.to_value(u.rad))\n",
    "\n",
    "        # Photometry\n",
    "        flux, flux_uncertainty, n_pix = get_flux_and_uncertainty(data_bkgsub, aperture, background_rms)\n",
    "\n",
    "        # Aperture correction\n",
    "        aperture_params = {'x_center': miri_x, 'y_center': miri_y, 'a': width / 2, 'b': height / 2, 'theta': theta.to_value(u.rad)}\n",
    "        correction_factor = calculate_aperture_correction(psf_data, aperture_params)\n",
    "\n",
    "        # Apply aperture correction\n",
    "        flux_corrected = flux * correction_factor\n",
    "        flux_uncertainty_corrected = flux_uncertainty * correction_factor\n",
    "        flux_bkg_corrected = flux_bkg * correction_factor\n",
    "        flux_bkg_err_corrected = flux_bkg_err * correction_factor\n",
    "\n",
    "        # AB magnitude\n",
    "        if flux_corrected > 0:\n",
    "            ab_mag = -2.5 * np.log10(flux_corrected) + 8.90\n",
    "        else: ab_mag = np.nan\n",
    "        \n",
    "        # Append results\n",
    "        photometry_results.append({\n",
    "            'Flux': flux_corrected,\n",
    "            'Flux_Err': flux_uncertainty_corrected,\n",
    "            'Image_Err': np.median(background_rms),\n",
    "            'Flux_BKG': flux_bkg_corrected,\n",
    "            'AB_Mag': ab_mag,\n",
    "            'Flux_BKG_Err': flux_bkg_err_corrected,\n",
    "            'N_PIX': n_pix,\n",
    "            'Apr_A': width / 2,\n",
    "            'Apr_B': height / 2,\n",
    "            'Apr_Xcenter': miri_x,\n",
    "            'Apr_Ycenter': miri_y,\n",
    "            'Apr_Theta': theta.to_value(u.deg),\n",
    "            'ID': int(galaxy_id)\n",
    "        })\n",
    "\n",
    "        # Save masked FITS files\n",
    "        bkg_dir = os.path.join(output_folder, 'mosaic_fits/')\n",
    "        os.makedirs(bkg_dir, exist_ok=True)\n",
    "        save_masked_cutout(galaxy_id, background_mesh_masked, aperture_params, filter, bkg_dir)\n",
    "        \n",
    "    # Save to output table (assuming it's a pandas DataFrame)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_table = os.path.join(output_folder, f'results/photometry_table_{filter}.csv')\n",
    "    output_df = pd.DataFrame(photometry_results)\n",
    "    output_df.to_csv(output_table, index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here is where the magic happens!\n",
    "\n",
    "I wanna call the photometry function with:\n",
    "\n",
    "perform_photometry(galaxy_id, filter, aperture_table, psf_data, cutouts_folder, output_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters ---\n",
    "cutouts_folder = \"/home/bpc/University/master/Red_Cardinal/cutouts/\"\n",
    "output_folder = '/home/bpc/University/master/Red_Cardinal/photometry/'\n",
    "aperture_table = '/home/bpc/University/master/Red_Cardinal/photometry/adjusted_apertures.csv'\n",
    "\n",
    "f770w_files = glob.glob(os.path.join(cutouts_folder, '*F770W*.fits'))\n",
    "f1800w_files = glob.glob(os.path.join(cutouts_folder, '*F1800W*.fits'))\n",
    "\n",
    "psf_f770w = get_psf('F770W')\n",
    "psf_f1800w = get_psf('F1800W')\n",
    "f770w_files = [f770w_files[1]]\n",
    "perform_photometry(f770w_files, aperture_table, psf_f770w, output_folder)\n",
    "#perform_photometry(f1800w_files, aperture_table, psf_f1800w, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and plot some of the images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the saved masked cutout\n",
    "background_dir = '/home/bpc/University/master/Red_Cardinal/photometry/mosaic_fits/'\n",
    "\n",
    "cutout_path = os.path.join(background_dir, '22199_F770W_masked.fits')\n",
    "with fits.open(cutout_path) as hdul:\n",
    "    bkg = hdul[0].data\n",
    "\n",
    "plt.imshow(bkg, origin='lower', cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dir = '/home/bpc/University/master/Red_Cardinal/photometry/results/'\n",
    "\n",
    "df_fw770 = pd.read_csv(os.path.join(table_dir, 'photometry_table_F770W.csv'))\n",
    "df_fw1800 = pd.read_csv(os.path.join(table_dir, 'photometry_table_F1800W.csv'))\n",
    "\n",
    "# Create lookup dictionaries\n",
    "photometry_fw770 = {row['ID']: row for _, row in df_fw770.iterrows()}\n",
    "photometry_fw1800 = {row['ID']: row for _, row in df_fw1800.iterrows()}\n",
    "\n",
    "# Find all unique IDs\n",
    "all_ids = set(photometry_fw770.keys()).union(photometry_fw1800.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and create those juicy looking mosaics with the cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mosaic(galaxy_id, plotting_data_fw770, plotting_data_fw1800, output_dir):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6)) if galaxy_id in plotting_data_fw770 and galaxy_id in plotting_data_fw1800 else plt.subplots(1, 1, figsize=(6, 6))\n",
    "    \n",
    "    if isinstance(axs, plt.Axes):  # Only one subplot\n",
    "        axs = [axs]\n",
    "\n",
    "    if galaxy_id in plotting_data_fw770:\n",
    "        data = plotting_data_fw770[galaxy_id]['background']\n",
    "        mask = plotting_data_fw770[galaxy_id]['source_mask']\n",
    "        masked_data = np.ma.array(data, mask=mask)\n",
    "        cmap = plt.cm.viridis.copy()\n",
    "        cmap.set_bad('white')\n",
    "        axs[0].imshow(masked_data, origin='lower', cmap=cmap)\n",
    "        axs[0].set_title(f'FW770 - ID {galaxy_id}')\n",
    "        axs[0].axis('off')\n",
    "\n",
    "    if galaxy_id in plotting_data_fw1800 and len(axs) > 1:\n",
    "        data = plotting_data_fw1800[galaxy_id]['background']\n",
    "        mask = plotting_data_fw1800[galaxy_id]['source_mask']\n",
    "        masked_data = np.ma.array(data, mask=mask)\n",
    "        cmap = plt.cm.viridis.copy()\n",
    "        cmap.set_bad('white')\n",
    "        axs[1].imshow(masked_data, origin='lower', cmap=cmap)\n",
    "        axs[1].set_title(f'FW1800 - ID {galaxy_id}')\n",
    "        axs[1].axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f'galaxy_{galaxy_id}.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photometry_dir = '/home/bpc/University/master/Red_Cardinal/photometry/'\n",
    "\n",
    "with open(os.path.join(photometry_dir, 'results/plotting_table_F770W.pkl'), 'rb') as f:\n",
    "    plotting_data_fw770 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(photometry_dir, 'results/plotting_table_F1800W.pkl'), 'rb') as f:\n",
    "    plotting_data_fw1800 = pickle.load(f)\n",
    "\n",
    "output_dir = os.path.join(photometry_dir, 'mosaic_plots/')\n",
    "for galaxy_id in all_ids:\n",
    "    plot_mosaic(galaxy_id, plotting_data_fw770, plotting_data_fw1800, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
