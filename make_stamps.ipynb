{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Make RGB NIRCam stamps showing slit footprint\n",
    "We will be using the `trilogy` package to make RGB stamps and the shutter footprint regions.\n",
    "The information we need to show the footprint and the source (optional) is all in the \"shutters\" files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from astropy.io import fits\n",
    "from miri_utils.stamp_maker import resample_nircam, make_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- SETUP ----------\n",
    "input_dir = \"/home/bpc/University/master/Red_Cardinal/cutouts_3x3/\"\n",
    "output_dir = \"/home/bpc/University/master/Red_Cardinal/stamps_miri_v2/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Now let's resample the NIRCam data instead of MIRI!\n",
    "\n",
    "NB: The transformation of the WCS does not work properly, but we are not concerned about it here since we only use the images to stack them together anyways, we don't care about sky coordinates here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Call the resampling function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_nircam(input_dir, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- STEP 1: Get IDs from NIRCam, PRIMER and COSMOS-Web ----------\n",
    "f444w_files = glob.glob(os.path.join(input_dir, \"*F444W_cutout_nircam_res.fits\"))\n",
    "f444w_ids = [os.path.basename(f).split(\"_F444W\")[0] for f in f444w_files]\n",
    "\n",
    "f770w_primer_files = glob.glob(os.path.join(input_dir, \"*F770W_cutout_primer.fits\"))\n",
    "f770w_primer_ids = [os.path.basename(f).split(\"_F770W\")[0] for f in f770w_primer_files]\n",
    "\n",
    "f770w_cweb_files = glob.glob(os.path.join(input_dir, \"*F770W_cutout_cweb.fits\"))\n",
    "f770w_cweb_ids = [os.path.basename(f).split(\"_F770W\")[0] for f in f770w_cweb_files]\n",
    "\n",
    "f1800w_files = glob.glob(os.path.join(input_dir, \"*F1800W*.fits\"))\n",
    "f1800w_ids = [os.path.basename(f).split(\"_F1800W\")[0] for f in f1800w_files]\n",
    "\n",
    "# Remove all galaxies in f770w_primer_ids from f770w_cweb_ids\n",
    "f770w_cweb_ids = np.setdiff1d(f770w_cweb_ids, f770w_primer_ids)\n",
    "f770w_leftover_primer = np.setdiff1d(f770w_primer_ids, f1800w_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Now let's try and call the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gal_id in f1800w_ids:\n",
    "    try:\n",
    "        print(f\"Creating image for {gal_id}...\")\n",
    "        \n",
    "        # Construct base filenames (without [0])\n",
    "        r_file_base = os.path.join(input_dir, f\"{gal_id}_F1800W_cutout_primer.fits\")\n",
    "        g_file_primer_base = os.path.join(input_dir, f\"{gal_id}_F770W_cutout_primer.fits\")\n",
    "        g_file_cweb_base = os.path.join(input_dir, f\"{gal_id}_F770W_cutout_cweb.fits\")\n",
    "        b_file_base = os.path.join(input_dir, f\"{gal_id}_F444W_cutout_nircam_res.fits\")\n",
    "\n",
    "        # Decide which F770W file to use\n",
    "        if gal_id in f770w_primer_ids and os.path.exists(g_file_primer_base):\n",
    "            g_file = g_file_primer_base + \"[1]\"\n",
    "        elif gal_id in f770w_cweb_ids and os.path.exists(g_file_cweb_base):\n",
    "            g_file = g_file_cweb_base + \"[1]\"\n",
    "        else:\n",
    "            print(f\"[Skipping {gal_id}] No valid F770W file found.\")\n",
    "            continue\n",
    "\n",
    "        # Now safely add [0] to files\n",
    "        r_file = r_file_base + \"[1]\"\n",
    "        b_file = b_file_base + \"[0]\"\n",
    "        \n",
    "        # Stack into imagesRGB dictionary\n",
    "        imagesRGB = {'R': [r_file], \n",
    "                    'G': [g_file], \n",
    "                    'B': [b_file]}\n",
    "        \n",
    "        # Call your image function (without shutters)\n",
    "        outfile = os.path.join(output_dir, f\"{gal_id}_primer.pdf\")\n",
    "        if gal_id == '19098':\n",
    "            make_stamp(imagesRGB, outfile=outfile, \n",
    "                    Q_r=10, alpha_r=1, weight_r=1,\n",
    "                    Q_g=10, alpha_g=1, weight_g=1,\n",
    "                    Q_b=10, alpha_b=5, weight_b=1,\n",
    "                    stretch='asinh')\n",
    "            \n",
    "        else:\n",
    "            make_stamp(imagesRGB, outfile=outfile, \n",
    "                    Q_r=5, alpha_r=0.7, weight_r=1,\n",
    "                    Q_g=5, alpha_g=0.85, weight_g=1,\n",
    "                    Q_b=10, alpha_b=1.0, weight_b=1,\n",
    "                    stretch='asinh')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gal_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Produce the stamps for all PRIMER galaxies that were only mapped in F770W AND for COSMOS-Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gal_id in f770w_leftover_primer:\n",
    "    try:\n",
    "        print(f\"Creating image for {gal_id}...\")\n",
    "        \n",
    "        # Construct base filenames (without [0])\n",
    "        r_file_base = os.path.join(input_dir, f\"{gal_id}_F770W_cutout_primer.fits\")\n",
    "        b_file_base = os.path.join(input_dir, f\"{gal_id}_F444W_cutout_nircam_res.fits\")\n",
    "\n",
    "        # Now safely add [1] to files\n",
    "        r_file = r_file_base + \"[1]\"\n",
    "        b_file = b_file_base + \"[0]\"\n",
    "        \n",
    "        with fits.open(r_file_base) as hdul:\n",
    "            r_data = hdul[1].data\n",
    "            g_data = np.zeros_like(r_data)  # fake green\n",
    "        fits.writeto('fake_green.fits', g_data, overwrite=True)\n",
    "        \n",
    "        # Stack into imagesRGB dictionary\n",
    "        imagesRGB = {'R': [r_file], \n",
    "                    'G': ['fake_green.fits[0]'], \n",
    "                    'B': [b_file]}\n",
    "        \n",
    "        # Call your image function (without shutters)\n",
    "        # Q determines the strength of the non-linearity for the stretch.\n",
    "        # alpha adjusts the sensitivity of the stretch for the given filter.\n",
    "\n",
    "        outfile = os.path.join(output_dir, f\"{gal_id}_primer.pdf\")\n",
    "        make_stamp(imagesRGB, outfile=outfile, \n",
    "                Q_r=5, alpha_r=0.7, weight_r=1,\n",
    "                Q_g=5, alpha_g=0.85, weight_g=1,\n",
    "                Q_b=10, alpha_b=1.0, weight_b=1,\n",
    "                stretch='asinh')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gal_id}: {e}\")\n",
    "\n",
    "for gal_id in f770w_cweb_ids:\n",
    "    try:\n",
    "        print(f\"Creating image for {gal_id}...\")\n",
    "        \n",
    "        # Construct base filenames (without [0])\n",
    "        r_file_base = os.path.join(input_dir, f\"{gal_id}_F770W_cutout_cweb.fits\")\n",
    "        b_file_base = os.path.join(input_dir, f\"{gal_id}_F444W_cutout_nircam_res.fits\")\n",
    "\n",
    "        # Now safely add [1] to files\n",
    "        r_file = r_file_base + \"[1]\"\n",
    "        b_file = b_file_base + \"[0]\"\n",
    "        \n",
    "        with fits.open(r_file_base) as hdul:\n",
    "            r_data = hdul[1].data\n",
    "            g_data = np.zeros_like(r_data)  # fake green\n",
    "        fits.writeto('fake_green.fits', g_data, overwrite=True)\n",
    "        \n",
    "        # Stack into imagesRGB dictionary\n",
    "        imagesRGB = {'R': [r_file], \n",
    "                    'G': ['fake_green.fits[0]'], \n",
    "                    'B': [b_file]}\n",
    "        \n",
    "        # Call your image function (without shutters)\n",
    "        # Q determines the strength of the non-linearity for the stretch.\n",
    "        # alpha adjusts the sensitivity of the stretch for the given filter.\n",
    "\n",
    "        outfile = os.path.join(output_dir, f\"{gal_id}_cweb.pdf\")\n",
    "        make_stamp(imagesRGB, outfile=outfile, \n",
    "                Q_r=5, alpha_r=0.7, weight_r=1,\n",
    "                Q_g=5, alpha_g=0.85, weight_g=1,\n",
    "                Q_b=10, alpha_b=1.0, weight_b=1,\n",
    "                stretch='asinh')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gal_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Check extensions in cutout FITS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_file = \"/home/bpc/University/master/Red_Cardinal/cutouts_3x3/18769_F1800W_cutout_primer.fits\"\n",
    "with fits.open(r_file) as hdul:\n",
    "    for i, hdu in enumerate(hdul):\n",
    "        print(f\"HDU {i}: {hdu.name}, shape = {getattr(hdu.data, 'shape', None)}\")\n",
    "\n",
    "g_file = \"/home/bpc/University/master/Red_Cardinal/cutouts_3x3/18769_F770W_cutout_primer.fits\"\n",
    "with fits.open(g_file) as hdul:\n",
    "    for i, hdu in enumerate(hdul):\n",
    "        print(f\"HDU {i}: {hdu.name}, shape = {getattr(hdu.data, 'shape', None)}\")\n",
    "        \n",
    "b_file = \"/home/bpc/University/master/Red_Cardinal/cutouts_3x3/18769_F444W_cutout_nircam.fits\"\n",
    "with fits.open(b_file) as hdul:\n",
    "    for i, hdu in enumerate(hdul):\n",
    "        print(f\"HDU {i}: {hdu.name}, shape = {getattr(hdu.data, 'shape', None)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Now let's check if we got all the galaxies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(input_dir, \"*.fits\"))\n",
    "unique_ids = []\n",
    "\n",
    "for file in files:\n",
    "    filename = os.path.basename(file)\n",
    "    \n",
    "    if \"nircam\" in filename:     \n",
    "        continue\n",
    "    \n",
    "    id = filename.split(\"_\")[0]\n",
    "    if id not in unique_ids:\n",
    "        unique_ids.append(id)\n",
    "print(unique_ids)\n",
    "print(len(unique_ids))\n",
    "\n",
    "stamps = glob.glob(os.path.join(output_dir, \"*.pdf\"))\n",
    "unique_stamps = []\n",
    "\n",
    "for stamp in stamps:\n",
    "    stampname = os.path.basename(stamp)\n",
    "    id = stampname.split(\"_\")[0]\n",
    "    if id not in unique_stamps:\n",
    "        unique_stamps.append(id)\n",
    "\n",
    "print(unique_stamps)\n",
    "print(len(unique_stamps))\n",
    "\n",
    "for gal in f770w_leftover_primer:\n",
    "    if gal in f770w_cweb_ids:\n",
    "        print(gal)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
