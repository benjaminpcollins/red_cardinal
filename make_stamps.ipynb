{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Make RGB NIRCam stamps showing slit footprint\n",
    "We will be using the `trilogy` package to make RGB stamps and the shutter footprint regions.\n",
    "The information we need to show the footprint and the source (optional) is all in the \"shutters\" files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trilogy import trilogy\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.table import Table\n",
    "from astropy import table\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "import glob\n",
    "\n",
    "from collections import defaultdict\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL  # Python Image Library\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "import contextlib\n",
    "\n",
    "from astropy.nddata import Cutout2D\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Function to produce the RGB-stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_image(img, stretch='asinh', Q=10, alpha=1, weight=1.0):\n",
    "    \"\"\"\n",
    "    Normalises the input image with optional stretching and channel weighting.\n",
    "\n",
    "    Parameters:\n",
    "    - img: 2D numpy array\n",
    "    - stretch: Type of stretch ('asinh' or 'linear')\n",
    "    - Q: Controls asinh stretch strength\n",
    "    - alpha: Controls non-linearity for asinh\n",
    "    - weight: Multiplier to boost/dampen this channelâ€™s contribution\n",
    "\n",
    "    Returns:\n",
    "    - Normalised image scaled between 0 and 1\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace nans with 0.0\n",
    "    img = np.nan_to_num(img, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Clip possible negative fluxes\n",
    "    img = np.clip(img, 0, None)\n",
    "    \n",
    "    # Apply scaling weight\n",
    "    img *= weight\n",
    "    \n",
    "    # Determine which scaling to us\n",
    "    if stretch == 'asinh':  # Lupton scaling\n",
    "        img_scaled = np.arcsinh(alpha * Q * img) / Q\n",
    "    elif stretch == 'log':\n",
    "        img_scaled = np.log10(1 + alpha * img)\n",
    "    elif stretch == 'linear':\n",
    "        img_scaled = img\n",
    "    else:\n",
    "        raise ValueError(\"Unknown stretch\")\n",
    "    \n",
    "    # After stretching the image is normalised to 1\n",
    "    return img_scaled / np.nanmax(img_scaled) if np.nanmax(img_scaled) != 0 else img_scaled\n",
    "\n",
    "\n",
    "def preprocess_fits_image(filename, ext=0, stretch='asinh', Q=10, alpha=1, weight=1):\n",
    "    \"\"\"\n",
    "    Load, optionally resample, and normalise a FITS image.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: FITS filename with optional extension (e.g., 'file.fits[1]')\n",
    "    - stretch, Q, alpha, weight: Passed to normalize_image\n",
    "    - upscale_size: Tuple of (new_y, new_x) size to resize image to\n",
    "\n",
    "    Returns:\n",
    "    - Processed 2D numpy image\n",
    "    \"\"\"\n",
    "    \n",
    "    with fits.open(filename) as hdul:\n",
    "        img_data = hdul[ext].data\n",
    "    return normalise_image(img_data, stretch=stretch, Q=Q, alpha=alpha, weight=weight)\n",
    "\n",
    "\n",
    "def make_stamp(imagesRGB, Q_r, alpha_r, Q_g, alpha_g, Q_b, alpha_b, outfile='stamp.pdf'):\n",
    "    \"\"\"\n",
    "    Make RGB stamp using trilogy\n",
    "    \"\"\"\n",
    "    \n",
    "    ##################\n",
    "    # MAKE RGB IMAGE #\n",
    "    ##################\n",
    "    \n",
    "    # Process images for scaling purposes\n",
    "    processed_images = {}\n",
    "    for colour in ['R', 'G', 'B']:\n",
    "        processed_images[colour] = []\n",
    "        for image_str in imagesRGB[colour]:\n",
    "            # Obtain filename and extension that carries the data\n",
    "            fname, ext = image_str.split('[')\n",
    "            ext = int(ext.replace(']', ''))\n",
    "            if colour == 'R':\n",
    "                norm_img = preprocess_fits_image(fname, ext, Q=Q_r, alpha=alpha_r)\n",
    "            elif colour == \"G\":\n",
    "                norm_img = preprocess_fits_image(fname, ext, Q=Q_g, alpha=alpha_g)\n",
    "            else:\n",
    "                norm_img = preprocess_fits_image(fname, ext, Q=Q_b, alpha=alpha_b)\n",
    "                \n",
    "            processed_images[colour].append(norm_img)\n",
    "\n",
    "    # Add scaled images to the dictionary\n",
    "    temp_files = {}\n",
    "    for colour in processed_images:\n",
    "        fname = f'temp_{colour}.fits'\n",
    "        fits.writeto(fname, processed_images[colour][0], overwrite=True)\n",
    "        temp_files[colour] = fname\n",
    "    \n",
    "    # set luminosity of the noise in each channel\n",
    "    noiselums = {'R': 0.2, 'G': 0.2, 'B': 0.2}\n",
    "        \n",
    "    with open(os.devnull, \"w\") as fnull, contextlib.redirect_stdout(fnull): # avoid printing out stuff\n",
    "        trilogy.Trilogy(\n",
    "            infile=None, samplesize=20000, stampsize=20000, maxstampsize=20000,\n",
    "            deletetests=1, deletefilters=1, testfirst=0, showwith=\"PIL\",\n",
    "            mode='RGB', imagesorder='RGB',\n",
    "            imagesRGB={'R': [temp_files['R']], 'G': [temp_files['G']], 'B': [temp_files['B']]},\n",
    "            noiselums=noiselums, images=None, outname='color_image_temp', satpercent=0.000, \n",
    "            noiselum=0.5, noisesig0=10, correctbias=0, colorsatfac=1, combine='sum', show=False\n",
    "            ).run()\n",
    "        \n",
    "    # read in RGB image and delete png file\n",
    "    im = Image.open('color_image_temp.png')\n",
    "    im = im.transpose(method=Image.FLIP_TOP_BOTTOM)\n",
    "    NIRCam_image = np.asarray(im)\n",
    "    os.remove('color_image_temp.png')\n",
    "    \n",
    "    # read WCS from a single FITS file\n",
    "    single_filename = imagesRGB['R'][0].split('[')[0] # remove '[1]' if present\n",
    "    image_hdulist = fits.open(single_filename)\n",
    "    image_wcs = WCS(image_hdulist[1].header, image_hdulist)\n",
    "    \n",
    "    # --- Plot using matplotlib and save ---\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.imshow(NIRCam_image, origin='lower')\n",
    "    ax.axis('off')  # Hide axes\n",
    "    \n",
    "    # Save the RGB image as PDF\n",
    "    fig.savefig(outfile, bbox_inches='tight', pad_inches=0.0)\n",
    "    plt.close(fig)  # Clean up the figure\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Start making the stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- SETUP ----------\n",
    "input_dir = \"/home/bpc/University/master/Red_Cardinal/cutouts_3x3/\"\n",
    "output_dir = \"/home/bpc/University/master/Red_Cardinal/stamps/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ---------- STEP 1: Get IDs from NIRCam, PRIMER and COSMOS-Web ----------\n",
    "f444w_files = glob.glob(os.path.join(input_dir, \"*F444W*.fits\"))\n",
    "f444w_ids = [os.path.basename(f).split(\"_F444W\")[0] for f in f444w_files]\n",
    "\n",
    "f770w_primer_files = glob.glob(os.path.join(input_dir, \"*F770W_cutout_primer.fits\"))\n",
    "f770w_primer_ids = [os.path.basename(f).split(\"_F770W\")[0] for f in f770w_primer_files]\n",
    "\n",
    "f770w_cweb_files = glob.glob(os.path.join(input_dir, \"*F770W_cutout_cweb.fits\"))\n",
    "f770w_cweb_ids = [os.path.basename(f).split(\"_F770W\")[0] for f in f770w_cweb_files]\n",
    "\n",
    "f1800w_files = glob.glob(os.path.join(input_dir, \"*F1800W*.fits\"))\n",
    "f1800w_ids = [os.path.basename(f).split(\"_F1800W\")[0] for f in f1800w_files]\n",
    "\n",
    "# Remove all galaxies in f770w_primer_ids from f770w_cweb_ids\n",
    "f770w_cweb_ids = np.setdiff1d(f770w_cweb_ids, f770w_primer_ids)\n",
    "\n",
    "\n",
    "# ---------- STEP 2: Collect MIRI and NIRCam Files ----------\n",
    "fits_files = glob.glob(os.path.join(input_dir, \"*.fits\"))\n",
    "filters = [\"F444W\", \"F770W\", \"F1800W\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Function which calls the make_stamps function iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gal_id = \"18769\"\n",
    "try:\n",
    "    print(f\"Creating image for {gal_id}...\")\n",
    "    \n",
    "    # Construct base filenames (without [0])\n",
    "    r_file_base = os.path.join(input_dir, f\"{gal_id}_F1800W_cutout_primer.fits\")\n",
    "    g_file_primer_base = os.path.join(input_dir, f\"{gal_id}_F770W_cutout_primer.fits\")\n",
    "    g_file_cweb_base = os.path.join(input_dir, f\"{gal_id}_F770W_cutout_cweb.fits\")\n",
    "    b_file_base = os.path.join(input_dir, f\"{gal_id}_F444W_cutout_nircam.fits\")\n",
    "\n",
    "    # Decide which F770W file to use\n",
    "    if gal_id in f770w_primer_ids and os.path.exists(g_file_primer_base):\n",
    "        g_file = g_file_primer_base + \"[1]\"\n",
    "    elif gal_id in f770w_cweb_ids and os.path.exists(g_file_cweb_base):\n",
    "        g_file = g_file_cweb_base + \"[1]\"\n",
    "    else:\n",
    "        print(f\"[Skipping {gal_id}] No valid F770W file found.\")\n",
    "        #continue\n",
    "\n",
    "    # Now safely add [0] to files\n",
    "    r_file = r_file_base + \"[1]\"\n",
    "    b_file = b_file_base + \"[0]\"\n",
    "    \n",
    "    # Stack into imagesRGB dictionary\n",
    "    imagesRGB = {'R': [r_file], \n",
    "                 'G': [g_file], \n",
    "                 'B': [b_file]}\n",
    "    \n",
    "    # Call your image function (without shutters)\n",
    "    # Q determines the strength of the non-linearity for the stretch.\n",
    "    # alpha adjusts the sensitivity of the stretch for the given filter.\n",
    "\n",
    "    outfile = os.path.join(output_dir, f\"{gal_id}_stamp.pdf\")\n",
    "    make_stamp(imagesRGB, outfile=outfile, \n",
    "               Q_r=10, alpha_r=1.0,\n",
    "               Q_g=10, alpha_g=1.0,\n",
    "               Q_b=100, alpha_b=1.0)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing {gal_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nircam_fits = \"/home/bpc/University/master/Red_Cardinal/cutouts_3x3/8338_F444W_cutout_3x3.fits\"\n",
    "miri_770_fits = \"/home/bpc/University/master/Red_Cardinal/cutouts_3x3/8338_F770W_cutout_primer004.fits\"\n",
    "miri_1800_fits = \"/home/bpc/University/master/Red_Cardinal/cutouts_3x3/8338_F1800W_cutout_primer004.fits\"\n",
    "\n",
    "with fits.open(nircam_fits) as nircam_hdul:\n",
    "    nircam_data = nircam_hdul[0].data\n",
    "    print(nircam_data)\n",
    "\n",
    "with fits.open(miri_770_fits) as miri_770_hdul:\n",
    "    miri_770_data = miri_770_hdul[1].data\n",
    "    print(miri_770_data)\n",
    "\n",
    "with fits.open(miri_1800_fits) as miri_1800_hdul:\n",
    "    miri_1800_data = miri_1800_hdul[1].data\n",
    "    print(miri_1800_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Check extensions on cutout FITS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_file = \"/home/bpc/University/master/Red_Cardinal/cutouts_3x3/18769_F1800W_cutout_primer.fits\"\n",
    "with fits.open(r_file) as hdul:\n",
    "    for i, hdu in enumerate(hdul):\n",
    "        print(f\"HDU {i}: {hdu.name}, shape = {getattr(hdu.data, 'shape', None)}\")\n",
    "\n",
    "g_file = \"/home/bpc/University/master/Red_Cardinal/cutouts_3x3/18769_F770W_cutout_primer.fits\"\n",
    "with fits.open(g_file) as hdul:\n",
    "    for i, hdu in enumerate(hdul):\n",
    "        print(f\"HDU {i}: {hdu.name}, shape = {getattr(hdu.data, 'shape', None)}\")\n",
    "        \n",
    "b_file = \"/home/bpc/University/master/Red_Cardinal/cutouts_3x3/18769_F444W_cutout_nircam.fits\"\n",
    "with fits.open(b_file) as hdul:\n",
    "    for i, hdu in enumerate(hdul):\n",
    "        print(f\"HDU {i}: {hdu.name}, shape = {getattr(hdu.data, 'shape', None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in shutter footprints\n",
    "import regions, pickle\n",
    "with open('shutters_bluejay/shutters_regions.pkl', 'rb') as f:\n",
    "    shutters = pickle.load(f)\n",
    "print(len(shutters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the list of shutters\n",
    "for s in shutters:\n",
    "\n",
    "    # read shutters into regions objects\n",
    "    reg_source = regions.Regions.parse(s['source'], format='ds9')\n",
    "    reg_source = reg_source[0] # list of regions with only one entry\n",
    "    reg_aperture = regions.Regions.parse(s['AB_aperture'], format='ds9')\n",
    "    \n",
    "    # read FITS files with NIRCam cutouts\n",
    "    imagesRGB = {\"R\": [f\"v1.0_JWST_cutouts/{s['ID']}_F444W_cutout.fits[1]\"], \\\n",
    "                 \"G\": [f\"v1.0_JWST_cutouts/{s['ID']}_F200W_cutout.fits[1]\"], \\\n",
    "                 \"B\": [f\"v1.0_JWST_cutouts/{s['ID']}_F115W_cutout.fits[1]\"]}\n",
    "    \n",
    "    # make footprint\n",
    "    make_stamp_with_shutters(imagesRGB, reg_source, reg_aperture,\n",
    "                             outfile=f\"stamps/{s['ID']}.pdf\", sourcemark=False, size_arcsec=3.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
